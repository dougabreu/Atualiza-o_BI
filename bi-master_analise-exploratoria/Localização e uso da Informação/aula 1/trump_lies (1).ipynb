{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"trump_lies (1).ipynb","provenance":[],"collapsed_sections":["CfUbIeEa7Lin"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"6rjRXrX37Lht","colab_type":"text"},"source":["## Mentiras de trump"]},{"cell_type":"markdown","metadata":{"id":"qlOyn8cO7Lhu","colab_type":"text"},"source":["## Sumario\n","\n","Este é um tutorial introdutório sobre captura da Web em Python. Tudo o que é necessário para acompanhar é um entendimento básico da linguagem de programação Python.\n","\n","No final deste tutorial, você poderá extrair dados de uma página da Web estática usando as bibliotecas ** requests ** e ** Beautiful Soup ** e exportar esses dados para um arquivo de texto estruturado usando os ** pandas * * biblioteca."]},{"cell_type":"markdown","metadata":{"id":"LMEsAb9Y7Lhv","colab_type":"text"},"source":["## Outline\n","\n","\n","- O que é web scraping?\n","- Examinando o artigo do New York Times\n","    - Examinando o HTML\n","    - Fato 1: HTML consiste em tags\n","    - Fato 2: as tags podem ter atributos\n","    - Fato 3: as tags podem ser aninhadas\n","- Lendo a página da web em Python\n","- Analisando o HTML usando Sopa Bonita\n","    - Coletando todos os registros\n","    - Extraindo a data\n","    - Extrair a mentira\n","    - Extraindo a explicação\n","    - Extraindo o URL\n","    - Recapitulação: métodos e atributos da Beautiful Soup\n","- Construindo o conjunto de dados\n","    - Aplicando uma estrutura de dados tabular\n","    "]},{"cell_type":"markdown","metadata":{"id":"uCKppwlm7Lhv","colab_type":"text"},"source":["## O que é web scraping?\n","\n","Em 21 de julho de 2017, o New York Times atualizou um artigo de opinião chamado [Mentiras de Trump] (https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html), detalhando cada público mentira que o presidente disse desde que assumiu o cargo. Porque este é um jornal, a informação foi (obviamente) publicada como um bloco de texto. Este é um ótimo formato para consumo humano, mas não pode ser facilmente entendido por um computador. ** Neste tutorial, vamos extrair as mentiras do presidente do artigo do New York Times e armazená-las em um conjunto de dados não estruturado. **\n","\n","Esse é um cenário comum: você encontra uma página da Web que contém dados que deseja analisar, mas ela não é apresentada em um formato que você possa baixar e ler facilmente em sua ferramenta de análise de dados favorita. Você pode imaginar copiar e colar manualmente os dados em uma planilha, mas na maioria dos casos, isso consome muito tempo. Uma técnica chamada ** web scraping ** é uma maneira útil de automatizar esse processo.\n","\n","O que é web scraping? É o processo de extrair informações de uma página da web ** aproveitando os padrões ** no código subjacente da página da web. Vamos começar a procurar por esses padrões!"]},{"cell_type":"markdown","metadata":{"id":"_pS2lGLf7Lhw","colab_type":"text"},"source":["## Examinando o artigo do New York Times\n","\n","Aqui está a maneira como o artigo apresentou as informações:\n","\n","! [Screenshot do artigo] (images / article_1.png)\n","\n","Ao converter isso em um conjunto de dados **, você pode pensar em cada mentira como um \"registro\" com quatro campos: **\n","\n","1. A data da mentira.\n","2. A própria mentira (como uma citação).\n","3. A breve explicação do escritor sobre o porquê disso ser uma mentira.\n","4. A URL de um artigo que substancia a alegação de que era mentira.\n","\n","É importante ressaltar que esses campos têm formatação diferente, que é consistente em todo o artigo: a data é texto em negrito, a mentira é texto \"regular\", a explicação é texto cinza itálico e a URL é vinculada ao texto itálico cinza.\n","\n","** Por que a formatação é importante? ** Porque é muito provável que o código subjacente à página da Web \"marque\" esses campos de maneira diferente, e podemos aproveitar esse padrão ao copiar a página. Vamos dar uma olhada no código-fonte, conhecido como HTML:"]},{"cell_type":"markdown","metadata":{"id":"m7HAKTC27Lhw","colab_type":"text"},"source":["## Examinando o HTML\n","\n","Para visualizar o código HTML que gera uma página da web, clique com o botão direito do mouse e selecione \"Exibir origem da página\" no Chrome ou Firefox, \"Exibir código-fonte\" no Internet Explorer ou \"Mostrar código-fonte\" no Safari. (Se essa opção não aparecer no Safari, apenas abra as Preferências do Safari, selecione a guia Avançado e marque \"Mostrar menu Desenvolver na barra de menus\".)\n","\n","Aqui estão as primeiras linhas que você verá se visualizar a fonte do artigo do New York Times:\n","\n","! [Captura de tela da fonte] (images / source_1.png)\n","\n","Vamos localizar a ** primeira mentira ** procurando no HTML pelo texto \"iraque\":\n","\n","! [Captura de tela da fonte] (images / source_2.png)\n","\n","Felizmente, você só precisa entender ** três fatos básicos ** sobre HTML para começar a usar a web scraping!"]},{"cell_type":"markdown","metadata":{"id":"viLw4zls7Lhx","colab_type":"text"},"source":["## Fato 1: HTML consiste em tags\n","\n","Você pode ver que o HTML contém o texto do artigo, junto com \"tags\" (especificados usando colchetes angulares) que \"marcam\" o texto. (\"HTML\" significa Hyper Text Markup Language.)\n","\n","Por exemplo, uma tag é `<strong>`, que significa \"use formatação em negrito\". Existe uma tag `<strong>` antes de \"21 de janeiro\" e uma tag `</ strong>` após ela. A primeira é uma \"tag de abertura\" e a segunda é uma \"tag de fechamento\" (denotada por `/`), que indica ao navegador da web ** por onde começar e parar de aplicar a formatação. ** Em outras palavras, tag informa ao navegador da Web para tornar o texto \"21 de janeiro\" em negrito. (Não se preocupe com o `& nbsp;` - vamos lidar com isso mais tarde.)"]},{"cell_type":"markdown","metadata":{"id":"Mqaa65eN7Lhx","colab_type":"text"},"source":["## Fato 2: as tags podem ter atributos\n","\n","As tags HTML podem ter \"atributos\", especificados na tag de abertura. Por exemplo, `<span class =\" short-desc \">` indica que esta tag `<span>` em particular possui um atributo `class` com um valor de` short-desc`.\n","\n","Para o propósito de web scraping, ** você não precisa realmente entender ** o significado de `<span>`, `class` ou` short-desc`. Em vez disso, você só precisa reconhecer que as tags podem ter atributos e que elas são especificadas dessa maneira específica."]},{"cell_type":"markdown","metadata":{"id":"fZVE02tz7Lhy","colab_type":"text"},"source":["## Fato 3: as tags podem ser aninhadas\n","\n","Vamos fingir que meu código HTML disse:\n","\n","`Olá <strong> <em> alunos da Data School </ em> </ strong>\n","\n","O texto ** alunos da Data School ** seria em negrito, porque todo esse texto está entre a tag de abertura `<strong>` e a tag de fechamento `</ strong>`. O texto *** Data School *** também estaria em itálico, porque a tag `<em>` significa \"use itálico\". O texto \"Hello\" não seria em negrito ou itálico, porque não está dentro das tags `<strong>` ou `<em>`. Assim, apareceria da seguinte forma:\n","\n","Olá *** alunos da Data School * **\n","\n","O ponto central a ser seguido neste exemplo é que as tags ** \"marcam\" o texto de onde quer que elas abram para onde quer que sejam fechadas, independentemente de estarem aninhadas em outras tags.\n","\n","Consegui? Agora você sabe o suficiente sobre o HTML para começar a usar a web!"]},{"cell_type":"markdown","metadata":{"id":"c9ldmdvy7Lhy","colab_type":"text"},"source":["## Lendo a página da web em Python\n","\n","A primeira coisa que precisamos fazer é ler o HTML deste artigo no Python, o que faremos usando a biblioteca [requests] (http://docs.python-requests.org/en/master/). (Se você não tiver, você pode `pip install requests` da linha de comando.)"]},{"cell_type":"code","metadata":{"id":"WRuEQeul7Lhy","colab_type":"code","colab":{}},"source":["import requests\n","r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zERCKOqz7Lh1","colab_type":"text"},"source":["O código acima busca nossa página web a partir do URL e armazena o resultado em um objeto \"resposta\" chamado `r`. Esse objeto de resposta tem um atributo `text`, que contém o mesmo código HTML que vimos ao visualizar a fonte em nosso navegador:"]},{"cell_type":"code","metadata":{"id":"duRB9uVY7Lh2","colab_type":"code","colab":{}},"source":["# print the first 500 characters of the HTML\n","print(r.text[0:500])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1kcOKBub7Lh5","colab_type":"text"},"source":["## Analisando o HTML usando beautifulsoup\n","\n","Vamos analisar o HTML usando a biblioteca [Beautiful Soup 4] (https://www.crummy.com/software/BeautifulSoup/bs4/doc/), que é uma biblioteca popular em Python para a criação de páginas da web. (Se você não tiver, você pode `pip instalar beautifulsoup4` a partir da linha de comando.)"]},{"cell_type":"code","metadata":{"id":"50BV4etk7Lh5","colab_type":"code","colab":{}},"source":["from bs4 import BeautifulSoup\n","soup = BeautifulSoup(r.text, 'html.parser')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AezHWVSz7Lh7","colab_type":"text"},"source":["O código acima analisa o HTML (armazenado em `r.text`) em um objeto especial chamado` soup` que a biblioteca Beautiful Soup entende. Em outras palavras, o Beautiful Soup está ** lendo o HTML e dando sentido a sua estrutura. **\n","\n","(Observe que `html.parser` é o analisador incluído na biblioteca padrão do Python, embora outros analisadores possam ser usados ​​pelo Beautiful Soup. Consulte [diferenças entre analisadores] (https://www.crummy.com/software/BeautifulSoup/bs4 / doc / # difference-between-parsers) para aprender mais.)"]},{"cell_type":"markdown","metadata":{"id":"Hu5LcYkp7Lh8","colab_type":"text"},"source":["## Coletando todos os registros\n","\n","O código Python acima é o código padrão que uso em todos os projetos de varredura da web. Agora, vamos começar ** aproveitando os padrões que observamos na formatação do artigo ** para criar nosso conjunto de dados!\n","\n","Vamos dar uma outra olhada no artigo e compará-lo com o HTML:\n","\n","! [Screenshot do artigo] (images / article_1.png)\n","\n","! [Captura de tela da fonte] (images / source_3.png)\n","\n","Você deve ter notado que cada registro tem o seguinte formato:\n","\n","`<span class =\" short-desc \"> <strong> DATA </ strong> MENTIRA <span class =\" short-truth \"> <a href=\"URL\"> EXPLICAÇÃO </a> </ span> </ span > `\n","\n","Há uma tag `<span>` externa e, em seguida, aninhada dentro dela é uma tag `<strong>` e outra tag <span>, que contém uma tag `<a>`. Todas essas tags afetam a formatação do texto. E como o New York Times quer que cada registro apareça de maneira consistente em seu navegador, sabemos que ** cada registro será marcado de maneira consistente no HTML. ** Esse é o padrão que nos permite construir nossa conjunto de dados!\n","\n","Vamos pedir para o Beautiful Soup ** encontrar todos os registros: **"]},{"cell_type":"code","metadata":{"id":"5gKNRbCs7Lh8","colab_type":"code","colab":{}},"source":["results = soup.find_all('span', attrs={'class':'short-desc'})"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mE_GWdpL7Lh_","colab_type":"text"},"source":["Este código procura o objeto `soup` por todas as tags` <span> `com o atributo` class = \"short-desc\" `. Ele retorna um objeto especial Beautiful Soup (chamado de \"ResultSet\") contendo os resultados da pesquisa.\n","\n","`results` atua como uma lista ** do Python **, para que possamos verificar sua duração:"]},{"cell_type":"code","metadata":{"id":"gpyfUiCk7Lh_","colab_type":"code","colab":{}},"source":["len(results)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wK1cy0FF7LiC","colab_type":"text"},"source":["Existem 180 resultados, o que parece razoável dada a duração do artigo. (Se esse número não parecer razoável, examinaríamos o HTML ainda mais para determinar se nossas suposições sobre os padrões no HTML estavam incorretas.)\n","\n","Também podemos dividir o objeto como uma lista, para examinar os ** primeiros três resultados: **"]},{"cell_type":"code","metadata":{"id":"-0Cm5brv7LiC","colab_type":"code","colab":{}},"source":["results[0:3]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x-HIK3gS7LiE","colab_type":"text"},"source":["ambém verificaremos se o ** último resultado ** deste objeto corresponde ao último registro no artigo:\n","\n","! [Screenshot do artigo] (images / article_2.png)"]},{"cell_type":"code","metadata":{"id":"icv3nNnm7LiE","colab_type":"code","colab":{}},"source":["results[-1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxQKbPbu7LiG","colab_type":"text"},"source":["Parece bom!\n","\n","Nós agora coletamos todos os 116 registros, mas ainda precisamos separar cada registro em seus quatro componentes (data, mentira, explicação e URL) para dar ao conjunto de dados alguma estrutura."]},{"cell_type":"markdown","metadata":{"id":"HK73xVVC7LiH","colab_type":"text"},"source":["## Extraindo a data\n","\n","O Web scraping é geralmente um processo interativo, no qual você experimenta seu código até que ele funcione exatamente como deseja. Para simplificar a experimentação, começaremos trabalhando apenas com o ** primeiro registro ** no objeto `results` e, mais tarde, modificaremos nosso código para usar um loop:"]},{"cell_type":"code","metadata":{"id":"6H3gP2Ah7LiH","colab_type":"code","colab":{}},"source":["first_result = results[0]\n","first_result"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vIrzN9vt7LiJ","colab_type":"text"},"source":["\n","Embora `first_result` possa parecer uma string Python, você notará que não há marcas de aspas em torno dela. Em vez disso, é outro objeto especial Beautiful Soup (chamado de \"Tag\") que possui métodos e atributos específicos.\n","\n","Para localizar a data, podemos usar seu método `find ()` para ** encontrar uma única tag ** que corresponda a um padrão específico, em contraste com o método `find_all ()` que usamos acima para ** encontrar todas tags ** que correspondem a um padrão:"]},{"cell_type":"code","metadata":{"id":"6mXxHNJG7LiK","colab_type":"code","colab":{}},"source":["first_result.find('strong')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tbNcRnDE7LiM","colab_type":"text"},"source":["Este código pesquisa `first_result` pela primeira instância de uma tag` <strong> `e retorna novamente um objeto\" Tag \"de Beautiful Soup (não uma string).\n","\n","Como queremos ** extrair o texto entre as tags de abertura e fechamento **, podemos acessar seu atributo `text`, que de fato retorna uma string normal do Python:"]},{"cell_type":"code","metadata":{"id":"rJqO1IPN7LiM","colab_type":"code","colab":{}},"source":["first_result.find('strong').text"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"77JWOzeU7LiO","colab_type":"text"},"source":["O que é `\\ xa0`? Na verdade, você não precisa saber disso, mas é chamado de \"seqüência de escape\" que representa o caractere \"& nbsp;\" que vimos anteriormente no código-fonte HTML.\n","\n","No entanto, você precisa saber que ** uma seqüência de escape representa um único caractere ** dentro de uma string. Vamos dividi-lo a partir do final da string:"]},{"cell_type":"code","metadata":{"id":"d-VUI4ox7LiO","colab_type":"code","colab":{}},"source":["first_result.find('strong').text[0:-1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5HaIBFWv7LiR","colab_type":"text"},"source":["Por fim, adicionaremos o ano, pois não queremos que nosso conjunto de dados inclua datas ambíguas:"]},{"cell_type":"code","metadata":{"id":"S8WYcB-S7LiR","colab_type":"code","colab":{}},"source":["first_result.find('strong').text[0:-1] + ', 2017'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7hHJhZlL7LiT","colab_type":"text"},"source":["\n","## Extraindo a mentira\n","\n","Vamos dar uma outra olhada no `first_result`:"]},{"cell_type":"code","metadata":{"id":"5-XA8DHp7LiT","colab_type":"code","colab":{}},"source":["first_result"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lF41I6X_7LiW","colab_type":"text"},"source":["osso objetivo é extrair as duas frases sobre o Iraque. Infelizmente, não há um par de tags de abertura e fechamento que começa **immediately before the lie** and ends **immediately after the lie**. Portanto, vamos ter que usar uma técnica diferente:"]},{"cell_type":"code","metadata":{"id":"6zQLADPH7LiW","colab_type":"code","colab":{}},"source":["first_result.contents"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eO99lqKV7LiY","colab_type":"text"},"source":["\n","O tag \"first_result`\" possui um atributo `contents`, que retorna uma lista do Python contendo seus\" filhos \". O que são crianças? São as tags e strings que estão aninhadas em uma tag.\n","\n","Podemos dividir essa lista para extrair o segundo elemento:"]},{"cell_type":"code","metadata":{"id":"Kv2Bk0-j7LiY","colab_type":"code","colab":{}},"source":["first_result.contents[1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bpIVD4a67Lia","colab_type":"text"},"source":["\n","Por fim, dividiremos as aspas curvas e o espaço extra no final:"]},{"cell_type":"code","metadata":{"id":"lTe2RB9p7Lia","colab_type":"code","colab":{}},"source":["first_result.contents[1][1:-2]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eHheT_dP7Lic","colab_type":"text"},"source":["# Extraindo a explicação\n","\n","Com base no que você já viu, você pode ter descoberto que temos pelo menos ** duas opções ** de como extraímos o terceiro componente do registro, que é a explicação do autor da razão pela qual a declaração do Presidente foi uma mentira.\n","\n","A ** primeira opção ** é dividir o atributo `contents`, como fizemos ao extrair a mentira:"]},{"cell_type":"code","metadata":{"id":"7SDN0Imw7Lic","colab_type":"code","colab":{}},"source":["first_result.contents[2]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RJ6r9wIM7Lie","colab_type":"text"},"source":["A ** segunda opção ** é pesquisar a tag ao redor, como fizemos ao extrair a data:"]},{"cell_type":"code","metadata":{"id":"9CRO-ssj7Lie","colab_type":"code","colab":{}},"source":["first_result.find('a')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBm6Pjsl7Lig","colab_type":"text"},"source":["De qualquer forma, podemos acessar o atributo `text` e depois cortar os parênteses de abertura e fechamento:"]},{"cell_type":"code","metadata":{"id":"e3IEt3Dp7Lih","colab_type":"code","colab":{}},"source":["first_result.find('a').text[1:-1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZpouYLCJ7Lij","colab_type":"text"},"source":["## Extraindo o URL\n","\n","Finalmente, queremos extrair a URL do artigo que substancia a afirmação do escritor de que o presidente estava mentindo.\n","\n","Vamos examinar a tag `<a>` dentro de `first_result`:"]},{"cell_type":"code","metadata":{"id":"RmAManDv7Lik","colab_type":"code","colab":{}},"source":["first_result.find('a')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DSaYI_0s7Lil","colab_type":"text"},"source":["Até agora, neste tutorial, extraímos o texto ** entre as tags **. Nesse caso, o texto que queremos extrair está localizado ** dentro da própria tag **. Especificamente, queremos acessar o valor do atributo `href` dentro da tag` <a> `.\n","\n","A Beautiful Soup trata os atributos da tag e seus valores como ** pares de valores-chave em um dicionário: ** você coloca o nome do atributo entre colchetes (como uma chave de dicionário) e recupera o valor do atributo:"]},{"cell_type":"code","metadata":{"id":"ZvLkRQxT7Lim","colab_type":"code","colab":{}},"source":["first_result.find('a')['href']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfUbIeEa7Lin","colab_type":"text"},"source":["## Recap: métodos e atributos da Beautiful Soup\n","\n","Antes de concluirmos a construção do conjunto de dados, quero resumir algumas maneiras pelas quais você pode interagir com os objetos Beautiful Soup.\n","\n","Você pode aplicar esses ** dois métodos ** ao objeto inicial `soup` ou a um objeto Tag (como` first_result`):\n","\n","- `find ()`: procura pela primeira tag correspondente e retorna um objeto Tag\n","- `find_all ()`: procura por todas as tags correspondentes e retorna um objeto ResultSet (que você pode tratar como uma lista de Tags)\n","\n","Você pode extrair informações de um objeto Tag (como `first_result`) usando esses ** dois atributos: **\n","\n","- `text`: extrai o texto de um Tag e retorna uma string\n","- `contents`: extrai os filhos de um Tag e retorna uma lista de Tags e strings\n","\n","É importante saber se você está interagindo com um Tag, um ResultSet, uma lista ou uma string, porque isso afeta quais métodos e atributos você pode acessar.\n","\n","E, claro, há muitos outros métodos e atributos disponíveis para você, descritos na [documentação da Beautiful Soup] (https://www.crummy.com/software/BeautifulSoup/bs4/doc/)."]},{"cell_type":"markdown","metadata":{"id":"3L5ZaFoE7Lio","colab_type":"text"},"source":["## Criando o conjunto de dados\n","\n","Agora que descobrimos como extrair os quatro componentes de `first_result`, podemos ** criar um loop para repetir este processo ** em todos os 116` results`. Nós vamos armazenar a saída em uma ** lista de tuplas ** chamada `registros`:"]},{"cell_type":"code","metadata":{"id":"xkjEDj4b7Lio","colab_type":"code","colab":{}},"source":["records = []\n","for result in results:\n","    date = result.find('strong').text[0:-1] + ', 2017'\n","    lie = result.contents[1][1:-2]\n","    explanation = result.find('a').text[1:-1]\n","    url = result.find('a')['href']\n","    records.append((date, lie, explanation, url))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ja-oqa2W7Liq","colab_type":"text"},"source":["Como havia 116 `resultados`, deveríamos ter 116` registros`:"]},{"cell_type":"code","metadata":{"id":"IJNUAmd-7Liq","colab_type":"code","colab":{}},"source":["len(records)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4tGxK68b7Lis","colab_type":"text"},"source":["Vamos fazer uma verificação rápida dos três primeiros registros:"]},{"cell_type":"code","metadata":{"id":"rbipzUij7Lis","colab_type":"code","colab":{}},"source":["records[0:3]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eY9CKGRM7Liu","colab_type":"text"},"source":["Boa sorte"]},{"cell_type":"markdown","metadata":{"id":"5RHLA3mU7Liv","colab_type":"text"},"source":["## Aplicando uma estrutura de dados tabular\n","\n","O último grande passo neste processo é aplicar uma estrutura de dados tabular à nossa estrutura existente (que é uma lista de tuplas). Faremos isso usando a biblioteca [pandas] (http://pandas.pydata.org/), uma biblioteca Python incrivelmente popular para análise e manipulação de dados. (Se você não tem, aqui estão as [instruções de instalação] (http://pandas.pydata.org/pandas-docs/stable/install.html).)\n","\n","A estrutura de dados primária em pandas é o \"DataFrame\", que é adequado para dados tabulares com colunas de diferentes tipos, ** semelhante a uma planilha do Excel ou tabela SQL. ** Podemos converter nossa lista de tuplas em um DataFrame passando-o ao construtor DataFrame e especificando os nomes de coluna desejados:"]},{"cell_type":"code","metadata":{"id":"PIxYeWVj7Liv","colab_type":"code","colab":{}},"source":["import pandas as pd\n","df = pd.DataFrame(records, columns=['date', 'lie', 'explanation', 'url'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w5b6sYJr7Lix","colab_type":"text"},"source":["O DataFrame inclui um método `head ()`, que permite examinar a parte superior do DataFrame:"]},{"cell_type":"code","metadata":{"id":"eb0zqh3m7Lix","colab_type":"code","colab":{}},"source":["df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mjBLXmJ57Liz","colab_type":"text"},"source":["The numbers on the left side of the DataFrame are known as the \"index\", which act as identifiers for the rows. Because we didn't specify an index, it was automatically assigned as the integers 0 to 115.\n","\n","We can examine the bottom of the DataFrame using the `tail()` method:"]},{"cell_type":"code","metadata":{"id":"HfWyhd3_7Liz","colab_type":"code","colab":{}},"source":["df.tail()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k-EfTKdT7Li1","colab_type":"text"},"source":["Did you notice that \"January\" is abbreviated, while \"July\" is not? It's best to format your data consistently, and so we're going to convert the date column to pandas' special \"datetime\" format:"]},{"cell_type":"code","metadata":{"id":"mTaj3lfx7Li1","colab_type":"code","colab":{}},"source":["df['date'] = pd.to_datetime(df['date'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9W9NHlgx7Li3","colab_type":"text"},"source":["The code above converts the \"date\" column to datetime format, and then overwrites the existing \"date\" column. (Notice that we did not have to tell pandas that the column was originally in \"MONTH DAY, YEAR\" format - **pandas just figured it out!**)\n","\n","Let's take a look at the results:"]},{"cell_type":"code","metadata":{"id":"Ayi5B3ZZ7Li4","colab_type":"code","colab":{}},"source":["df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xL3vqtTA7Li6","colab_type":"code","colab":{}},"source":["df.tail()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mp0f6XHA7Li7","colab_type":"text"},"source":["Not only is the date column now consistently formatted, but pandas also provides a wealth of [date-related functionality](https://pandas.pydata.org/pandas-docs/stable/timeseries.html) because it's in datetime format."]},{"cell_type":"code","metadata":{"id":"fMwvYcsH7pGc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}