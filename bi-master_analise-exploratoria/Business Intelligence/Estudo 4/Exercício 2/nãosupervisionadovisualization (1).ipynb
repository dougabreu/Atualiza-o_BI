{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "version": "3.6.1",
      "name": "python",
      "nbconvert_exporter": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "nãosupervisionadovisualization.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZUCnaMmMewq",
        "colab_type": "text"
      },
      "source": [
        "#Projeto de data sciencies em texto não supervisionado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a9f0d9e1da1d1c9ce96322ecedc81d7a7847f043",
        "_cell_guid": "b370038e-edd0-42b6-985a-c30f6eea960b",
        "id": "3dbAf_6UePPt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# NIPS: Visualização de modelagem de tópicos\n",
        "\n",
        "Alguns tópicos principais do NIPS de acordo com [wikipedia] (https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems):\n",
        "\n",
        "1. Aprendizado de máquina,\n",
        "2. Estatísticas,\n",
        "3. Inteligência artificial,\n",
        "4. Neurociência computacional\n",
        "\n",
        "No entanto, os tópicos estão dentro do mesmo domínio, o que torna mais difícil distingui-los. Aqui neste Kernel tentarei extrair alguns tópicos usando a alocação de Dirichlet latente __LDA__. Este tutorial apresenta um pipeline de processamento de linguagem natural de ponta a ponta, começando com dados brutos e passando pela preparação, modelagem e visualização do papel. Iremos abordar os seguintes pontos\n",
        "\n",
        "\n",
        "1. Modelagem de tópico com ** LDA **\n",
        "1. Visualização de modelos de tópicos com ** pyLDAvis **\n",
        "1. Visualização dos resultados do LDA com ** t-SNE ** e ** bokeh **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "49cf47103ed18adfb84e28e636784cf89dbb3144",
        "_cell_guid": "a614ee7b-dc9a-4a69-a22a-6712176d67c2",
        "id": "gP7-aZ4hePPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4c36944-af59-45ac-f69b-162e7abbcfc7"
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "import pandas as pd\n",
        "import pickle as pk\n",
        "from scipy import sparse as sp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XFrIzJO9dFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "97fd3547-2cc5-4368-83bc-cac8af2d13f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "workdir_path = '/content/drive/My Drive/'  # Inserir o local da pasta onde estão os arquivos de entrada (treino e teste)\n",
        "os.chdir(workdir_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "eda4ba077f4beb7a55182bc37b147050f444827f",
        "_cell_guid": "9b886989-75f5-4522-b9d6-2a40737885f0",
        "id": "PpSqPeCsePPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "22084730-65bc-45a5-c3d8-4fc576be2d74"
      },
      "source": [
        "p_df = pd.read_csv('papers/Papers.csv')\n",
        "docs = array(p_df['PaperText'])\n",
        "docs[1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Learning with Symmetric Label Noise: The\\nImportance of Being Unhinged\\n\\nBrendan van Rooyen∗,†\\n∗\\n\\nAditya Krishna Menon†,∗\\n\\nThe Australian National University\\n\\n†\\n\\nRobert C. Williamson∗,†\\n\\nNational ICT Australia\\n\\n{ brendan.vanrooyen, aditya.menon, bob.williamson }@nicta.com.au\\n\\nAbstract\\nConvex potential minimisation is the de facto approach to binary classification.\\nHowever, Long and Servedio [2010] proved that under symmetric label noise\\n(SLN), minimisation of any convex potential over a linear function class can result in classification performance equivalent to random guessing. This ostensibly\\nshows that convex losses are not SLN-robust. In this paper, we propose a convex,\\nclassification-calibrated loss and prove that it is SLN-robust. The loss avoids the\\nLong and Servedio [2010] result by virtue of being negatively unbounded. The\\nloss is a modification of the hinge loss, where one does not clamp at zero; hence,\\nwe call it the unhinged loss. We show that the optimal unhinged solution is equivalent to that of a strongly regularised SVM, and is the limiting solution for any\\nconvex potential; this implies that strong `2 regularisation makes most standard\\nlearners SLN-robust. Experiments confirm the unhinged loss’ SLN-robustness is\\nborne out in practice. So, with apologies to Wilde [1895], while the truth is rarely\\npure, it can be simple.\\n\\n1\\n\\nLearning with symmetric label noise\\n\\nBinary classification is the canonical supervised learning problem. Given an instance space X, and\\nsamples from some distribution D over X × {±1}, the goal is to learn a scorer s : X → R with low\\nmisclassification error on future samples drawn from D. Our interest is in the more realistic scenario\\nwhere the learner observes samples from some corruption D of D, where labels have some constant\\nprobability of being flipped, and the goal is still to perform well with respect to D. This problem is\\nknown as learning from symmetric label noise (SLN learning) [Angluin and Laird, 1988].\\nLong and Servedio [2010] showed that there exist linearly separable D where, when the learner\\nobserves some corruption D with symmetric label noise of any nonzero rate, minimisation of any\\nconvex potential over a linear function class results in classification performance on D that is equivalent to random guessing. Ostensibly, this establishes that convex losses are not “SLN-robust” and\\nmotivates the use of non-convex losses [Stempfel and Ralaivola, 2009, Masnadi-Shirazi et al., 2010,\\nDing and Vishwanathan, 2010, Denchev et al., 2012, Manwani and Sastry, 2013].\\nIn this paper, we propose a convex loss and prove that it is SLN-robust. The loss avoids the result\\nof Long and Servedio [2010] by virtue of being negatively unbounded. The loss is a modification of the hinge loss where one does not clamp at zero; thus, we call it the unhinged loss. This\\nloss has several appealing properties, such as being the unique convex loss satisfying a notion of\\n“strong” SLN-robustness (Proposition 5), being classification-calibrated (Proposition 6), consistent\\nwhen minimised on D (Proposition 7), and having an simple optimal solution that is the difference\\nof two kernel means (Equation 8). Finally, we show that this optimal solution is equivalent to that of\\na strongly regularised SVM (Proposition 8), and any twice-differentiable convex potential (Proposition 9), implying that strong `2 regularisation endows most standard learners with SLN-robustness.\\n1\\n\\n\\x0cThe classifier resulting from minimising the unhinged loss is not new [Devroye et al., 1996, Chapter 10], [Schölkopf and Smola, 2002, Section 1.2], [Shawe-Taylor and Cristianini, 2004, Section\\n5.1]. However, establishing this classifier’s (strong) SLN-robustness, uniqueness thereof, and its\\nequivalence to a highly regularised SVM solution, to our knowledge is novel.\\n\\n2\\n\\nBackground and problem setup\\n\\nFix an instance space X. We denote by D a distribution over X × {±1}, with random variables\\n(X, Y) ∼ D. Any D may be expressed via the class-conditionals (P, Q) = (P(X | Y = 1), P(X |\\nY = −1)) and base rate π = P(Y = 1), or via the marginal M = P(X) and class-probability\\nfunction η : x 7→ P(Y = 1 | X = x). We interchangeably write D as DP,Q,π or DM,η .\\n2.1\\n\\nClassifiers, scorers, and risks\\n\\nA scorer is any function s : X → R. A loss is any function ` : {±1} × R → R. We use `−1 , `1 to\\nrefer to `(−1, ·) and `(1, ·). The `-conditional risk L` : [0, 1] × R → R is defined as L` : (η, v) 7→\\nη · `1 (v) + (1 − η) · `−1 (v). Given a distribution D, the `-risk of a scorer s is defined as\\n.\\n\\nLD\\n` (s) =\\n\\n[`(Y, s(X))] ,\\n\\nE\\n\\n(X,Y)∼D\\n\\n(1)\\n\\nD\\nso that LD\\n` (s) = E [L` (η(X), s(X))]. For a set S, L` (S) is the set of `-risks for all scorers in S.\\nX∼M\\n\\nA function class is any F ⊆ RX . Given some F, the set of restricted Bayes-optimal scorers for a\\nloss ` are those scorers in F that minimise the `-risk:\\n.\\n\\nSD,F,∗\\n= Argmin LD\\n` (s).\\n`\\ns∈F\\n\\nThe set of (unrestricted) Bayes-optimal scorers is SD,∗\\n= SD,F,∗\\nfor F = RX . The restricted\\n`\\n`\\n`-regret of a scorer is its excess risk over that of any restricted Bayes-optimal scorer:\\n.\\n\\nD\\nregretD,F\\n(s) = LD\\n` (s) − inf L` (t).\\n`\\nt∈F\\n\\nBinary classification is concerned with the zero-one loss, `01 : (y, v) 7→ Jyv < 0K + 21 Jv = 0K.\\nA loss ` is classification-calibrated if all its Bayes-optimal scorers are also optimal for zero-one\\nloss: (∀D) SD,∗\\n⊆ SD,∗\\n01 . A convex potential is any loss ` : (y, v) 7→ φ(yv), where φ : R → R+ is\\n`\\nconvex, non-increasing, differentiable with φ0 (0) < 0, and φ(+∞) = 0 [Long and Servedio, 2010,\\nDefinition 1]. All convex potentials are classification-calibrated [Bartlett et al., 2006, Theorem 2.1].\\n2.2\\n\\nLearning with symmetric label noise (SLN learning)\\n\\nThe problem of learning with symmetric label noise (SLN learning) is the following [Angluin and\\nLaird, 1988, Kearns, 1998, Blum and Mitchell, 1998, Natarajan et al., 2013]. For some notional\\n“clean” distribution D, which we would like to observe, we instead observe samples from some\\ncorrupted distribution SLN(D, ρ), for some ρ ∈ [0, 1/2). The distribution SLN(D, ρ) is such that\\nthe marginal distribution of instances is unchanged, but each label is independently flipped with\\nprobability ρ. The goal is to learn a scorer from these corrupted samples such that LD\\n01 (s) is small.\\nFor any quantity in D, we denote its corrupted counterparts in SLN(D, ρ) with a bar, e.g. M for\\nthe corrupted marginal distribution, and η for the corrupted class-probability function; additionally,\\nwhen ρ is clear from context, we will occasionally refer to SLN(D, ρ) by D. It is easy to check that\\nthe corrupted marginal distribution M = M , and [Natarajan et al., 2013, Lemma 7]\\n(∀x ∈ X) η(x) = (1 − 2ρ) · η(x) + ρ.\\n\\n3\\n\\n(2)\\n\\nSLN-robustness: formalisation\\n\\nWe consider learners (`, F) for a loss ` and a function class F, with learning being the search for\\nsome s ∈ F that minimises the `-risk. Informally, (`, F) is “robust” to symmetric label noise (SLNrobust) if minimising ` over F gives the same classifier on both the clean distribution D, which\\n2\\n\\n\\x0cthe learner would like to observe, and SLN(D, ρ) for any ρ ∈ [0, 1/2), which the learner actually\\nobserves. We now formalise this notion, and review what is known about SLN-robust learners.\\n3.1\\n\\nSLN-robust learners: a formal definition\\n\\nFor some fixed instance space X, let ∆ denote the set of distributions on X × {±1}. Given a notional\\n“clean” distribution D, Nsln : ∆ → 2∆ returns the set of possible corrupted versions of D the learner\\nmay observe, where labels are flipped with unknown probability ρ:\\n\\x1a\\n\\x14\\n\\x13\\x1b\\n1\\nNsln : D 7→ SLN(D, ρ) | ρ ∈ 0,\\n.\\n2\\nEquipped with this, we define our notion of SLN-robustness.\\nDefinition 1 (SLN-robustness). We say that a learner (`, F) is SLN-robust if\\nD,F,∗\\nD,F,∗\\n(∀D ∈ ∆) (∀D ∈ Nsln (D)) LD\\n) = LD\\n).\\n01 (S`\\n01 (S`\\n\\n(3)\\n\\nThat is, SLN-robustness requires that for any level of label noise in the observed distribution D, the\\nclassification performance (wrt D) of the learner is the same as if the learner directly observes D.\\nUnfortunately, a widely adopted class of learners is not SLN-robust, as we will now see.\\n3.2\\n\\nConvex potentials with linear function classes are not SLN-robust\\n\\nFix X = Rd , and consider learners with a convex potential `, and a function class of linear scorers\\nFlin = {x 7→ hw, xi | w ∈ Rd }.\\nThis captures e.g. the linear SVM and logistic regression, which are widely studied in theory and\\napplied in practice. Disappointingly, these learners are not SLN-robust: Long and Servedio [2010,\\nTheorem 2] give an example where, when learning under symmetric label noise, for any convex\\npotential `, the corrupted `-risk minimiser over Flin has classification performance equivalent to\\nrandom guessing on D. This implies that (`, Flin ) is not SLN-robust1 as per Definition 1.\\nProposition 1 (Long and Servedio [2010, Theorem 2]). Let X = Rd for any d ≥ 2. Pick any convex\\npotential `. Then, (`, Flin ) is not SLN-robust.\\n3.3\\n\\nThe fallout: what learners are SLN-robust?\\n\\nIn light of Proposition 1, there are two ways to proceed in order to obtain SLN-robust learners: either\\nwe change the class of losses `, or we change the function class F.\\nThe first approach has been pursued in a large body of work that embraces non-convex losses\\n[Stempfel and Ralaivola, 2009, Masnadi-Shirazi et al., 2010, Ding and Vishwanathan, 2010,\\nDenchev et al., 2012, Manwani and Sastry, 2013]. While such losses avoid the conditions of Proposition 1, this does not automatically imply that they are SLN-robust when used with Flin . In Appendix\\nB, we present evidence that some of these losses are in fact not SLN-robust when used with Flin .\\nThe second approach is to consider suitably rich F that contains the Bayes-optimal scorer for D,\\ne.g. by employing a universal kernel. With this choice, one can still use a convex potential loss, and\\nin fact, owing to Equation 2, any classification-calibrated loss.\\nProposition 2. Pick any classification-calibrated `. Then, (`, RX ) is SLN-robust.\\nBoth approaches have drawbacks. The first approach has a computational penalty, as it requires\\noptimising a non-convex loss. The second approach has a statistical penalty, as estimation rates\\nwith a rich F will require a larger sample size. Thus, it appears that SLN-robustness involves a\\ncomputational-statistical tradeoff. However, there is a variant of the first option: pick a loss that is\\nconvex, but not a convex potential. Such a loss would afford the computational and statistical advantages of minimising convex risks with linear scorers. Manwani and Sastry [2013] demonstrated\\nthat square loss, `(y, v) = (1 − yv)2 , is one such loss. We will show that there is a simpler loss that\\nis convex and SLN-robust, but is not in the class of convex potentials by virtue of being negatively\\nunbounded. To derive this loss, we first re-interpret robustness via a noise-correction procedure.\\n1\\nEven if we were content with a difference of \\x0f ∈ [0, 1/2] between the clean and corrupted minimisers’\\nperformance, Long and Servedio [2010, Theorem 2] implies that in the worst case \\x0f = 1/2.\\n\\n3\\n\\n\\x0c4\\n\\nA noise-corrected loss perspective on SLN-robustness\\n\\nWe now re-express SLN-robustness to reason about optimal scorers on the same distribution, but\\nwith two different losses. This will help characterise a set of “strongly SLN-robust” losses.\\n4.1\\n\\nReformulating SLN-robustness via noise-corrected losses\\n\\nGiven any ρ ∈ [0, 1/2), Natarajan et al. [2013, Lemma 1] showed how to associate with a loss ` a\\nD\\nnoise-corrected counterpart ` such that LD\\n` (s) = L` (s). The loss ` is defined as follows.\\nDefinition 2 (Noise-corrected loss). Given any loss ` and ρ ∈ [0, 1/2), the noise-corrected loss ` is\\n(∀y ∈ {±1}) (∀v ∈ R) `(y, v) =\\n\\n(1 − ρ) · `(y, v) − ρ · `(−y, v)\\n.\\n1 − 2ρ\\n\\n(4)\\n\\nSince ` depends on the unknown parameter ρ, it is not directly usable to design an SLN-robust\\nlearner. Nonetheless, it is a useful theoretical device, since, by construction, for any F, SD,F,∗\\n=\\n`\\nSD,F,∗\\n= SD,F,∗\\n. This means that a sufficient condition for (`, F) to be SLN-robust is for SD,F,∗\\n.\\n`\\n`\\n`\\nGhosh et al. [2015, Theorem 1] proved a sufficient condition on ` such that this holds, namely,\\n(∃C ∈ R)(∀v ∈ R) `1 (v) + `−1 (v) = C.\\n(5)\\nInterestingly, Equation 5 is necessary for a stronger notion of robustness, which we now explore.\\n4.2\\n\\nCharacterising a stronger notion of SLN-robustness\\n\\nAs the first step towards a stronger notion of robustness, we rewrite (with a slight abuse of notation)\\nLD\\n` (s) =\\n\\nE\\n\\n(X,Y)∼D\\n\\n[`(Y, s(X))] =\\n\\nE\\n\\n(Y,S)∼R(D,s)\\n\\n.\\n\\n[`(Y, S)] = L` (R(D, s)),\\n\\nwhere R(D, s) is a distribution over labels and scores. Standard SLN-robustness requires that label\\nnoise does not change the `-risk minimisers, i.e. that if s is such that L` (R(D, s)) ≤ L` (R(D, s0 ))\\nfor all s0 , the same relation holds with D in place of D. Strong SLN-robustness strengthens this\\nnotion by requiring that label noise does not affect the ordering of all pairs of joint distributions over\\nlabels and scores. (This of course trivially implies SLN-robustness.) As with the definition of D,\\ngiven a distribution R over labels and scores, let R be the corresponding distribution where labels\\nare flipped with probability ρ. Strong SLN-robustness can then be made precise as follows.\\nDefinition 3 (Strong SLN-robustness). Call a loss ` strongly SLN-robust if for every ρ ∈ [0, 1/2),\\n(∀R, R0 ) L` (R) ≤ L` (R0 ) ⇐⇒ L` (R) ≤ L` (R0 ).\\nWe now re-express strong SLN-robustness using a notion of order equivalence of loss pairs, which\\nsimply requires that two losses order all distributions over labels and scores identically.\\n˜ order equivalent if\\nDefinition 4 (Order equivalent loss pairs). Call a pair of losses (`, `)\\n(∀R, R0 ) L` (R) ≤ L` (R0 ) ⇐⇒ L`˜(R) ≤ L`˜(R0 ).\\nClearly, order equivalence of (`, `) implies SD,F,∗\\n= SD,F,∗\\n, which in turn implies SLN-robustness.\\n`\\n`\\nIt is thus not surprising that we can relate order equivalence to strong SLN-robustness of `.\\nProposition 3. A loss ` is strongly SLN-robust iff for every ρ ∈ [0, 1/2), (`, `) are order equivalent.\\nThis connection now lets us exploit a classical result in decision theory about order equivalent losses\\nbeing affine transformations of each other. Combined with the definition of `, this lets us conclude\\nthat the sufficient condition of Equation 5 is also necessary for strong SLN-robustness of `.\\nProposition 4. A loss ` is strongly SLN-robust if and only if it satisfies Equation 5.\\nWe now return to our original goal, which was to find a convex ` that is SLN-robust for Flin (and\\nideally more general function classes). The above suggests that to do so, it is reasonable to consider\\nthose losses that satisfy Equation 5. Unfortunately, it is evident that if ` is convex, non-constant, and\\nbounded below by zero, then it cannot possibly be admissible in this sense. But we now show that\\nremoving the boundedness restriction allows for the existence of a convex admissible loss.\\n4\\n\\n\\x0c5\\n\\nThe unhinged loss: a convex, strongly SLN-robust loss\\n\\nConsider the following simple, but non-standard convex loss:\\nunh\\n`unh\\n1 (v) = 1 − v and `−1 (v) = 1 + v.\\n\\nCompared to the hinge loss, the loss does not clamp at zero, i.e. it does not have a hinge. (Thus, peculiarly, it is negatively unbounded, an issue we discuss in §5.3.) Thus, we call this the unhinged loss2 .\\nThe loss has a number of attractive properties, the most immediate being is its SLN-robustness.\\n5.1\\n\\nThe unhinged loss is strongly SLN-robust\\n\\nunh\\nunh\\nSince `unh\\nis strongly SLN-robust, and thus that\\n1 (v) + `−1 (v) = 2, Proposition 4 implies that `\\nunh\\n(` , F) is SLN-robust for any F. Further, the following uniqueness property is not hard to show.\\nProposition 5. Pick any convex loss `. Then,\\n\\n(∃C ∈ R) `1 (v) + `−1 (v) = C ⇐⇒ (∃A, B, D ∈ R) `1 (v) = −A · v + B, `−1 (v) = A · v + D.\\nThat is, up to scaling and translation, `unh is the only convex loss that is strongly SLN-robust.\\nReturning to the case of linear scorers, the above implies that (`unh , Flin ) is SLN-robust. This does\\nnot contradict Proposition 1, since `unh is not a convex potential as it is negatively unbounded. Intuitively, this property allows the loss to offset the penalty incurred by instances that are misclassified\\nwith high margin by awarding a “gain” for instances that correctly classified with high margin.\\n5.2\\n\\nThe unhinged loss is classification calibrated\\n\\nSLN-robustness is by itself insufficient for a learner to be useful. For example, a loss that is uniformly zero is strongly SLN-robust, but is useless as it is not classification-calibrated. Fortunately,\\nthe unhinged loss is classification-calibrated, as we now establish. For technical reasons (see §5.3),\\nwe operate with FB = [−B, +B]X , the set of scorers with range bounded by B ∈ [0, ∞).\\nProposition 6. Fix ` = `unh . For any DM,η , B ∈ [0, ∞), S`D,FB ,∗ = {x 7→ B · sign(2η(x) − 1)}.\\nThus, for every B ∈ [0, ∞), the restricted Bayes-optimal scorer over FB has the same sign as the\\nBayes-optimal classifier for 0-1 loss. In the limiting case where F = RX , the optimal scorer is\\nattainable if we operate over the extended reals R ∪ {±∞}, so that `unh is classification-calibrated.\\n5.3\\n\\nEnforcing boundedness of the loss\\n\\nWhile the classification-calibration of `unh is encouraging, Proposition 6 implies that its (unrestricted) Bayes-risk is −∞. Thus, the regret of every non-optimal scorer s is identically +∞, which\\nhampers analysis of consistency. In orthodox decision theory, analogous theoretical issues arise\\nwhen attempting to establish basic theorems with unbounded losses [Ferguson, 1967, pg. 78].\\nWe can side-step this issue by restricting attention to bounded scorers, so that `unh is effectively\\nbounded. By Proposition 6, this does not affect the classification-calibration of the loss. In the context of linear scorers, boundedness of scorers can be achieved by regularisation:\\ninstead of work√\\ning with Flin , one can instead use Flin,λ = {x 7→ hw, xi | ||w||2 ≤ 1/ λ}, where λ > 0, so\\nthat Flin,λ ⊆ FR/√λ for R = supx∈X ||x||2 . Observe that as (`unh , F) is SLN-robust for any F,\\n(`unh , Flin,λ ) is SLN-robust for any λ > 0. As we shall see in §6.3, working with Flin,λ also lets us\\nestablish SLN-robustness of the hinge loss when λ is large.\\n5.4\\n\\nUnhinged loss minimisation on corrupted distribution is consistent\\n\\nUsing bounded scorers makes it possible to establish a surrogate regret bound for the unhinged loss.\\nThis shows classification consistency of unhinged loss minimisation on the corrupted distribution.\\n2\\nThis loss has been considered in Sriperumbudur et al. [2009], Reid and Williamson [2011] in the context\\nof maximum mean discrepancy; see the Appendix. The analysis of its SLN-robustness is to our knowledge\\nnovel.\\n\\n5\\n\\n\\x0cProposition 7. Fix ` = `unh . Then, for any D, ρ ∈ [0, 1/2), B ∈ [1, ∞), and scorer s ∈ FB ,\\n1\\nD,FB\\nregretD\\n(s) =\\n· regret`D,FB (s).\\n01 (s) ≤ regret`\\n1 − 2ρ\\nStandard rates of convergence via generalisation bounds are also trivial to derive; see the Appendix.\\n\\n6\\n\\nLearning with the unhinged loss and kernels\\n\\nWe now show that the optimal solution for the unhinged loss when employing regularisation and\\nkernelised scorers has a simple form. This sheds further light on SLN-robustness and regularisation.\\n6.1\\n\\nThe centroid classifier optimises the unhinged loss\\n\\nConsider minimising the unhinged\\nrisk over the class of kernelised scorers FH,λ = {s : x 7→\\n√\\nhw, Φ(x)iH | ||w||H ≤ 1/ λ} for some λ > 0, where Φ : X → H is a feature mapping into a\\nreproducing kernel Hilbert space H with kernel k. Equivalently, given a distribution3 D, we want\\nλ\\n∗\\nwunh,λ\\n= argmin E [1 − Y · hw, Φ(X)i] + hw, wiH .\\n(6)\\n2\\n(X,Y)∼D\\nw∈H\\nThe first-order optimality condition implies that\\n1\\n∗\\n(7)\\nwunh,λ\\n= · E [Y · Φ(X)] ,\\nλ (X,Y)∼D\\nwhich is the kernel mean map of D [Smola et al., 2007], and thus the optimal unhinged scorer is\\n\\x12\\n\\x13\\n1\\n1\\ns∗unh,λ : x 7→ · E [Y · k(X, x)] = x 7→ · π · E [k(X, x)] − (1 − π) · E [k(X, x)] .\\nX∼P\\nX∼Q\\nλ (X,Y)∼D\\nλ\\n(8)\\nFrom Equation 8, the unhinged solution is equivalent to a nearest centroid classifier [Manning et al.,\\n2008, pg. 181] [Tibshirani et al., 2002] [Shawe-Taylor and Cristianini, 2004, Section 5.1]. Equation\\n8 gives a simple way to understand the SLN-robustness of (`unh , FH,λ ), as the optimal scorers on\\nthe clean and corrupted distributions only differ by a scaling (see the Appendix):\\n\\x03\\n\\x02\\n1\\n· E\\nY · k(X, x) .\\n(9)\\n(∀x ∈ X) E [Y · k(X, x)] =\\n1 − 2ρ (X,Y)∼D\\n(X,Y)∼D\\nInterestingly, Servedio [1999, Theorem 4] established that a nearest centroid classifier (which they\\ntermed “AVERAGE ”) is robust to a general class of label noise, but required the assumption that\\nM is uniform over the unit sphere. Our result establishes that SLN robustness of the classifier\\nholds without any assumptions on M . In fact, Ghosh et al. [2015, Theorem 1] lets one quantify the\\nunhinged loss’ performance under a more general noise model; see the Appendix for discussion.\\n6.2\\n\\nPractical considerations\\n\\nWe note several points relating to practical usage of the unhinged loss with kernelised scorers. First,\\ncross-validation is not required to select λ, since changing λ only changes the magnitude of scores,\\nnot their sign. Thus, for the purposes of classification, one can simply use λ = 1.\\nSecond, we can easily extend the scorers to use a bias regularised with strength 0 < λb 6= λ. Tuning\\nλb is equivalent to computing s∗unh,λ as per Equation 8, and tuning a threshold on a holdout set.\\n∗\\nThird, when H = Rd for d small, we can store wunh,λ\\nexplicitly, and use this to make predictions.\\nFor high (or infinite) dimensional H, we can either make predictions directly via Equation 8, or\\nuse random Fourier features [Rahimi and Recht, 2007] to (approximately) embed H into some low∗\\ndimensional Rd , and then store wunh,λ\\nas usual. (The latter requires a translation-invariant kernel.)\\n∗\\nWe now show that under some assumptions, wunh,λ\\ncoincides with the solution of two established\\nmethods; the Appendix discusses some further relationships, e.g. to the maximum mean discrepancy.\\n3\\n\\nGiven a training sample S ∼ Dn , we can use plugin estimates as appropriate.\\n\\n6\\n\\n\\x0c6.3\\n\\nEquivalence to a highly regularised SVM and other convex potentials\\n\\nThere is an interesting equivalence between the unhinged solution and that of a highly regularised\\nSVM. This has been noted in e.g. Hastie et al. [2004, Section 6], which showed how SVMs approach\\na nearest centroid classifier, which is of course the optimal unhinged solution.\\nProposition 8. Pick any D and Φ : X → H with R = supx∈X ||Φ(x)||H < ∞. For any λ > 0, let\\n∗\\nwhinge,λ\\n= argmin\\nw∈H\\n\\nE\\n\\n(X,Y)∼D\\n\\n[max(0, 1 − Y · hw, Φ(x)iH )] +\\n\\nλ\\nhw, wiH\\n2\\n\\n∗\\n∗\\nbe the soft-margin SVM solution. Then, if λ ≥ R2 , whinge,λ\\n= wunh,λ\\n.\\n\\nSince (`unh , FH,λ ) is SLN-robust, it follows that for `hinge : (y, v) 7→ max(0, 1−yv), (`hinge , FH,λ )\\nis similarly SLN-robust provided λ is sufficiently large. That is, strong `2 regularisation (and a\\nbounded feature map) endows the hinge loss with SLN-robustness4 . Proposition 8 can be generalised\\n∗\\nto show that wunh,λ\\nis the limiting solution of any twice differentiable convex potential. This shows\\nthat strong `2 regularisation endows most learners with SLN-robustness. Intuitively, with strong\\nregularisation, one only considers the behaviour of a loss near zero; since a convex potential φ has\\nφ0 (0) < 0, it will behave similarly to its linear approximation around zero, viz. the unhinged loss.\\nProposition 9. Pick any D, bounded feature mapping Φ : X → H, and twice differentiable convex\\n∗\\npotential φ with φ00 ([−1, 1]) bounded. Let wφ,λ\\nbe the minimiser of the regularised φ risk. Then,\\n\\x0c\\x0c\\n\\x0c\\x0c2\\n∗\\n\\x0c\\x0c w ∗\\n\\x0c\\x0c\\nwunh,λ\\n\\x0c\\x0c\\n\\x0c\\x0c\\nφ,λ\\nlim \\x0c\\x0c ∗\\n−\\n\\x0c\\x0c = 0.\\n∗\\nλ→∞ \\x0c\\x0c ||wφ,λ ||H\\n||wunh,λ\\n||H \\x0c\\x0c\\nH\\n\\n6.4\\n\\nEquivalence to Fisher Linear Discriminant with whitened data\\n\\nFor binary classification on DM,η , the Fisher Linear Discriminant (FLD) finds a weight vector proportional to the minimiser of square loss `sq : (y, v) 7→ (1 − yv)2 [Bishop, 2006, Section 4.1.5],\\n∗\\nwsq,λ\\n= (EX∼M [XXT ] + λI)−1 · E(X,Y)∼D [Y · X].\\n\\n(10)\\n\\n∗\\nwsq,λ\\n\\nis only changed by a scaling\\nBy Equation 9, and the fact that the corrupted marginal M = M ,\\nfactor under label noise. This provides an alternate proof of the fact that (`sq , Flin ) is SLN-robust5\\n∗\\n[Manwani and Sastry, 2013, Theorem 2]. Clearly, the unhinged loss solution wunh,λ\\nis equivalent to\\n\\x02 T\\x03\\n∗\\nthe FLD and square loss solution wsq,λ when the input data is whitened i.e. E XX = I. With\\nX∼M\\n\\na well-specified F, e.g. with a universal kernel, both the unhinged and square loss asymptotically\\nrecover the optimal classifier, but the unhinged loss does not require a matrix inversion. With a\\nmisspecified F, one cannot in general argue for the superiority of the unhinged loss over square loss,\\nor vice-versa, as there is no universally good surrogate to the 0-1 loss [Reid and Williamson, 2010,\\nAppendix A]; the Appendix illustrate examples where both losses may underperform.\\n\\n7\\n\\nSLN-robustness of unhinged loss: empirical illustration\\n\\nWe now illustrate that the unhinged loss’ SLN-robustness is empirically manifest. We reiterate\\nthat with high regularisation, the unhinged solution is equivalent to an SVM (and in the limit any\\nclassification-calibrated loss) solution. Thus, we do not aim to assert that the unhinged loss is\\n“better” than other losses, but rather, to demonstrate that its SLN-robustness is not purely theoretical.\\nWe first show that the unhinged risk minimiser performs well on the example of Long\\nand Servedio [2010] (henceforth LS10). Figure 1 shows the distribution D, where X =\\n{(1, 0), (γ, 5γ), (γ, −γ)} ⊂ R2 , with marginal distribution M = { 14 , 14 , 12 } and all three instances\\nare deterministically positive. We pick γ = 1/2. The unhinged minimiser perfectly classifies all\\nthree points, regardless of the level of label noise (Figure 1). The hinge minimiser is perfect when\\nthere is no noise, but with even a small amount of noise, achieves a 50% error rate.\\n4\\n5\\n\\nLong and Servedio [2010, Section 6] show that `1 regularisation does not endow SLN-robustness.\\nSquare loss escapes the result of Long and Servedio [2010] since it is not monotone decreasing.\\n\\n7\\n\\n\\x0c1\\n\\nUnhinged\\nHinge 0% noise\\nHinge 1% noise\\n\\n0.5\\n\\n0.5\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n1\\n\\n−0.5\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\nHinge\\n\\nt-logistic\\n\\nUnhinged\\n\\n0.00 ± 0.00\\n0.15 ± 0.27\\n0.21 ± 0.30\\n0.38 ± 0.37\\n0.42 ± 0.36\\n0.47 ± 0.38\\n\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.22 ± 0.08\\n0.22 ± 0.08\\n0.39 ± 0.23\\n\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.34 ± 0.48\\n\\nTable 1: Mean and standard deviation of the 01 error over 125 trials on LS10. Grayed cells\\ndenote the best performer at that noise rate.\\n\\n−1\\n\\nFigure 1: LS10 dataset.\\n\\nWe next consider empirical risk minimisers from a random training sample: we construct a training\\nset of 800 instances, injected with varying levels of label noise, and evaluate classification performance on a test set of 1000 instances. We compare the hinge, t-logistic (for t = 2) [Ding and\\nVishwanathan, 2010] and unhinged minimisers using a linear scorer without a bias term, and regularisation strength λ = 10−16 . From Table 1, even at 40% label noise, the unhinged classifier is able\\nto find a perfect solution. By contrast, both other losses suffer at even moderate noise rates.\\nWe next report results on some UCI datasets, where we additionally tune a threshold so as to ensure\\nthe best training set 0-1 accuracy. Table 2 summarises results on a sample of four datasets. (The\\nAppendix contains results with more datasets, performance metrics, and losses.) Even at noise close\\nto 50%, the unhinged loss is often able to learn a classifier with some discriminative power.\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\nHinge\\n\\nt-Logistic\\n\\nUnhinged\\n\\n0.00 ± 0.00\\n0.01 ± 0.03\\n0.06 ± 0.12\\n0.17 ± 0.20\\n0.35 ± 0.24\\n0.60 ± 0.20\\n\\n0.00 ± 0.00\\n0.01 ± 0.03\\n0.04 ± 0.05\\n0.09 ± 0.11\\n0.24 ± 0.16\\n0.49 ± 0.20\\n\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.01\\n0.02 ± 0.07\\n0.13 ± 0.22\\n0.45 ± 0.33\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\nHinge\\n\\nt-Logistic\\n\\nUnhinged\\n\\n0.05 ± 0.00\\n0.06 ± 0.01\\n0.06 ± 0.01\\n0.08 ± 0.04\\n0.14 ± 0.10\\n0.45 ± 0.26\\n\\n0.05 ± 0.00\\n0.07 ± 0.02\\n0.08 ± 0.03\\n0.11 ± 0.05\\n0.24 ± 0.13\\n0.49 ± 0.16\\n\\n0.05 ± 0.00\\n0.05 ± 0.00\\n0.05 ± 0.00\\n0.05 ± 0.01\\n0.09 ± 0.10\\n0.46 ± 0.30\\n\\n(a) iris.\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\n(b) housing.\\n\\nHinge\\n\\nt-Logistic\\n\\nUnhinged\\n\\n0.00 ± 0.00\\n0.10 ± 0.08\\n0.19 ± 0.11\\n0.31 ± 0.13\\n0.39 ± 0.13\\n0.50 ± 0.16\\n\\n0.00 ± 0.00\\n0.11 ± 0.02\\n0.15 ± 0.02\\n0.22 ± 0.03\\n0.33 ± 0.04\\n0.48 ± 0.04\\n\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.00 ± 0.00\\n0.01 ± 0.00\\n0.02 ± 0.02\\n0.34 ± 0.21\\n\\nρ\\nρ\\nρ\\nρ\\nρ\\nρ\\n\\n(c) usps0v7.\\n\\n=\\n=\\n=\\n=\\n=\\n=\\n\\n0\\n0.1\\n0.2\\n0.3\\n0.4\\n0.49\\n\\nHinge\\n\\nt-Logistic\\n\\nUnhinged\\n\\n0.05 ± 0.00\\n0.15 ± 0.03\\n0.21 ± 0.03\\n0.25 ± 0.03\\n0.31 ± 0.05\\n0.48 ± 0.09\\n\\n0.04 ± 0.00\\n0.24 ± 0.00\\n0.24 ± 0.00\\n0.24 ± 0.00\\n0.24 ± 0.00\\n0.40 ± 0.24\\n\\n0.19 ± 0.00\\n0.19 ± 0.01\\n0.19 ± 0.01\\n0.19 ± 0.03\\n0.22 ± 0.05\\n0.45 ± 0.08\\n\\n(d) splice.\\n\\nTable 2: Mean and standard deviation of the 0-1 error over 125 trials on UCI datasets.\\n\\n8\\n\\nConclusion and future work\\n\\nWe proposed a convex, classification-calibrated loss, proved that is robust to symmetric label noise\\n(SLN-robust), showed it is the unique loss that satisfies a notion of strong SLN-robustness, established that it is optimised by the nearest centroid classifier, and showed that most convex potentials,\\nsuch as the SVM, are also SLN-robust when highly regularised. So, with apologies to Wilde [1895]:\\nWhile the truth is rarely pure, it can be simple.\\nAcknowledgments\\nNICTA is funded by the Australian Government through the Department of Communications and\\nthe Australian Research Council through the ICT Centre of Excellence Program. The authors thank\\nCheng Soon Ong for valuable comments on a draft of this paper.\\n8\\n\\n\\x0cReferences\\nDana Angluin and Philip Laird. Learning from noisy examples. Machine Learning, 2(4):343–370, 1988.\\nPeter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Convexity, classification, and risk bounds. Journal\\nof the American Statistical Association, 101(473):138 – 156, 2006.\\nChristopher M Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., 2006.\\nAvrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In Conference on\\nComputational Learning Theory (COLT), pages 92–100, 1998.\\nVasil Denchev, Nan Ding, Hartmut Neven, and S.V.N. Vishwanathan. Robust classification with adiabatic\\nquantum optimization. In International Conference on Machine Learning (ICML), pages 863–870, 2012.\\nLuc Devroye, László Györfi, and Gábor Lugosi. A Probabilistic Theory of Pattern Recognition. Springer, 1996.\\nNan Ding and S.V.N. Vishwanathan. t-logistic regression. In Advances in Neural Information Processing\\nSystems (NIPS), pages 514–522. Curran Associates, Inc., 2010.\\nThomas S. Ferguson. Mathematical Statistics: A Decision Theoretic Approach. Academic Press, 1967.\\nAritra Ghosh, Naresh Manwani, and P. S. Sastry. Making risk minimization tolerant to label noise. Neurocomputing, 160:93 – 107, 2015.\\nTrevor Hastie, Saharon Rosset, Robert Tibshirani, and Ji Zhu. The entire regularization path for the support\\nvector machine. Journal of Machine Learning Research, 5:1391–1415, December 2004. ISSN 1532-4435.\\nMichael Kearns. Efficient noise-tolerant learning from statistical queries. Journal of the ACM, 5(6):392–401,\\nNovember 1998.\\nPhilip M. Long and Rocco A. Servedio. Random classification noise defeats all convex potential boosters.\\nMachine Learning, 78(3):287–304, 2010. ISSN 0885-6125.\\nChristopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze. Introduction to Information Retrieval.\\nCambridge University Press, New York, NY, USA, 2008. ISBN 0521865719, 9780521865715.\\nNaresh Manwani and P. S. Sastry. Noise tolerance under risk minimization. IEEE Transactions on Cybernetics,\\n43(3):1146–1151, June 2013.\\nHamed Masnadi-Shirazi, Vijay Mahadevan, and Nuno Vasconcelos. On the design of robust classifiers for\\ncomputer vision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010.\\nNagarajan Natarajan, Inderjit S. Dhillon, Pradeep D. Ravikumar, and Ambuj Tewari. Learning with noisy\\nlabels. In Advances in Neural Information Processing Systems (NIPS), pages 1196–1204, 2013.\\nAli Rahimi and Benjamin Recht. Random features for large-scale kernel machines. In Advances in Neural\\nInformation Processing Systems (NIPS), pages 1177–1184, 2007.\\nMark D. Reid and Robert C. Williamson. Composite binary losses. Journal of Machine Learning Research,\\n11:2387–2422, December 2010.\\nMark D Reid and Robert C Williamson. Information, divergence and risk for binary experiments. Journal of\\nMachine Learning Research, 12:731–817, Mar 2011.\\nBernhard Schölkopf and Alexander J Smola. Learning with kernels, volume 129. MIT Press, 2002.\\nRocco A. Servedio. On PAC learning using Winnow, Perceptron, and a Perceptron-like algorithm. In Conference on Computational Learning Theory (COLT), 1999.\\nJohn Shawe-Taylor and Nello Cristianini. Kernel Methods for Pattern Analysis. Cambridge Uni. Press, 2004.\\nAlex Smola, Arthur Gretton, Le Song, and Bernhard Schölkopf. A Hilbert space embedding for distributions.\\nIn Algorithmic Learning Theory (ALT), 2007.\\nBharath K. Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Gert R. G. Lanckriet, and Bernhard Schölkopf.\\nKernel choice and classifiability for RKHS embeddings of probability distributions. In Advances in Neural\\nInformation Processing Systems (NIPS), 2009.\\nGuillaume Stempfel and Liva Ralaivola. Learning SVMs from sloppily labeled data. In Artificial Neural\\nNetworks (ICANN), volume 5768, pages 884–893. Springer Berlin Heidelberg, 2009.\\nRobert Tibshirani, Trevor Hastie, Balasubramanian Narasimhan, and Gilbert Chu. Diagnosis of multiple cancer\\ntypes by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences, 99(10):\\n6567–6572, 2002.\\nOscar Wilde. The Importance of Being Earnest, 1895.\\n\\n9\\n\\n\\x0c'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "365398b9b4072a8c5bf3c8de0067122e70fff748",
        "_cell_guid": "7364c06e-8044-4da4-9b50-4daa5bf5765e",
        "id": "OYeZKng1ePPz",
        "colab_type": "text"
      },
      "source": [
        "## Primeiro pré-processar deixando todo em minuscula e tokenizar o texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn-4I7gqV5xk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "18d25fb5-a48b-4f31-a6a2-ed6a9174d638"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f10f622826eaa4e9bd97c1414aac5538ddabafd2",
        "_cell_guid": "125f9eb3-99d9-422a-8242-384da62d43dd",
        "id": "_jFrxinGePPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "def docs_preprocessor(docs):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    for idx in range(len(docs)):\n",
        "        docs[idx] = str(docs[idx]).lower()  # Convert to lowercase.\n",
        "        docs[idx] = tokenizer.tokenize(docs[idx])  # Split into words.\n",
        "\n",
        "    # Remove numbers, but not words that contain numbers.\n",
        "    docs = [[token for token in doc if not token.isdigit()] for doc in docs]\n",
        "    \n",
        "    # Remove words that are only one character.\n",
        "    docs = [[token for token in doc if len(token) > 3] for doc in docs]\n",
        "    \n",
        "    # Lemmatize all words in documents.\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]\n",
        "  \n",
        "    return docs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "790063fc1a341eb17e0244c220de736d51196cfe",
        "_cell_guid": "c87ebee3-e88b-4233-9000-b71103f281c3",
        "id": "XuXIp0hWePP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs = docs_preprocessor(docs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f649c357b776963b7e626064fa6ced1a03a3219d",
        "_cell_guid": "b167c49c-6187-4921-9d2b-2fa1ba8377a4",
        "id": "-GZlfsohePP4",
        "colab_type": "text"
      },
      "source": [
        "### **Computar bigramas e trigramas :**\n",
        "Sine tópicos são muito semelhantes, o que os faria distingui-los são frases ao invés de palavras únicas / individuais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d6ce91b0d51d55e3504cbb352f0548cffcdb0169",
        "_cell_guid": "66b3e9bf-1c76-4ee1-bb22-60405308c401",
        "id": "PeYS98CfePP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "84b2b9d7-32a6-4e05-a444-4ce1a223359d"
      },
      "source": [
        "from gensim.models import Phrases\n",
        "# Add bigrams and trigrams to docs (only ones that appear 10 times or more).\n",
        "bigram = Phrases(docs, min_count=10)\n",
        "trigram = Phrases(bigram[docs])\n",
        "\n",
        "for idx in range(len(docs)):\n",
        "    for token in bigram[docs[idx]]:\n",
        "        if '_' in token:\n",
        "            # Token is a bigram, add to document.\n",
        "            docs[idx].append(token)\n",
        "    for token in trigram[docs[idx]]:\n",
        "        if '_' in token:\n",
        "            # Token is a bigram, add to document.\n",
        "            docs[idx].append(token)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2bUTDbpOfpL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abe89b03-6d74-4ef4-e0db-0bbcd593efee"
      },
      "source": [
        "print(bigram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Phrases<556123 vocab, min_count=10, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWzohYYpOydW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b4d8972-5d8a-4810-b689-702ae3a7ba1e"
      },
      "source": [
        "print(trigram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Phrases<616916 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "c75a2e62b9a0e570a0a34b84af5912c22aa9ba28",
        "_cell_guid": "b9849dae-b405-4bc6-ab61-c062f2a13746",
        "id": "GXcCXaDSePP7",
        "colab_type": "text"
      },
      "source": [
        "### Remover Tokens comuns e pouco comuns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "73f7ba9fedcde10c4e70cf2456c7ef20c8e32d35",
        "_cell_guid": "df440d67-082a-4b2d-a6fb-80029af194b5",
        "id": "qRe_v6O5ePP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "64fc11e5-93c0-4a2f-94cd-4ffee2966307"
      },
      "source": [
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Create a dictionary representation of the documents.\n",
        "dictionary = Dictionary(docs)\n",
        "print('Number of unique words in initital documents:', len(dictionary))\n",
        "\n",
        "# Filter out words that occur less than 10 documents, or more than 20% of the documents.\n",
        "dictionary.filter_extremes(no_below=10, no_above=0.2)\n",
        "print('Number of unique words after removing rare and common words:', len(dictionary))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique words in initital documents: 39534\n",
            "Number of unique words after removing rare and common words: 6001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f5e4e52fe4ff798ac96f8f23538770c5cc4d217a",
        "_cell_guid": "ac2ede6e-8815-4da1-a739-1ffc71614cb9",
        "id": "1KLQtDWtePP-",
        "colab_type": "text"
      },
      "source": [
        "Eliminando as palavras comuns e raras, acabamos com apenas cerca de 6% das palavras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "78cd228789c6fa5d094886b58dce875f63625c33",
        "_cell_guid": "0e6a6363-b43f-45f0-80d9-0f5b5b9462fc",
        "id": "5tkGL0wBePP-",
        "colab_type": "text"
      },
      "source": [
        "** Vetorizar dados: **\n",
        "A primeira etapa é obter uma representação por trás das palavras de cada documento.\n",
        "Passos\n",
        "1-converter um corpus\n",
        "doc2bow:converter documento (uma lista de palavras) no formato de saco de palavras = lista de (token_id, token_count) 2-tuplas. Cada palavra é considerada uma string tokenizada e normalizada (codificada em unicode ou em utf8). Nenhum outro pré-processamento é feito nas palavras do documento; aplique tokenização, lematização etc. antes de chamar esse método.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "27e71950ec4bca8f6b62ec6d6cd9f613a50019ea",
        "_cell_guid": "ca1d1e18-2939-4880-bca7-712d4bc42735",
        "id": "JGXwd5TZePP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [dictionary.doc2bow(doc) for doc in docs]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "80752c24b3b1bab16b48054a6ca6e7fb84d49372",
        "_cell_guid": "ad5717c6-b2e8-4122-8c7d-b5bca9dfb1ab",
        "id": "2gY7iFHjePQB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8f7d53f5-edbc-4451-838f-6ee199b022b6"
      },
      "source": [
        "print('Number of unique tokens: %d' % len(dictionary))\n",
        "print('Number of documents: %d' % len(corpus))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique tokens: 6001\n",
            "Number of documents: 403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "bb7f095fc6b213d727b36798294d56a6ab950f5b",
        "_cell_guid": "a0a1a95d-8ed7-47a1-a1b0-0471a77e9af0",
        "id": "hBlY7rrUePQD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Com o corpus de bag of words, podemos prosseguir para aprender nosso modelo de tópico a partir dos documentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "49a8f93233d2640b476e093390182e21102ae555",
        "_cell_guid": "ff8fbb06-d7f2-4170-b91c-151e3c5c9cad",
        "id": "No58jWGgePQD",
        "colab_type": "text"
      },
      "source": [
        "# Entrenando LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b11f495c4fcf6991c523d5a3b6669506f39533ee",
        "_cell_guid": "f15e826a-f41b-410a-9ff9-ef19edc05085",
        "id": "Fb1p3x-MePQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import LdaModel"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "084c1198f0e528c52edc746436d797c855de8c51",
        "_cell_guid": "5f8f0fa0-b911-4043-af2c-ec311384d7a5",
        "id": "0NNGy2ZmePQF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e54759c8-ab4d-4e59-f9d3-86b51cfbc962"
      },
      "source": [
        "# Set training parameters.\n",
        "num_topics = 4\n",
        "chunksize = 500 # size of the doc looked at every pass\n",
        "passes = 20 # number of passes through documents\n",
        "iterations = 400\n",
        "eval_every = 1  # Don't evaluate model perplexity, takes too much time.\n",
        "\n",
        "# Make a index to word dictionary.\n",
        "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
        "id2word = dictionary.id2token\n",
        "\n",
        "%time model = LdaModel(corpus=corpus, id2word=id2word, chunksize=chunksize, \\\n",
        "                       alpha='auto', eta='auto', \\\n",
        "                       iterations=iterations, num_topics=num_topics, \\\n",
        "                       passes=passes, eval_every=eval_every)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 35.6 s, sys: 14.7 ms, total: 35.6 s\n",
            "Wall time: 35.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "f5f7c3e213b2fdffa3c767ebd5a1eb7631e76b13",
        "_cell_guid": "93191a68-99d9-4b7d-88b2-5b75e3f44b1d",
        "id": "-nUU7q-OePQI",
        "colab_type": "text"
      },
      "source": [
        "# Como escolher a quantidade de tópicos?\n",
        "__LDA__ é uma técnica não supervisionada, o que significa que não sabemos antes de executar o modelo quantos tópicos existem em nosso corpus. A coerência do tópico é uma das principais técnicas utilizadas para desestimar o número de tópicos. Você pode ler sobre isso [aqui.] (Http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf)\n",
        "\n",
        "No entanto, usei a ferramenta de visualização LDA ** pyLDAvis **, tentei alguns tópicos e comparei os resultados. Quatro pareciam ser o número ideal de tópicos que separariam mais os tópicos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2lTDTQkGhaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "1a1d3531-23e5-4568-bce3-e4940304dcf8"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.35.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.0.5)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 18.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (20.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (49.6.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Building wheels for collected packages: pyLDAvis, funcy\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=aad01083a6e9e8bbcc6fe87112c96226cb0b22adfb79bc2d21651307d8d855f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=18091c0f28387428998261219458dcc36f8f71e1e6781c92453098db2e6cf435\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "Successfully built pyLDAvis funcy\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.14 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7e100266faefe67e6ce1131fa464c78630293984",
        "_cell_guid": "8b9015bc-0e3d-4ee9-9d79-92f2d9dba89f",
        "id": "4fk6tS_cePQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyLDAvis.gensim\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f195b367d556a559c4db98446e9c9148758a95f6",
        "_cell_guid": "483a506d-d21b-4219-948d-87ae641b04ab",
        "id": "wCAN5DPxePQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "3e0c15fa-3592-4cfe-8547-57350001ad85"
      },
      "source": [
        "pyLDAvis.gensim.prepare(model, corpus, dictionary)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1021399098441442008286400133\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1021399098441442008286400133_data = {\"mdsDat\": {\"x\": [-0.13050008920133913, 0.005060620236909095, 0.17901433596336497, -0.05357486699893503], \"y\": [-0.09443564477449488, 0.043571728758738375, -0.0422174906595883, 0.09308140667534485], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [32.010581970214844, 25.28189468383789, 22.83439826965332, 19.873125076293945]}, \"tinfo\": {\"Term\": [\"regret\", \"gaussian_process\", \"convolutional\", \"convergence_rate\", \"submodular\", \"vertex\", \"matrix_completion\", \"random_walk\", \"fully_connected\", \"recurrent_neural\", \"recurrent\", \"lstm\", \"deep_learning\", \"active_learning\", \"hidden_layer\", \"bandit\", \"rank_matrix\", \"submodular_function\", \"hidden_unit\", \"convolutional_neural\", \"policy\", \"during_training\", \"variational_inference\", \"strongly_convex\", \"regret_bound\", \"trajectory\", \"pixel\", \"greedy\", \"greedy_algorithm\", \"polynomial_time\", \"strongly_convex\", \"primal_dual\", \"regret_bound\", \"strong_convexity\", \"linear_convergence\", \"dual_variable\", \"bandit_problem\", \"linear_measurement\", \"current_iterate\", \"stochastic_dual\", \"convergence_analysis\", \"additive_error\", \"richta_taka\", \"rakhlin\", \"closed_convex\", \"restricted_strong\", \"matrix_completion\", \"accelerated_gradient\", \"bubeck\", \"regret_minimization\", \"multiarmed_bandit\", \"richta\", \"minimizing_composite\", \"dual_norm\", \"regret\", \"fischer_finite\", \"absolute_constant\", \"bubeck_cesa\", \"stochastic_dual_coordinate_ascent\", \"proximal_operator\", \"convergence_rate\", \"lipschitz_constant\", \"primal\", \"convex_programming\", \"spectral_norm\", \"bianchi\", \"cesa\", \"bandit\", \"lipschitz\", \"rank_matrix\", \"coordinate_descent\", \"rate_convergence\", \"nuclear_norm\", \"iteration_complexity\", \"smooth_convex\", \"singular_value\", \"player\", \"lasso\", \"multi_armed\", \"regularization_parameter\", \"rank_approximation\", \"nonconvex\", \"step_size\", \"singular\", \"completion\", \"proximal\", \"gradient_descent\", \"sample_complexity\", \"game\", \"online_learning\", \"probability_least\", \"estimation_error\", \"round\", \"least_square\", \"sample_size\", \"logistic_regression\", \"empirical_risk\", \"covariance_matrix\", \"recovery\", \"bayesian_nonparametric\", \"posterior_predictive\", \"linear_dynamical\", \"squared_exponential\", \"covariance_function\", \"variational_distribution\", \"firing\", \"optimal_control\", \"titsias\", \"black_variational\", \"spiking\", \"predictive_distribution\", \"gaussian_approximation\", \"marginal_likelihood\", \"latent_state\", \"reward_function\", \"mackay\", \"variational_parameter\", \"gaussian_process\", \"rasmussen\", \"bootstrap\", \"dirichlet_process\", \"calibration\", \"true_posterior\", \"variational_posterior\", \"joint_posterior\", \"quadrature\", \"stochastic_variational\", \"spike\", \"kalman\", \"trajectory\", \"posterior_mean\", \"posterior_distribution\", \"active_learning\", \"hamiltonian_monte\", \"particle\", \"disease\", \"policy\", \"approximate_posterior\", \"bayesian_inference\", \"reinforcement_learning\", \"point_process\", \"mixture_model\", \"mcmc\", \"variational_inference\", \"hidden_markov\", \"sampler\", \"mean_field\", \"state_space\", \"neuron\", \"activity\", \"manifold\", \"latent_space\", \"population\", \"markov_chain\", \"covariance_matrix\", \"environment\", \"reward\", \"probability_measure\", \"generative_model\", \"trial\", \"time_step\", \"query\", \"time_series\", \"stochastic_optimization\", \"lstm\", \"semantic_segmentation\", \"convolutional_layer\", \"pooling_layer\", \"convolutional_network\", \"convolutional\", \"cnns\", \"very_deep\", \"visual_recognition\", \"encoder_decoder\", \"object_recognition\", \"image_caption\", \"input_image\", \"softmax_layer\", \"convnets\", \"lstms\", \"fully_convolutional\", \"recurrent_convolutional\", \"rnns\", \"patch\", \"during_training\", \"convolutional_neural\", \"visual_semantic\", \"object_detection\", \"fine_tuning\", \"natural_scene\", \"input_sequence\", \"convnet\", \"convolutional_architecture\", \"deep_convolutional_neural_network\", \"recurrent_neural\", \"deep_network\", \"encoder\", \"texture\", \"deep_convolutional\", \"machine_translation\", \"lstm_lstm\", \"sentence\", \"fully_connected\", \"hidden_layer\", \"decoder\", \"autoencoder\", \"recurrent\", \"stack\", \"pixel\", \"deep_learning\", \"feature_map\", \"hidden_unit\", \"scene\", \"segmentation\", \"speech_recognition\", \"unlabeled_data\", \"deep_neural\", \"pooling\", \"natural_image\", \"embedding\", \"semi_supervised\", \"frame\", \"spatial\", \"proposal\", \"answer\", \"generative_model\", \"ground_truth\", \"input_output\", \"filter\", \"submodular\", \"maximizing_submodular\", \"submodular_function\", \"submodularity\", \"lifted\", \"maximum_degree\", \"maximizing_spread\", \"vertex_edge\", \"bipartite_graph\", \"kempe\", \"submodular_maximization\", \"newman\", \"number_topic\", \"wolsey\", \"relational\", \"market\", \"kempe_kleinberg\", \"influence_through\", \"hamming_distance\", \"security\", \"multilabel\", \"bilmes\", \"weighted_graph\", \"true_false\", \"equivalence_class\", \"edge_weight\", \"predicate\", \"hamming\", \"vertex\", \"lattice\", \"walk\", \"belief_propagation\", \"greedy_algorithm\", \"random_walk\", \"directed_edge\", \"topic_model\", \"clique\", \"polynomial_time\", \"normalization_constant\", \"bayesian_network\", \"parent\", \"causal\", \"partition_function\", \"greedy\", \"community\", \"approximation_guarantee\", \"symmetry\", \"gibbs_sampling\", \"multi_label\", \"cover\", \"tensor\", \"document\", \"graphical_model\", \"social_network\", \"decision_making\", \"data_set\", \"running_time\", \"belief\", \"gibbs\", \"agent\", \"markov_chain\", \"item\"], \"Freq\": [1186.0, 899.0, 653.0, 935.0, 583.0, 655.0, 733.0, 619.0, 577.0, 527.0, 562.0, 467.0, 597.0, 650.0, 487.0, 684.0, 701.0, 386.0, 534.0, 415.0, 665.0, 396.0, 791.0, 484.0, 482.0, 511.0, 440.0, 569.0, 413.0, 422.0, 483.1732177734375, 279.12432861328125, 481.1567687988281, 212.97657775878906, 244.24427795410156, 154.42970275878906, 268.6690368652344, 118.01429748535156, 54.816139221191406, 63.4420051574707, 177.93943786621094, 66.31351470947266, 43.3080940246582, 48.11116409301758, 89.21391296386719, 77.76243591308594, 723.2676391601562, 63.40198516845703, 65.30987548828125, 69.0493392944336, 42.351318359375, 33.71861267089844, 31.79560089111328, 106.1549072265625, 1165.709228515625, 31.801427841186523, 68.93856048583984, 26.99940299987793, 31.801464080810547, 103.0302734375, 911.9426879882812, 170.99440002441406, 250.71214294433594, 111.52750396728516, 209.431396484375, 85.93492889404297, 85.92767333984375, 657.0778198242188, 272.0047302246094, 665.6982421875, 300.1363220214844, 372.9256286621094, 353.9851989746094, 145.96484375, 119.52672576904297, 536.2261352539062, 343.3260498046875, 295.57464599609375, 289.39434814453125, 456.9123840332031, 309.35467529296875, 151.19985961914062, 716.1800537109375, 282.5200500488281, 312.16290283203125, 273.4520263671875, 604.5862426757812, 691.8226318359375, 441.6802062988281, 453.65826416015625, 473.1883239746094, 334.3885498046875, 374.5299072265625, 352.3941345214844, 376.7281799316406, 367.7575988769531, 298.7283630371094, 324.4904479980469, 302.3013610839844, 106.83811950683594, 84.13804626464844, 107.45323181152344, 56.891292572021484, 51.192779541015625, 73.3279800415039, 107.8379135131836, 209.44482421875, 22.887102127075195, 42.52433395385742, 75.86161804199219, 158.89625549316406, 57.916046142578125, 300.2709655761719, 177.22406005859375, 392.7463073730469, 16.24822998046875, 52.227901458740234, 859.228271484375, 44.71637725830078, 31.018211364746094, 127.63176727294922, 146.6846466064453, 169.48875427246094, 20.804561614990234, 10.549809455871582, 50.85269546508789, 149.5764923095703, 163.04383850097656, 39.451934814453125, 472.2003479003906, 203.17401123046875, 428.74029541015625, 584.6573486328125, 128.4302520751953, 197.58497619628906, 159.50637817382812, 568.308837890625, 192.46287536621094, 291.0505676269531, 370.53948974609375, 171.17869567871094, 296.25543212890625, 317.6089172363281, 619.7489013671875, 237.57020568847656, 307.03460693359375, 273.8612060546875, 387.2473449707031, 362.73455810546875, 183.75827026367188, 222.5462188720703, 185.16444396972656, 270.4834289550781, 402.2549743652344, 358.49957275390625, 216.7544403076172, 282.53009033203125, 202.28778076171875, 299.3824157714844, 206.9526824951172, 230.6833038330078, 225.0167694091797, 214.43739318847656, 212.97535705566406, 465.1199645996094, 153.4070587158203, 196.09388732910156, 108.83727264404297, 326.4625549316406, 648.0078735351562, 95.83032989501953, 98.6229019165039, 106.03181457519531, 119.94076538085938, 142.1380615234375, 78.18170928955078, 78.18492889404297, 58.67527389526367, 60.53914260864258, 94.85179901123047, 53.10213851928711, 67.04484558105469, 81.84444427490234, 185.95469665527344, 391.452392578125, 409.8846435546875, 47.53337097167969, 249.05494689941406, 61.43312072753906, 55.88132858276367, 49.391971588134766, 44.73971939086914, 63.2536735534668, 49.3825798034668, 515.5343017578125, 320.2176513671875, 206.435546875, 199.48973083496094, 237.600830078125, 190.94688415527344, 88.94142150878906, 334.3701477050781, 550.83837890625, 465.2464904785156, 158.44688415527344, 114.38031768798828, 531.1038208007812, 186.8873748779297, 411.92938232421875, 542.4423217773438, 285.16180419921875, 474.18231201171875, 177.62158203125, 383.0126647949219, 214.53700256347656, 245.5813446044922, 294.958740234375, 205.89395141601562, 235.51220703125, 457.5293273925781, 344.7244873046875, 277.5755615234375, 293.370361328125, 375.138671875, 275.1521911621094, 405.5887145996094, 404.8808898925781, 230.09494018554688, 232.86749267578125, 573.3421020507812, 68.97181701660156, 377.7637939453125, 87.54094696044922, 205.13795471191406, 99.63260650634766, 34.49448013305664, 66.31985473632812, 166.71026611328125, 15.481759071350098, 123.2187271118164, 12.61255168914795, 33.87955093383789, 12.58177375793457, 64.09812927246094, 264.7193908691406, 9.705058097839355, 9.705049514770508, 137.43167114257812, 31.547582626342773, 120.79793548583984, 39.37742614746094, 84.09808349609375, 43.72743606567383, 203.76039123535156, 101.8570785522461, 93.10738372802734, 93.52008819580078, 597.9073486328125, 36.21799850463867, 289.68408203125, 187.57296752929688, 365.1163024902344, 540.5523071289062, 118.9691390991211, 355.219970703125, 115.81893157958984, 360.72235107421875, 88.1700668334961, 302.86187744140625, 204.39114379882812, 276.3385314941406, 261.3211669921875, 439.10357666015625, 217.94085693359375, 176.41407775878906, 176.8723602294922, 320.8227844238281, 248.2030487060547, 279.1009826660156, 416.54754638671875, 340.8918762207031, 441.5963439941406, 182.02391052246094, 200.38055419921875, 367.9274597167969, 337.9291076660156, 229.8668212890625, 226.65750122070312, 209.41448974609375, 222.09133911132812, 204.26165771484375], \"Total\": [1186.0, 899.0, 653.0, 935.0, 583.0, 655.0, 733.0, 619.0, 577.0, 527.0, 562.0, 467.0, 597.0, 650.0, 487.0, 684.0, 701.0, 386.0, 534.0, 415.0, 665.0, 396.0, 791.0, 484.0, 482.0, 511.0, 440.0, 569.0, 413.0, 422.0, 484.80340576171875, 280.1445617675781, 482.9358215332031, 214.07240295410156, 246.12208557128906, 155.69554138183594, 271.3531494140625, 119.19481658935547, 55.41728973388672, 64.18328094482422, 180.03173828125, 67.10198974609375, 43.892852783203125, 48.77687454223633, 90.455322265625, 78.8525390625, 733.6663208007812, 64.31358337402344, 66.25577545166016, 70.12340545654297, 43.02052688598633, 34.28901672363281, 32.34440231323242, 108.01676177978516, 1186.79833984375, 32.37842559814453, 70.21340942382812, 27.512807846069336, 32.408992767333984, 105.08549499511719, 935.5667724609375, 174.47732543945312, 256.8105773925781, 113.8097915649414, 215.4916229248047, 87.68446350097656, 87.69139099121094, 684.844482421875, 281.10284423828125, 701.1797485351562, 311.14166259765625, 388.6706848144531, 369.7206726074219, 150.13014221191406, 122.48551940917969, 567.7883911132812, 360.0921936035156, 310.88592529296875, 304.9879150390625, 492.53759765625, 332.1120300292969, 156.5722198486328, 825.436767578125, 306.2558288574219, 343.1051330566406, 303.0585021972656, 771.5585327148438, 904.2584838867188, 541.521240234375, 562.8579711914062, 602.7324829101562, 392.7444152832031, 507.5360412597656, 474.0946044921875, 643.778076171875, 639.177978515625, 388.9854736328125, 722.3045043945312, 494.9319763183594, 108.53858184814453, 85.58900451660156, 109.623046875, 58.058197021484375, 52.36690139770508, 75.24456787109375, 110.77274322509766, 215.33335876464844, 23.538461685180664, 43.80005645751953, 78.2409439086914, 164.3720245361328, 59.979923248291016, 311.452392578125, 184.16709899902344, 408.6117858886719, 16.932340621948242, 54.63436508178711, 899.045166015625, 46.81571960449219, 32.48600387573242, 133.93235778808594, 154.26087951660156, 178.33218383789062, 21.95302963256836, 11.162785530090332, 53.860225677490234, 159.43820190429688, 174.93643188476562, 42.49679946899414, 511.5838928222656, 219.18350219726562, 473.6297607421875, 650.9580078125, 139.68356323242188, 219.68524169921875, 176.34129333496094, 665.928955078125, 214.8339080810547, 333.9445495605469, 435.4141845703125, 191.31297302246094, 347.37139892578125, 375.82672119140625, 791.7030029296875, 276.31890869140625, 378.18536376953125, 338.83026123046875, 519.7792358398438, 482.1944580078125, 217.63824462890625, 290.3987121582031, 224.05062866210938, 413.47503662109375, 813.9197998046875, 722.3045043945312, 308.50665283203125, 537.3245239257812, 271.7392272949219, 792.013916015625, 361.11505126953125, 687.013427734375, 668.1218872070312, 484.6090393066406, 465.64324951171875, 467.23291015625, 154.16905212402344, 197.32766723632812, 109.60296630859375, 328.9526672363281, 653.2908325195312, 96.61807250976562, 99.44185638427734, 106.98881530761719, 121.03056335449219, 143.47422790527344, 78.96279907226562, 78.97854614257812, 59.27791976928711, 61.188358306884766, 95.87335968017578, 53.70172119140625, 67.80509948730469, 82.84545135498047, 188.24732971191406, 396.8471374511719, 415.620361328125, 48.200660705566406, 252.63375854492188, 62.31598663330078, 56.698856353759766, 50.13522720336914, 45.44256591796875, 64.27528381347656, 50.19601821899414, 527.1408081054688, 327.1368713378906, 210.35150146484375, 203.4967041015625, 242.81069946289062, 195.680908203125, 90.52774810791016, 346.54254150390625, 577.4988403320312, 487.280029296875, 162.77186584472656, 116.77855682373047, 562.3212890625, 193.82119750976562, 440.0213317871094, 597.4108276367188, 308.0833740234375, 534.8175048828125, 186.4110107421875, 436.3437805175781, 231.63429260253906, 269.9134521484375, 337.24462890625, 222.14903259277344, 261.45703125, 616.3430786132812, 432.7769775390625, 333.84637451171875, 365.17279052734375, 584.3060913085938, 371.3673400878906, 792.013916015625, 796.1497802734375, 310.7602844238281, 372.67291259765625, 583.4288330078125, 70.37525939941406, 386.74700927734375, 89.71182250976562, 210.4887237548828, 102.81288146972656, 35.61814880371094, 68.52810668945312, 172.6309051513672, 16.117021560668945, 129.10536193847656, 13.221076965332031, 35.80810546875, 13.300301551818848, 68.03219604492188, 281.12542724609375, 10.363327980041504, 10.364039421081543, 147.07542419433594, 33.83089828491211, 129.96652221679688, 42.813385009765625, 91.54943084716797, 47.651573181152344, 222.47940063476562, 111.26040649414062, 101.88739776611328, 102.49443817138672, 655.9451904296875, 39.858375549316406, 323.58734130859375, 208.77244567871094, 413.99072265625, 619.9920654296875, 132.41049194335938, 410.0018005371094, 129.17202758789062, 422.7890625, 97.93131256103516, 354.4468688964844, 237.08544921875, 330.5308837890625, 315.93408203125, 569.04052734375, 274.61737060546875, 216.18055725097656, 217.9605255126953, 463.8525085449219, 338.4365234375, 395.6577453613281, 681.88525390625, 531.8927001953125, 760.5531005859375, 237.95803833007812, 278.8150634765625, 783.9661865234375, 705.2757568359375, 418.0065612792969, 430.389892578125, 482.04681396484375, 813.9197998046875, 602.4412841796875], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.676700115203857, -6.225500106811523, -5.6809000968933105, -6.4959001541137695, -6.35890007019043, -6.817399978637695, -6.263599872589111, -7.086299896240234, -7.853099822998047, -7.706999778747559, -6.6757001876831055, -7.662700176239014, -8.088800430297852, -7.98360013961792, -7.366099834442139, -7.503499984741211, -5.2733001708984375, -7.707600116729736, -7.677999973297119, -7.622300148010254, -8.111100196838379, -8.339099884033203, -8.39780044555664, -7.192200183868408, -4.796000003814697, -8.397600173950195, -7.623899936676025, -8.561300277709961, -8.397600173950195, -7.222099781036377, -5.041500091552734, -6.7154998779296875, -6.332799911499023, -7.1427998542785645, -6.512700080871582, -7.403500080108643, -7.403600215911865, -5.36929988861084, -6.251299858093262, -5.356299877166748, -6.152900218963623, -5.935699939727783, -5.9878997802734375, -6.873799800872803, -7.073599815368652, -5.5725998878479, -6.018400192260742, -6.1682000160217285, -6.189300060272217, -5.732600212097168, -6.122600078582764, -6.838500022888184, -5.283199787139893, -6.213399887084961, -6.11359977722168, -6.245999813079834, -5.452600002288818, -5.317800045013428, -5.766499996185303, -5.739799976348877, -5.6975998878479, -6.0447998046875, -5.931399822235107, -5.992400169372559, -5.925600051879883, -5.949699878692627, -6.157599925994873, -6.074900150299072, -6.145699977874756, -6.94980001449585, -7.188700199127197, -6.9440999031066895, -7.579999923706055, -7.685500144958496, -7.326200008392334, -6.940499782562256, -6.276700019836426, -8.490599632263184, -7.871099948883057, -7.292200088500977, -6.5528998374938965, -7.562099933624268, -5.916500091552734, -6.443699836730957, -5.6479997634887695, -8.833200454711914, -7.665500164031982, -4.865099906921387, -7.820799827575684, -8.186599731445312, -6.771999835968018, -6.632900238037109, -6.488399982452393, -8.586000442504883, -9.265000343322754, -7.692200183868408, -6.61329984664917, -6.527100086212158, -7.946100234985352, -5.463699817657471, -6.30709981918335, -5.560299873352051, -5.250100135803223, -6.7657999992370605, -6.335000038146973, -6.549099922180176, -5.278500080108643, -6.361199855804443, -5.9475998878479, -5.706200122833252, -6.478400230407715, -5.929900169372559, -5.860300064086914, -5.191800117492676, -6.150700092315674, -5.894199848175049, -6.008500099182129, -5.662099838256836, -5.727499961853027, -6.40749979019165, -6.216000080108643, -6.399899959564209, -6.020899772644043, -5.624100208282471, -5.739200115203857, -6.242400169372559, -5.977399826049805, -6.311399936676025, -5.919400215148926, -6.288599967956543, -6.180099964141846, -6.204999923706055, -6.2530999183654785, -6.260000228881836, -5.376999855041504, -6.486199855804443, -6.240699768066406, -6.829500198364258, -5.730999946594238, -5.045400142669678, -6.956699848175049, -6.927999973297119, -6.855599880218506, -6.7322998046875, -6.5625, -7.160299777984619, -7.160200119018555, -7.447299957275391, -7.415999889373779, -6.9670000076293945, -7.547100067138672, -7.314000129699707, -7.114500045776367, -6.293799877166748, -5.549499988555908, -5.503399848937988, -7.657899856567383, -6.0015997886657715, -7.401400089263916, -7.496099948883057, -7.619500160217285, -7.718500137329102, -7.372200012207031, -7.619699954986572, -5.274099826812744, -5.75029993057251, -6.189300060272217, -6.223599910736084, -6.048699855804443, -6.267300128936768, -7.031300067901611, -5.707099914550781, -5.207900047302246, -5.376800060272217, -6.45389986038208, -6.779799938201904, -5.2444000244140625, -6.28879976272583, -5.498499870300293, -5.223199844360352, -5.866300106048584, -5.357699871063232, -6.339700222015381, -5.571300029754639, -6.1508002281188965, -6.015699863433838, -5.832499980926514, -6.191999912261963, -6.057600021362305, -5.393499851226807, -5.676599979400635, -5.893199920654297, -5.837900161743164, -5.5920000076293945, -5.9019999504089355, -5.513999938964844, -5.515699863433838, -6.0808000564575195, -6.06879997253418, -5.028900146484375, -7.146699905395508, -5.446199893951416, -6.908299922943115, -6.056700229644775, -6.778900146484375, -7.839600086212158, -7.1859002113342285, -6.264200210571289, -8.640800476074219, -6.566500186920166, -8.84570026397705, -7.857600212097168, -8.848199844360352, -7.21999979019165, -5.801700115203857, -9.107799530029297, -9.107799530029297, -6.457300186157227, -7.928899765014648, -6.586299896240234, -7.707200050354004, -6.948400020599365, -7.602399826049805, -6.063499927520752, -6.756800174713135, -6.846700191497803, -6.842199802398682, -4.986999988555908, -7.790900230407715, -5.711599826812744, -6.146299839019775, -5.480199813842773, -5.087800025939941, -6.601600170135498, -5.507699966430664, -6.628399848937988, -5.492300033569336, -6.901199817657471, -5.667099952697754, -6.060400009155273, -5.758800029754639, -5.814700126647949, -5.2957000732421875, -5.996200084686279, -6.207600116729736, -6.204999923706055, -5.609499931335449, -5.866199970245361, -5.748799800872803, -5.348400115966797, -5.548900127410889, -5.289999961853027, -6.176300048828125, -6.0802001953125, -5.472499847412109, -5.557600021362305, -5.94290018081665, -5.956999778747559, -6.036099910736084, -5.97730016708374, -6.060999870300293], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.135699987411499, 1.1354999542236328, 1.1354000568389893, 1.1339999437332153, 1.1313999891281128, 1.1309000253677368, 1.1291999816894531, 1.1291999816894531, 1.1282000541687012, 1.127500057220459, 1.1274000406265259, 1.1273000240325928, 1.1256999969482422, 1.1253999471664429, 1.1253000497817993, 1.1252000331878662, 1.1247999668121338, 1.1247999668121338, 1.1246999502182007, 1.1237000226974487, 1.1233999729156494, 1.1223000288009644, 1.121999979019165, 1.1217000484466553, 1.1211999654769897, 1.1210999488830566, 1.1208000183105469, 1.120300054550171, 1.1202000379562378, 1.1194000244140625, 1.1134999990463257, 1.118899941444397, 1.1151000261306763, 1.1188000440597534, 1.1105999946594238, 1.118899941444397, 1.1188000440597534, 1.0976999998092651, 1.1061999797821045, 1.0872000455856323, 1.1030999422073364, 1.0978000164031982, 1.0956000089645386, 1.1109999418258667, 1.1146999597549438, 1.0819000005722046, 1.0914000272750854, 1.0886000394821167, 1.0865999460220337, 1.0640000104904175, 1.0680999755859375, 1.104200005531311, 0.9970999956130981, 1.05840003490448, 1.044600009918213, 1.0362999439239502, 0.8952000141143799, 0.8712999820709229, 0.9352999925613403, 0.9233999848365784, 0.8970999717712402, 0.9782000184059143, 0.8352000117301941, 0.8424000144004822, 0.6032999753952026, 0.5863000154495239, 0.8751000165939331, 0.33889999985694885, 0.6460999846458435, 1.3593000173568726, 1.3580000400543213, 1.3551000356674194, 1.3547999858856201, 1.3523999452590942, 1.3493000268936157, 1.3481999635696411, 1.3473999500274658, 1.347000002861023, 1.3454999923706055, 1.3442000150680542, 1.3411999940872192, 1.3401000499725342, 1.3385000228881836, 1.3366999626159668, 1.3355000019073486, 1.333799958229065, 1.3300000429153442, 1.329800009727478, 1.329200029373169, 1.3287999629974365, 1.3269000053405762, 1.3246999979019165, 1.3242000341415405, 1.3213000297546387, 1.318600058555603, 1.3176000118255615, 1.3112000226974487, 1.3047000169754028, 1.3006999492645264, 1.2949999570846558, 1.2992000579833984, 1.2755000591278076, 1.267699956893921, 1.291100025177002, 1.2690999507904053, 1.2747000455856323, 1.216599941253662, 1.2651000022888184, 1.2375999689102173, 1.2137000560760498, 1.2639000415802002, 1.21589994430542, 1.2067999839782715, 1.1302000284194946, 1.2239999771118164, 1.166700005531311, 1.1621999740600586, 1.0807000398635864, 1.090399980545044, 1.205899953842163, 1.1089999675750732, 1.184499979019165, 0.9506999850273132, 0.6703000068664551, 0.6746000051498413, 1.0220999717712402, 0.7322999835014343, 1.0799000263214111, 0.40220001339912415, 0.8184000253677368, 0.28380000591278076, 0.28679999709129333, 0.5598000288009644, 0.5928000211715698, 1.4723999500274658, 1.4718999862670898, 1.4706000089645386, 1.4699000120162964, 1.4693000316619873, 1.4687999486923218, 1.4687000513076782, 1.4686000347137451, 1.467900037765503, 1.467900037765503, 1.4674999713897705, 1.4670000076293945, 1.4667999744415283, 1.4666999578475952, 1.4661999940872192, 1.4661999940872192, 1.4657000303268433, 1.4656000137329102, 1.4646999835968018, 1.4645999670028687, 1.4631999731063843, 1.4630000591278076, 1.4630000591278076, 1.4625999927520752, 1.4625999927520752, 1.462399959564209, 1.4620000123977661, 1.461300015449524, 1.4608999490737915, 1.4606000185012817, 1.4545999765396118, 1.4555000066757202, 1.4580999612808228, 1.4570000171661377, 1.455199956893921, 1.4523999691009521, 1.4592000246047974, 1.441100001335144, 1.4296000003814697, 1.4306000471115112, 1.4500000476837158, 1.4562000036239624, 1.419800043106079, 1.440500020980835, 1.4108999967575073, 1.3803999423980713, 1.3996000289916992, 1.356600046157837, 1.4285999536514282, 1.346500039100647, 1.4002000093460083, 1.3824000358581543, 1.342900037765503, 1.4009000062942505, 1.3724000453948975, 1.1789000034332275, 1.249400019645691, 1.2922999858856201, 1.2580000162124634, 1.0338000059127808, 1.1770000457763672, 0.807699978351593, 0.8007000088691711, 1.1763999462127686, 1.006700038909912, 1.5983999967575073, 1.5957000255584717, 1.5923000574111938, 1.5913000106811523, 1.5901000499725342, 1.5844000577926636, 1.5836999416351318, 1.5829999446868896, 1.580899953842163, 1.575600028038025, 1.569100022315979, 1.5686999559402466, 1.5604000091552734, 1.5602999925613403, 1.5562000274658203, 1.5556999444961548, 1.5501999855041504, 1.5500999689102173, 1.5479999780654907, 1.5458999872207642, 1.5426000356674194, 1.532099962234497, 1.530900001525879, 1.5298999547958374, 1.527899980545044, 1.527500033378601, 1.5256999731063843, 1.5241999626159668, 1.5232000350952148, 1.5199999809265137, 1.5051000118255615, 1.5087000131607056, 1.4902000427246094, 1.478700041770935, 1.5088000297546387, 1.4723999500274658, 1.506700038909912, 1.4570000171661377, 1.5108000040054321, 1.4585000276565552, 1.4673999547958374, 1.4366999864578247, 1.4259999990463257, 1.356600046157837, 1.384600043296814, 1.412500023841858, 1.4069000482559204, 1.2470999956130981, 1.3056999444961548, 1.266800045967102, 1.1229000091552734, 1.1708999872207642, 1.0721999406814575, 1.3478000164031982, 1.2855000495910645, 0.8593000173568726, 0.8799999952316284, 1.017799973487854, 0.9746000170707703, 0.7821000218391418, 0.31700000166893005, 0.5342000126838684]}, \"token.table\": {\"Topic\": [1, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 2, 3, 4, 1, 2, 3, 4, 2, 4, 2, 3, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 4, 1, 2, 4, 3, 3, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 3, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 2, 1, 2, 3, 4, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 3, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 2, 3, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 1, 2, 3, 4, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 1, 2, 3, 4, 2, 3, 4, 2, 1, 2, 3, 4, 1, 4, 3, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 4], \"Freq\": [0.982718288898468, 0.014242293313145638, 0.9795753359794617, 0.012289579026401043, 0.8986755013465881, 0.0061447895132005215, 0.08295466005802155, 0.018379122018814087, 0.8454396724700928, 0.11946430057287216, 0.018379122018814087, 0.9835773706436157, 0.14521411061286926, 0.3858546316623688, 0.03526628389954567, 0.4335678517818451, 0.05654778331518173, 0.12117382138967514, 0.7405067086219788, 0.08078254759311676, 0.009309517219662666, 0.893713653087616, 0.06516662240028381, 0.03258331120014191, 0.14802441000938416, 0.02775457687675953, 0.00925152562558651, 0.8141342401504517, 0.017126431688666344, 0.9762066006660461, 0.9593418836593628, 0.029203711077570915, 0.004380556754767895, 0.005840742029249668, 0.9913281202316284, 0.0036852345801889896, 0.0036852345801889896, 0.0036852345801889896, 0.020961564034223557, 0.8714021444320679, 0.029945090413093567, 0.07486272603273392, 0.00846389215439558, 0.06488984078168869, 0.07335373014211655, 0.854853093624115, 0.009213313460350037, 0.9858245849609375, 0.04784613847732544, 0.2224845439195633, 0.18181532621383667, 0.5502306222915649, 0.06705866008996964, 0.009579808451235294, 0.02394952066242695, 0.9005019664764404, 0.9807894825935364, 0.011404529213905334, 0.046714361757040024, 0.023357180878520012, 0.9109300971031189, 0.01737811602652073, 0.011585410684347153, 0.005792705342173576, 0.9673818349838257, 0.9817339181900024, 0.02283102087676525, 0.9542571306228638, 0.030782487243413925, 0.9810465574264526, 0.9813611507415771, 0.019447574391961098, 0.9529311656951904, 0.019447574391961098, 0.006482524797320366, 0.009076307527720928, 0.024203486740589142, 0.1300937384366989, 0.8350203037261963, 0.9807119965553284, 0.011403627693653107, 0.0696745291352272, 0.007741614244878292, 0.0232248418033123, 0.898027241230011, 0.9839111566543579, 0.9936029314994812, 0.05462145432829857, 0.09467718750238419, 0.05826288461685181, 0.7938317656517029, 0.9093422889709473, 0.026231026276946068, 0.03206014260649681, 0.03206014260649681, 0.9887145757675171, 0.005554575938731432, 0.005554575938731432, 0.9748101830482483, 0.018170803785324097, 0.0021377415396273136, 0.005344354081898928, 0.9840980768203735, 0.008786589838564396, 0.008786589838564396, 0.9902609586715698, 0.9969216585159302, 0.0015307117719203234, 0.004592135548591614, 0.9919012784957886, 0.0015307117719203234, 0.9801590442657471, 0.9932717680931091, 0.0030399509705603123, 0.0030399509705603123, 0.9910240173339844, 0.0030399509705603123, 0.004812083672732115, 0.004812083672732115, 0.9864771962165833, 0.007218125741928816, 0.9641910195350647, 0.012855879962444305, 0.0032139699906110764, 0.019283819943666458, 0.9738976359367371, 0.4485642910003662, 0.49563583731651306, 0.019382407888770103, 0.03461144119501114, 0.16175596415996552, 0.07076823711395264, 0.06065848469734192, 0.7051548957824707, 0.9924700260162354, 0.2691442668437958, 0.17475242912769318, 0.08673843741416931, 0.4694080054759979, 0.08249195665121078, 0.18291693925857544, 0.014346427284181118, 0.7173213362693787, 0.006143567617982626, 0.01843070425093174, 0.9706836938858032, 0.006143567617982626, 0.004118434619158506, 0.016473738476634026, 0.9801874756813049, 0.004118434619158506, 0.9761730432510376, 0.05858615040779114, 0.023434460163116455, 0.9072483777999878, 0.010043339803814888, 0.003056824440136552, 0.01528412289917469, 0.9781838655471802, 0.003056824440136552, 0.03558247908949852, 0.04744330421090126, 0.874735951423645, 0.04151289165019989, 0.007552271708846092, 0.022656815126538277, 0.06797044724225998, 0.8987203240394592, 0.03733227774500847, 0.9557062983512878, 0.007466455455869436, 0.007466455455869436, 0.045366570353507996, 0.9073314666748047, 0.0056708212941884995, 0.045366570353507996, 0.02632109820842743, 0.0507621169090271, 0.2820117771625519, 0.6411067247390747, 0.9813292026519775, 0.009257822297513485, 0.009257822297513485, 0.9891098737716675, 0.002519862027838826, 0.007559585850685835, 0.9852660298347473, 0.002519862027838826, 0.03595169261097908, 0.00898792315274477, 0.03595169261097908, 0.9167681932449341, 0.06814386695623398, 0.10383827239274979, 0.7430926561355591, 0.08599106967449188, 0.7686662077903748, 0.09511923044919968, 0.030849481001496315, 0.1054023951292038, 0.004753947723656893, 0.009507895447313786, 0.9793131947517395, 0.004753947723656893, 0.9914851188659668, 0.14586395025253296, 0.7033883929252625, 0.08103553205728531, 0.07131126523017883, 0.004494798369705677, 0.06742197275161743, 0.008989596739411354, 0.916938841342926, 0.8504258394241333, 0.04328514635562897, 0.02800803631544113, 0.07638555765151978, 0.03245874494314194, 0.0032458745408803225, 0.9250742793083191, 0.038950495421886444, 0.013416591100394726, 0.34078142046928406, 0.6252131462097168, 0.02146654576063156, 0.9788820147514343, 0.009027491323649883, 0.9749690890312195, 0.009027491323649883, 0.018054982647299767, 0.9883124232292175, 0.014976948499679565, 0.08387091010808945, 0.8327183723449707, 0.07188935577869415, 0.010389631614089012, 0.010389631614089012, 0.9541144967079163, 0.025974078103899956, 0.9869329929351807, 0.81621915102005, 0.024006444960832596, 0.12557217478752136, 0.035086341202259064, 0.016672246158123016, 0.9669902324676514, 0.020021241158246994, 0.9554581046104431, 0.012235202826559544, 0.012235202826559544, 0.0416659340262413, 0.3775186240673065, 0.5126172304153442, 0.0681806206703186, 0.01858779788017273, 0.4298427999019623, 0.025558220222592354, 0.5274287462234497, 0.006467572879046202, 0.27594977617263794, 0.025870291516184807, 0.6920303106307983, 0.7841271758079529, 0.018145091831684113, 0.18533915281295776, 0.01296077948063612, 0.2406143695116043, 0.12096459418535233, 0.056537799537181854, 0.5811560153961182, 0.08610986173152924, 0.0843525156378746, 0.05623501166701317, 0.7714740633964539, 0.0797119289636612, 0.026570644229650497, 0.012077565304934978, 0.8816622495651245, 0.08415501564741135, 0.2486969232559204, 0.5086982250213623, 0.15951772034168243, 0.05727230757474899, 0.9163569211959839, 0.007159038446843624, 0.014318076893687248, 0.03902650624513626, 0.03902650624513626, 0.009756626561284065, 0.9171229600906372, 0.033996161073446274, 0.013598465360701084, 0.013598465360701084, 0.9314948320388794, 0.004104415886104107, 0.03693974390625954, 0.9542767405509949, 0.004104415886104107, 0.021714041009545326, 0.8613235950469971, 0.06514212489128113, 0.05428510159254074, 0.011218779720366001, 0.09722942858934402, 0.8862836360931396, 0.0056093898601830006, 0.9878069162368774, 0.9648747444152832, 0.9876099824905396, 0.04505080357193947, 0.1576777994632721, 0.7401202917098999, 0.05792246013879776, 0.9773566722869873, 0.3585411608219147, 0.28716492652893066, 0.014939215034246445, 0.33862221240997314, 0.972489595413208, 0.019982662051916122, 0.9854171276092529, 0.02353118360042572, 0.9177161455154419, 0.04706236720085144, 0.02353118360042572, 0.9306930303573608, 0.9649409651756287, 0.9521177411079407, 0.022516297176480293, 0.0032166140154004097, 0.022516297176480293, 0.008926553651690483, 0.8257062435150146, 0.09819209575653076, 0.06694915145635605, 0.005429851356893778, 0.961083710193634, 0.02714925818145275, 0.005429851356893778, 0.07526648789644241, 0.025088829919695854, 0.9031978845596313, 0.7424678206443787, 0.13288487493991852, 0.031639255583286285, 0.09280847758054733, 0.014252545312047005, 0.009501696564257145, 0.0047508482821285725, 0.973923921585083, 0.9913778901100159, 0.004063024185597897, 0.004063024185597897, 0.9760721325874329, 0.009122169576585293, 0.009122169576585293, 0.9899759292602539, 0.967617392539978, 0.02134450152516365, 0.003557416843250394, 0.007114833686500788, 0.9800700545310974, 0.011462807655334473, 0.005731403827667236, 0.005731403827667236, 0.5757395029067993, 0.2362409234046936, 0.11420919001102448, 0.07509645819664001, 0.002140260301530361, 0.002140260301530361, 0.9952210187911987, 0.002140260301530361, 0.011046336963772774, 0.9831239581108093, 0.9908905029296875, 0.005110360682010651, 0.005110360682010651, 0.9760788679122925, 0.015331082046031952, 0.9449372887611389, 0.013774165883660316, 0.7679097652435303, 0.18595123291015625, 0.030991872772574425, 0.003210763679817319, 0.9632290601730347, 0.01926458068192005, 0.012843054719269276, 0.039128441363573074, 0.007114262320101261, 0.010671393014490604, 0.9426397681236267, 0.2150088995695114, 0.493906170129776, 0.018429333344101906, 0.27275413274765015, 0.9854615926742554, 0.009541122242808342, 0.0027260349597781897, 0.0013630174798890948, 0.028075573965907097, 0.9545695185661316, 0.014209538698196411, 0.9804581999778748, 0.009726407937705517, 0.009726407937705517, 0.009726407937705517, 0.9726407527923584, 0.031929608434438705, 0.846134603023529, 0.03725120797753334, 0.08780642598867416, 0.005902660544961691, 0.8086645007133484, 0.14461518824100494, 0.0413186252117157, 0.9893520474433899, 0.02590886875987053, 0.8521139025688171, 0.040302686393260956, 0.08060537278652191, 0.9475785493850708, 0.03278818354010582, 0.0032788184471428394, 0.013115273788571358, 0.05318574979901314, 0.01772858388721943, 0.19796918332576752, 0.7327814102172852, 0.9762781262397766, 0.02308286726474762, 0.0076942890882492065, 0.03847144544124603, 0.9310089945793152, 0.0076494403183460236, 0.07266968488693237, 0.9026339650154114, 0.01912360079586506, 0.9876742362976074, 0.006221556570380926, 0.7528083324432373, 0.23019757866859436, 0.012443113140761852, 0.9832784533500671, 0.964411199092865, 0.01916048675775528, 0.006386829074472189, 0.012773658148944378, 0.0306337159126997, 0.05105619132518768, 0.020422477275133133, 0.898589015007019, 0.9574795961380005, 0.027047445997595787, 0.005409489385783672, 0.010818978771567345, 0.02792663872241974, 0.02792663872241974, 0.9495056867599487, 0.007916598580777645, 0.9856165051460266, 0.0039582992903888226, 0.9897248148918152, 0.006969892885535955, 0.8065977692604065, 0.15279164910316467, 0.02487305924296379, 0.017766471952199936, 0.004643962252885103, 0.9705881476402283, 0.004643962252885103, 0.02321981079876423, 0.016871554777026176, 0.02530733123421669, 0.09701143950223923, 0.8604492545127869, 0.02275983616709709, 0.9012894630432129, 0.018207868561148643, 0.05917557328939438, 0.07913043349981308, 0.05380869284272194, 0.03798260539770126, 0.8261216878890991, 0.00531216012313962, 0.00531216012313962, 0.9880618453025818, 0.011363085359334946, 0.020453553646802902, 0.9363182187080383, 0.03181663900613785, 0.9525338411331177, 0.00833120010793209, 0.00833120010793209, 0.0305477324873209, 0.005227037239819765, 0.8938233256340027, 0.01045407447963953, 0.08885963261127472, 0.1111229658126831, 0.8529438376426697, 0.02402658760547638, 0.01201329380273819, 0.115897037088871, 0.021287210285663605, 0.011826228350400925, 0.853853702545166, 0.009002964943647385, 0.009002964943647385, 0.9273054003715515, 0.05401778966188431, 0.994498610496521, 0.21524879336357117, 0.6530019640922546, 0.01209262851625681, 0.1185077577829361, 0.008445415645837784, 0.9057707786560059, 0.050672490149736404, 0.03589301556348801, 0.004562387242913246, 0.9261645674705505, 0.05931103229522705, 0.009124774485826492, 0.9814344644546509, 0.011683743447065353, 0.00981475692242384, 0.01962951384484768, 0.068703293800354, 0.9127723574638367, 0.0060837604105472565, 0.9673178791999817, 0.0060837604105472565, 0.024335041642189026, 0.9773740768432617, 0.003893920686095953, 0.007787841372191906, 0.011681761592626572, 0.9959143996238708, 0.7847594022750854, 0.07631909847259521, 0.006636443547904491, 0.13106974959373474, 0.12143995612859726, 0.7433597445487976, 0.02943998947739601, 0.1067199632525444, 0.018825748935341835, 0.22590899467468262, 0.6417869329452515, 0.11295449733734131, 0.9008162021636963, 0.08579201996326447, 0.006599385756999254, 0.006599385756999254, 0.980154275894165, 0.009516061283648014, 0.009516061283648014, 0.03713315352797508, 0.9468954205513, 0.01856657676398754, 0.01856657676398754, 0.15266674757003784, 0.3367649018764496, 0.2529478669166565, 0.257438063621521, 0.9840728640556335, 0.037097249180078506, 0.08064619451761246, 0.009677543304860592, 0.8725917935371399, 0.9304089546203613, 0.027099289000034332, 0.021077224984765053, 0.021077224984765053, 0.9498277902603149, 0.00855700671672821, 0.028523355722427368, 0.014261677861213684, 0.961215615272522, 0.021360347047448158, 0.9596813321113586, 0.025728721171617508, 0.010291488841176033, 0.0051457444205880165, 0.6101848483085632, 0.030307196080684662, 0.016163837164640427, 0.34348154067993164, 0.003556685522198677, 0.04445856809616089, 0.9442999958992004, 0.007113371044397354, 0.988126277923584, 0.0018970263190567493, 0.013279184699058533, 0.9788655638694763, 0.005691078957170248, 0.9824752807617188, 0.01348165050148964, 0.0025278094690293074, 0.001685206312686205, 0.9959915280342102, 0.0020706686191260815, 0.0020706686191260815, 0.9839795827865601, 0.014260574243962765, 0.9278479218482971, 0.03654543310403824, 0.016242414712905884, 0.020303018391132355, 0.041339948773384094, 0.8520622849464417, 0.09875654429197311, 0.009186655282974243, 0.014698922634124756, 0.014698922634124756, 0.02939784526824951, 0.9407310485839844, 0.9891881942749023, 0.4112970530986786, 0.5266835689544678, 0.013027508743107319, 0.05024896189570427, 0.03426235169172287, 0.9617931246757507, 0.0024473106022924185, 0.0024473106022924185, 0.9915711283683777, 0.9796583652496338, 0.9897948503494263, 0.7388637661933899, 0.009851517155766487, 0.01182182040065527, 0.2403770238161087, 0.28215914964675903, 0.11484869569540024, 0.12477388978004456, 0.4792451560497284, 0.7652679085731506, 0.04091750457882881, 0.013270542025566101, 0.18025819957256317, 0.5856055021286011, 0.2562994956970215, 0.015533302910625935, 0.14290638267993927, 0.015865236520767212, 0.8117712140083313, 0.02115364745259285, 0.1507197469472885, 0.01609347015619278, 0.01609347015619278, 0.9548792243003845, 0.010728980414569378, 0.05911755561828613, 0.9458808898925781, 0.018334167078137398, 0.03208479285240173, 0.8777482509613037, 0.07333666831254959, 0.9924170970916748, 0.1594354659318924, 0.023106589913368225, 0.7971773147583008, 0.020795930176973343, 0.002885648515075445, 0.014428243041038513, 0.9638066291809082, 0.017313892021775246, 0.924064040184021, 0.03918292745947838, 0.013060975819826126, 0.022856708616018295, 0.9440136551856995, 0.019373415037989616, 0.0211346335709095, 0.014089756645262241, 0.979707658290863, 0.016328461468219757, 0.15548959374427795, 0.05042905732989311, 0.029416950419545174, 0.7648407220840454, 0.9953115582466125, 0.016430577263236046, 0.13144461810588837, 0.8023598790168762, 0.04929173365235329, 0.9698752760887146, 0.004640551749616861, 0.004640551749616861, 0.018562206998467445, 0.004317149985581636, 0.06475725024938583, 0.9281872510910034, 0.004317149985581636, 0.005716362036764622, 0.9317670464515686, 0.05144726112484932, 0.011432724073529243, 0.012781032361090183, 0.9713584184646606, 0.012781032361090183, 0.012781032361090183, 0.9817734956741333, 0.010318788699805737, 0.02579697221517563, 0.9648067355155945, 0.005159394349902868, 0.04809734225273132, 0.7445468902587891, 0.03270619362592697, 0.17507432401180267, 0.8674195408821106, 0.08238063007593155, 0.021806636825203896, 0.027864037081599236, 0.9815640449523926, 0.9873802661895752, 0.35649609565734863, 0.45743173360824585, 0.11596860736608505, 0.07086970657110214, 0.006272022612392902, 0.9408034086227417, 0.03136011213064194, 0.02508809044957161, 0.9949904680252075, 0.9962801337242126, 0.0020626918412745, 0.0020626918412745, 0.0020626918412745, 0.010284030809998512, 0.003428010269999504, 0.003428010269999504, 0.982124924659729, 0.01809968799352646, 0.002585669746622443, 0.002585669746622443, 0.9773831367492676, 0.0232368353754282, 0.007745611481368542, 0.015491222962737083, 0.9527102112770081, 0.011146802455186844, 0.9809186458587646, 0.05505584180355072, 0.03211590647697449, 0.10093570500612259, 0.8120736479759216, 0.2566414177417755, 0.02786392532289028, 0.1055896133184433, 0.6115398406982422, 0.014742253348231316, 0.0049140844494104385, 0.9779028296470642, 0.0049140844494104385, 0.2888926863670349, 0.44159308075904846, 0.20222486555576324, 0.06396909058094025, 0.22561421990394592, 0.33623796701431274, 0.2998485863208771, 0.13973526656627655, 0.9771241545677185, 0.004878027364611626, 0.10731659829616547, 0.02195112220942974, 0.8658498525619507, 0.025411276146769524, 0.9226248264312744, 0.04300370067358017, 0.007818854413926601, 0.1356908231973648, 0.5732244849205017, 0.02215360477566719, 0.26861244440078735, 0.020985666662454605, 0.020985666662454605, 0.06295699626207352, 0.923369288444519, 0.011215025559067726, 0.9476696848869324, 0.02803756482899189, 0.005607512779533863, 0.007409782614558935, 0.07780271768569946, 0.911403238773346, 0.007409782614558935, 0.970169723033905, 0.01328999549150467, 0.020209599286317825, 0.7831219434738159, 0.03789299726486206, 0.15915058553218842, 0.9517819285392761, 0.01830349862575531, 0.01830349862575531, 0.9565877914428711, 0.05335811525583267, 0.012196141295135021, 0.02286776341497898, 0.9116615653038025, 0.014592552557587624, 0.963108479976654, 0.995556652545929, 0.9907577633857727, 0.9958369731903076, 0.02472284622490406, 0.052536047995090485, 0.027813201770186424, 0.8962031602859497, 0.06553836166858673, 0.010923060588538647, 0.010923060588538647, 0.9175370931625366, 0.9774214625358582], \"Term\": [\"absolute_constant\", \"absolute_constant\", \"accelerated_gradient\", \"active_learning\", \"active_learning\", \"active_learning\", \"active_learning\", \"activity\", \"activity\", \"activity\", \"activity\", \"additive_error\", \"agent\", \"agent\", \"agent\", \"agent\", \"answer\", \"answer\", \"answer\", \"answer\", \"approximate_posterior\", \"approximate_posterior\", \"approximate_posterior\", \"approximate_posterior\", \"approximation_guarantee\", \"approximation_guarantee\", \"approximation_guarantee\", \"approximation_guarantee\", \"autoencoder\", \"autoencoder\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit_problem\", \"bandit_problem\", \"bandit_problem\", \"bandit_problem\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_inference\", \"bayesian_network\", \"bayesian_network\", \"bayesian_network\", \"bayesian_network\", \"bayesian_nonparametric\", \"bayesian_nonparametric\", \"belief\", \"belief\", \"belief\", \"belief\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"belief_propagation\", \"bianchi\", \"bianchi\", \"bilmes\", \"bilmes\", \"bilmes\", \"bipartite_graph\", \"bipartite_graph\", \"bipartite_graph\", \"bipartite_graph\", \"black_variational\", \"black_variational\", \"bootstrap\", \"bootstrap\", \"bubeck\", \"bubeck_cesa\", \"calibration\", \"calibration\", \"calibration\", \"calibration\", \"causal\", \"causal\", \"causal\", \"causal\", \"cesa\", \"cesa\", \"clique\", \"clique\", \"clique\", \"clique\", \"closed_convex\", \"cnns\", \"community\", \"community\", \"community\", \"community\", \"completion\", \"completion\", \"completion\", \"completion\", \"convergence_analysis\", \"convergence_analysis\", \"convergence_analysis\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convex_programming\", \"convex_programming\", \"convex_programming\", \"convnet\", \"convnets\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional_architecture\", \"convolutional_layer\", \"convolutional_network\", \"convolutional_network\", \"convolutional_network\", \"convolutional_network\", \"convolutional_neural\", \"convolutional_neural\", \"convolutional_neural\", \"convolutional_neural\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"covariance_function\", \"covariance_matrix\", \"covariance_matrix\", \"covariance_matrix\", \"covariance_matrix\", \"cover\", \"cover\", \"cover\", \"cover\", \"current_iterate\", \"data_set\", \"data_set\", \"data_set\", \"data_set\", \"decision_making\", \"decision_making\", \"decision_making\", \"decision_making\", \"decoder\", \"decoder\", \"decoder\", \"decoder\", \"deep_convolutional\", \"deep_convolutional\", \"deep_convolutional\", \"deep_convolutional\", \"deep_convolutional_neural_network\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_network\", \"deep_network\", \"deep_network\", \"deep_network\", \"deep_neural\", \"deep_neural\", \"deep_neural\", \"deep_neural\", \"directed_edge\", \"directed_edge\", \"directed_edge\", \"directed_edge\", \"dirichlet_process\", \"dirichlet_process\", \"dirichlet_process\", \"dirichlet_process\", \"disease\", \"disease\", \"disease\", \"disease\", \"document\", \"document\", \"document\", \"document\", \"dual_norm\", \"dual_norm\", \"dual_norm\", \"dual_variable\", \"during_training\", \"during_training\", \"during_training\", \"during_training\", \"edge_weight\", \"edge_weight\", \"edge_weight\", \"edge_weight\", \"embedding\", \"embedding\", \"embedding\", \"embedding\", \"empirical_risk\", \"empirical_risk\", \"empirical_risk\", \"empirical_risk\", \"encoder\", \"encoder\", \"encoder\", \"encoder\", \"encoder_decoder\", \"environment\", \"environment\", \"environment\", \"environment\", \"equivalence_class\", \"equivalence_class\", \"equivalence_class\", \"equivalence_class\", \"estimation_error\", \"estimation_error\", \"estimation_error\", \"estimation_error\", \"feature_map\", \"feature_map\", \"feature_map\", \"feature_map\", \"filter\", \"filter\", \"filter\", \"filter\", \"fine_tuning\", \"firing\", \"firing\", \"firing\", \"firing\", \"fischer_finite\", \"frame\", \"frame\", \"frame\", \"frame\", \"fully_connected\", \"fully_connected\", \"fully_connected\", \"fully_connected\", \"fully_convolutional\", \"game\", \"game\", \"game\", \"game\", \"gaussian_approximation\", \"gaussian_approximation\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"generative_model\", \"generative_model\", \"generative_model\", \"generative_model\", \"gibbs\", \"gibbs\", \"gibbs\", \"gibbs\", \"gibbs_sampling\", \"gibbs_sampling\", \"gibbs_sampling\", \"gibbs_sampling\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"graphical_model\", \"graphical_model\", \"graphical_model\", \"graphical_model\", \"greedy\", \"greedy\", \"greedy\", \"greedy\", \"greedy_algorithm\", \"greedy_algorithm\", \"greedy_algorithm\", \"greedy_algorithm\", \"ground_truth\", \"ground_truth\", \"ground_truth\", \"ground_truth\", \"hamiltonian_monte\", \"hamiltonian_monte\", \"hamiltonian_monte\", \"hamiltonian_monte\", \"hamming\", \"hamming\", \"hamming\", \"hamming\", \"hamming_distance\", \"hamming_distance\", \"hamming_distance\", \"hamming_distance\", \"hidden_layer\", \"hidden_layer\", \"hidden_layer\", \"hidden_layer\", \"hidden_markov\", \"hidden_markov\", \"hidden_markov\", \"hidden_markov\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"image_caption\", \"influence_through\", \"input_image\", \"input_output\", \"input_output\", \"input_output\", \"input_output\", \"input_sequence\", \"item\", \"item\", \"item\", \"item\", \"iteration_complexity\", \"iteration_complexity\", \"joint_posterior\", \"kalman\", \"kalman\", \"kalman\", \"kalman\", \"kempe\", \"kempe_kleinberg\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"latent_space\", \"latent_space\", \"latent_space\", \"latent_space\", \"latent_state\", \"latent_state\", \"latent_state\", \"latent_state\", \"lattice\", \"lattice\", \"lattice\", \"least_square\", \"least_square\", \"least_square\", \"least_square\", \"lifted\", \"lifted\", \"lifted\", \"lifted\", \"linear_convergence\", \"linear_convergence\", \"linear_convergence\", \"linear_dynamical\", \"linear_dynamical\", \"linear_dynamical\", \"linear_measurement\", \"lipschitz\", \"lipschitz\", \"lipschitz\", \"lipschitz\", \"lipschitz_constant\", \"lipschitz_constant\", \"lipschitz_constant\", \"lipschitz_constant\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"lstm\", \"lstm\", \"lstm\", \"lstm\", \"lstm_lstm\", \"lstm_lstm\", \"lstms\", \"machine_translation\", \"machine_translation\", \"machine_translation\", \"machine_translation\", \"mackay\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"marginal_likelihood\", \"marginal_likelihood\", \"marginal_likelihood\", \"marginal_likelihood\", \"market\", \"market\", \"market\", \"market\", \"markov_chain\", \"markov_chain\", \"markov_chain\", \"markov_chain\", \"matrix_completion\", \"matrix_completion\", \"matrix_completion\", \"matrix_completion\", \"maximizing_spread\", \"maximizing_spread\", \"maximizing_submodular\", \"maximizing_submodular\", \"maximum_degree\", \"maximum_degree\", \"maximum_degree\", \"maximum_degree\", \"mcmc\", \"mcmc\", \"mcmc\", \"mcmc\", \"mean_field\", \"mean_field\", \"mean_field\", \"mean_field\", \"minimizing_composite\", \"mixture_model\", \"mixture_model\", \"mixture_model\", \"mixture_model\", \"multi_armed\", \"multi_armed\", \"multi_armed\", \"multi_armed\", \"multi_label\", \"multi_label\", \"multi_label\", \"multi_label\", \"multiarmed_bandit\", \"multilabel\", \"multilabel\", \"multilabel\", \"multilabel\", \"natural_image\", \"natural_image\", \"natural_image\", \"natural_image\", \"natural_scene\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"newman\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"normalization_constant\", \"normalization_constant\", \"normalization_constant\", \"normalization_constant\", \"nuclear_norm\", \"nuclear_norm\", \"nuclear_norm\", \"nuclear_norm\", \"number_topic\", \"number_topic\", \"number_topic\", \"object_detection\", \"object_detection\", \"object_detection\", \"object_recognition\", \"object_recognition\", \"online_learning\", \"online_learning\", \"online_learning\", \"online_learning\", \"optimal_control\", \"optimal_control\", \"optimal_control\", \"optimal_control\", \"parent\", \"parent\", \"parent\", \"parent\", \"particle\", \"particle\", \"particle\", \"particle\", \"partition_function\", \"partition_function\", \"partition_function\", \"partition_function\", \"patch\", \"patch\", \"patch\", \"pixel\", \"pixel\", \"pixel\", \"pixel\", \"player\", \"player\", \"player\", \"player\", \"point_process\", \"point_process\", \"point_process\", \"point_process\", \"policy\", \"policy\", \"policy\", \"policy\", \"polynomial_time\", \"polynomial_time\", \"polynomial_time\", \"polynomial_time\", \"pooling\", \"pooling\", \"pooling\", \"pooling\", \"pooling_layer\", \"population\", \"population\", \"population\", \"population\", \"posterior_distribution\", \"posterior_distribution\", \"posterior_distribution\", \"posterior_distribution\", \"posterior_mean\", \"posterior_mean\", \"posterior_mean\", \"posterior_mean\", \"posterior_predictive\", \"posterior_predictive\", \"predicate\", \"predicate\", \"predicate\", \"predicate\", \"predictive_distribution\", \"predictive_distribution\", \"predictive_distribution\", \"predictive_distribution\", \"primal\", \"primal\", \"primal\", \"primal\", \"primal_dual\", \"probability_least\", \"probability_least\", \"probability_least\", \"probability_least\", \"probability_measure\", \"probability_measure\", \"probability_measure\", \"probability_measure\", \"proposal\", \"proposal\", \"proposal\", \"proposal\", \"proximal\", \"proximal\", \"proximal\", \"proximal\", \"proximal_operator\", \"proximal_operator\", \"proximal_operator\", \"quadrature\", \"quadrature\", \"quadrature\", \"quadrature\", \"query\", \"query\", \"query\", \"query\", \"rakhlin\", \"random_walk\", \"random_walk\", \"random_walk\", \"random_walk\", \"rank_approximation\", \"rank_approximation\", \"rank_approximation\", \"rank_approximation\", \"rank_matrix\", \"rank_matrix\", \"rank_matrix\", \"rank_matrix\", \"rasmussen\", \"rasmussen\", \"rate_convergence\", \"rate_convergence\", \"rate_convergence\", \"rate_convergence\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent\", \"recurrent_convolutional\", \"recurrent_neural\", \"recurrent_neural\", \"recurrent_neural\", \"recurrent_neural\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret_bound\", \"regret_bound\", \"regret_bound\", \"regret_minimization\", \"regret_minimization\", \"regularization_parameter\", \"regularization_parameter\", \"regularization_parameter\", \"regularization_parameter\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"relational\", \"relational\", \"relational\", \"relational\", \"restricted_strong\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward_function\", \"reward_function\", \"reward_function\", \"reward_function\", \"richta\", \"richta_taka\", \"rnns\", \"round\", \"round\", \"round\", \"round\", \"running_time\", \"running_time\", \"running_time\", \"running_time\", \"sample_complexity\", \"sample_complexity\", \"sample_complexity\", \"sample_complexity\", \"sample_size\", \"sample_size\", \"sample_size\", \"sample_size\", \"sampler\", \"sampler\", \"sampler\", \"sampler\", \"scene\", \"scene\", \"scene\", \"scene\", \"security\", \"security\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"semantic_segmentation\", \"semi_supervised\", \"semi_supervised\", \"semi_supervised\", \"semi_supervised\", \"sentence\", \"sentence\", \"sentence\", \"sentence\", \"singular\", \"singular\", \"singular\", \"singular\", \"singular_value\", \"singular_value\", \"singular_value\", \"singular_value\", \"smooth_convex\", \"smooth_convex\", \"social_network\", \"social_network\", \"social_network\", \"social_network\", \"softmax_layer\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"spectral_norm\", \"spectral_norm\", \"spectral_norm\", \"spectral_norm\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"speech_recognition\", \"spike\", \"spike\", \"spike\", \"spike\", \"spiking\", \"spiking\", \"spiking\", \"spiking\", \"squared_exponential\", \"stack\", \"stack\", \"stack\", \"stack\", \"state_space\", \"state_space\", \"state_space\", \"state_space\", \"step_size\", \"step_size\", \"step_size\", \"step_size\", \"stochastic_dual\", \"stochastic_dual_coordinate_ascent\", \"stochastic_optimization\", \"stochastic_optimization\", \"stochastic_optimization\", \"stochastic_optimization\", \"stochastic_variational\", \"stochastic_variational\", \"stochastic_variational\", \"stochastic_variational\", \"strong_convexity\", \"strongly_convex\", \"strongly_convex\", \"strongly_convex\", \"strongly_convex\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular_function\", \"submodular_function\", \"submodular_function\", \"submodular_function\", \"submodular_maximization\", \"submodular_maximization\", \"submodular_maximization\", \"submodular_maximization\", \"submodularity\", \"submodularity\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry\", \"tensor\", \"tensor\", \"tensor\", \"tensor\", \"texture\", \"texture\", \"texture\", \"texture\", \"time_series\", \"time_series\", \"time_series\", \"time_series\", \"time_step\", \"time_step\", \"time_step\", \"time_step\", \"titsias\", \"topic_model\", \"topic_model\", \"topic_model\", \"topic_model\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trial\", \"trial\", \"trial\", \"trial\", \"true_false\", \"true_false\", \"true_false\", \"true_false\", \"true_posterior\", \"true_posterior\", \"true_posterior\", \"true_posterior\", \"unlabeled_data\", \"unlabeled_data\", \"unlabeled_data\", \"unlabeled_data\", \"variational_distribution\", \"variational_distribution\", \"variational_inference\", \"variational_inference\", \"variational_inference\", \"variational_inference\", \"variational_parameter\", \"variational_parameter\", \"variational_parameter\", \"variational_posterior\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"vertex_edge\", \"vertex_edge\", \"very_deep\", \"visual_recognition\", \"visual_semantic\", \"walk\", \"walk\", \"walk\", \"walk\", \"weighted_graph\", \"weighted_graph\", \"weighted_graph\", \"weighted_graph\", \"wolsey\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 4, 2, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1021399098441442008286400133\", ldavis_el1021399098441442008286400133_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1021399098441442008286400133\", ldavis_el1021399098441442008286400133_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1021399098441442008286400133\", ldavis_el1021399098441442008286400133_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "2     -0.130500 -0.094436       1        1  32.010582\n",
              "3      0.005061  0.043572       2        1  25.281895\n",
              "1      0.179014 -0.042217       3        1  22.834398\n",
              "0     -0.053575  0.093081       4        1  19.873125, topic_info=                  Term         Freq        Total Category  logprob  loglift\n",
              "609             regret  1186.000000  1186.000000  Default  30.0000  30.0000\n",
              "3230  gaussian_process   899.000000   899.000000  Default  29.0000  29.0000\n",
              "2180     convolutional   653.000000   653.000000  Default  28.0000  28.0000\n",
              "3048  convergence_rate   935.000000   935.000000  Default  27.0000  27.0000\n",
              "3287        submodular   583.000000   583.000000  Default  26.0000  26.0000\n",
              "...                ...          ...          ...      ...      ...      ...\n",
              "29              belief   229.866821   418.006561   Topic4  -5.9429   1.0178\n",
              "1073             gibbs   226.657501   430.389893   Topic4  -5.9570   0.9746\n",
              "7                agent   209.414490   482.046814   Topic4  -6.0361   0.7821\n",
              "845       markov_chain   222.091339   813.919800   Topic4  -5.9773   0.3170\n",
              "2511              item   204.261658   602.441284   Topic4  -6.0610   0.5342\n",
              "\n",
              "[291 rows x 6 columns], token_table=      Topic      Freq                  Term\n",
              "term                                       \n",
              "1475      1  0.982718     absolute_constant\n",
              "1475      4  0.014242     absolute_constant\n",
              "4737      1  0.979575  accelerated_gradient\n",
              "3185      1  0.012290       active_learning\n",
              "3185      2  0.898676       active_learning\n",
              "...     ...       ...                   ...\n",
              "2132      1  0.065538        weighted_graph\n",
              "2132      2  0.010923        weighted_graph\n",
              "2132      3  0.010923        weighted_graph\n",
              "2132      4  0.917537        weighted_graph\n",
              "3302      4  0.977421                wolsey\n",
              "\n",
              "[821 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 4, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "864ddc392f72ba631bf372d038385d72301816ec",
        "_cell_guid": "aa6b35ff-22bf-44a7-ba48-2c7a368407fe",
        "id": "_cmy3kuwePQM",
        "colab_type": "text"
      },
      "source": [
        "** O que vemos aqui? **\n",
        "\n",
        "** O painel esquerdo **, rotulado Mapa de distância intertópica, os círculos representam diferentes tópicos e a distância entre eles. Tópicos semelhantes aparecem mais próximos e tópicos diferentes mais distantes.\n",
        "O tamanho relativo do círculo de um tópico no gráfico corresponde à frequência relativa do tópico no corpus.\n",
        "Um tópico individual pode ser selecionado para um exame mais detalhado clicando em seu círculo ou inserindo seu número na caixa \"tópico selecionado\" no canto superior esquerdo.\n",
        " \n",
        "** O painel direito ** inclui o gráfico de barras dos 30 principais termos. Quando nenhum tópico é selecionado no gráfico à esquerda, o gráfico de barras mostra os 30 termos mais \"salientes\" no corpus. A saliência de um termo é uma medida de quão frequente o termo é no corpus e quão \"distinto\" ele é na distinção entre diferentes tópicos.\n",
        "Selecionar cada tópico à direita modifica o gráfico de barras para mostrar os termos \"relevantes\" para o tópico selecionado.\n",
        "A relevância é definida como no rodapé 2 e pode ser ajustada pelo parâmetro $ \\ lambda $, menor $ \\ lambda $ dá maior peso à distinção do termo, enquanto $ \\ lambda $ s maior corresponde à probabilidade da ocorrência do termo por tópicos.\n",
        "\n",
        "Portanto, para ter uma noção melhor dos termos por tópico, usaremos $ \\ lambda $ = 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "132463131ee73972307d5a3560da8db816f519e2",
        "_cell_guid": "66d42d65-8258-40bf-9fb0-d304f4ed54ea",
        "id": "7oK7drBkePQN",
        "colab_type": "text"
      },
      "source": [
        "** Como avaliar nosso modelo? **\n",
        "Então, novamente, uma vez que não há base para aqui, temos que ser criativos na definição de maneiras de avaliar. Eu faço isso em duas etapas:\n",
        "\n",
        "1. divida cada documento em duas partes e veja se os tópicos atribuídos a eles são semelhantes. => quanto mais semelhante, melhor\n",
        "2. comparar documentos escolhidos aleatoriamente entre si. => quanto menos semelhante melhor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "71d492523a3cbcfd89141a9d13b66ac5a1f1f2e0",
        "_cell_guid": "b522a831-eb7e-4d54-a839-7d21d2194a96",
        "id": "JUcYXXBkePQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "p_df['tokenz'] = docs\n",
        "\n",
        "docs1 = p_df['tokenz'].apply(lambda l: l[:int0(len(l)/2)])\n",
        "docs2 = p_df['tokenz'].apply(lambda l: l[int0(len(l)/2):])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "60006b777f680005368652ec6a395d873b80b246",
        "_cell_guid": "b757e081-e199-4f92-8f86-22bd82050dc6",
        "id": "a8imGhSQePQR",
        "colab_type": "text"
      },
      "source": [
        "transformando os dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1e989bc95613b95e5d9c40c0f91f31b93b6c5aab",
        "_cell_guid": "c88c3646-2a4c-4e77-a6bf-e92ecdcbf627",
        "id": "MEzNe4rxePQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus1 = [dictionary.doc2bow(doc) for doc in docs1]\n",
        "corpus2 = [dictionary.doc2bow(doc) for doc in docs2]\n",
        "\n",
        "# Usando a transformação do modelo LDA corpus\n",
        "lda_corpus1 = model[corpus1]\n",
        "lda_corpus2 = model[corpus2]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "eea1742d65603d9463bc8689a501ac3fda4049c8",
        "_cell_guid": "d94655b5-1fb1-49ab-af80-90140319a040",
        "id": "TcxxA0HvePQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "def get_doc_topic_dist(model, corpus, kwords=False):\n",
        "    \n",
        "    '''\n",
        "   A transformação LDA, para cada doc retorna apenas tópicos com peso diferente de zero\n",
        "     Esta função faz uma transformação de matriz de documentos no espaço do tópico.\n",
        "    '''\n",
        "    top_dist =[]\n",
        "    keys = []\n",
        "\n",
        "    for d in corpus:\n",
        "        tmp = {i:0 for i in range(num_topics)}\n",
        "        tmp.update(dict(model[d]))\n",
        "        vals = list(OrderedDict(tmp).values())\n",
        "        top_dist += [array(vals)]\n",
        "        if kwords:\n",
        "            keys += [array(vals).argmax()]\n",
        "\n",
        "    return array(top_dist), keys"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "36f95ae8a010e1dfd3f441be37b179973c742b1a",
        "_cell_guid": "48443091-a545-47b3-87c5-69e27985d05c",
        "id": "9LtWaf14ePQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "591862ac-555d-4f7c-e715-9b4699d95a92"
      },
      "source": [
        "top_dist1, _ = get_doc_topic_dist(model, lda_corpus1)\n",
        "top_dist2, _ = get_doc_topic_dist(model, lda_corpus2)\n",
        "\n",
        "print(\"Intra similarity: cosine similarity for corresponding parts of a doc(higher is better):\")\n",
        "print(mean([cosine_similarity(c1.reshape(1, -1), c2.reshape(1, -1))[0][0] for c1,c2 in zip(top_dist1, top_dist2)]))\n",
        "\n",
        "random_pairs = np.random.randint(0, len(p_df['PaperText']), size=(400, 2))\n",
        "\n",
        "print(\"Inter similarity: cosine similarity between random parts (lower is better):\")\n",
        "print(np.mean([cosine_similarity(top_dist1[i[0]].reshape(1, -1), top_dist2[i[1]].reshape(1, -1)) for i in random_pairs]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intra similarity: cosine similarity for corresponding parts of a doc(higher is better):\n",
            "0.8952567\n",
            "Inter similarity: cosine similarity between random parts (lower is better):\n",
            "0.418154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d69f784d5b4a966efb9c7169938b312e53f25d6c",
        "_cell_guid": "91108906-bd63-4c7b-8b9d-fea0dc5776ce",
        "id": "H7xamNIQePQX",
        "colab_type": "text"
      },
      "source": [
        "## Vejamos os termos que aparecem mais em cada tópico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "5d5c2efcf69d5a7a8b4c15d747c3fac732fa1fd7",
        "_cell_guid": "521793ab-fd0d-4b31-a19c-238482821dfd",
        "id": "DTpyI9LfePQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def explore_topic(lda_model, topic_number, topn, output=True):\n",
        "    \"\"\"\n",
        "    accept a ldamodel, atopic number and topn vocabs of interest\n",
        "    prints a formatted list of the topn terms\n",
        "    \"\"\"\n",
        "    terms = []\n",
        "    for term, frequency in lda_model.show_topic(topic_number, topn=topn):\n",
        "        terms += [term]\n",
        "        if output:\n",
        "            print(u'{:20} {:.3f}'.format(term, round(frequency, 3)))\n",
        "    \n",
        "    return terms"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e61600b519fa785ac652a70782a23b229b28be51",
        "_cell_guid": "8b32274f-ca80-4bd7-88d1-41d207bd2bdd",
        "id": "u7p-T4BwePQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "9e87283a-81cc-4fbb-a160-e92744e4607e"
      },
      "source": [
        "topic_summaries = []\n",
        "print(u'{:20} {}'.format(u'term', u'frequency') + u'\\n')\n",
        "for i in range(num_topics):\n",
        "    print('Topic '+str(i)+' |---------------------\\n')\n",
        "    tmp = explore_topic(model,topic_number=i, topn=10, output=True )\n",
        "#     print tmp[:5]\n",
        "    topic_summaries += [tmp[:5]]\n",
        "    print"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "term                 frequency\n",
            "\n",
            "Topic 0 |---------------------\n",
            "\n",
            "vertex               0.007\n",
            "submodular           0.007\n",
            "random_walk          0.006\n",
            "graphical_model      0.005\n",
            "greedy               0.005\n",
            "tensor               0.005\n",
            "submodular_function  0.004\n",
            "data_set             0.004\n",
            "greedy_algorithm     0.004\n",
            "polynomial_time      0.004\n",
            "Topic 1 |---------------------\n",
            "\n",
            "convolutional        0.006\n",
            "fully_connected      0.005\n",
            "deep_learning        0.005\n",
            "recurrent            0.005\n",
            "recurrent_neural     0.005\n",
            "hidden_unit          0.005\n",
            "hidden_layer         0.005\n",
            "lstm                 0.005\n",
            "embedding            0.005\n",
            "pixel                0.004\n",
            "Topic 2 |---------------------\n",
            "\n",
            "regret               0.008\n",
            "convergence_rate     0.006\n",
            "matrix_completion    0.005\n",
            "step_size            0.005\n",
            "sample_complexity    0.005\n",
            "rank_matrix          0.005\n",
            "bandit               0.005\n",
            "gradient_descent     0.004\n",
            "singular_value       0.004\n",
            "strongly_convex      0.003\n",
            "Topic 3 |---------------------\n",
            "\n",
            "gaussian_process     0.008\n",
            "variational_inference 0.006\n",
            "active_learning      0.005\n",
            "policy               0.005\n",
            "trajectory           0.004\n",
            "posterior_distribution 0.004\n",
            "markov_chain         0.004\n",
            "reward_function      0.004\n",
            "state_space          0.003\n",
            "reinforcement_learning 0.003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "33ecddaa5755866ad6e9f8f7c5072859d09c27b4",
        "_cell_guid": "2bc62349-d01d-4fe7-8daf-7996155e8c70",
        "id": "aUUcA-29ePQb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "De cima, é possível inspecionar cada tópico e atribuir um rótulo interpretável por humanos a ele. Aqui, eu os rotulei da seguinte maneira:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a52935b629c3b73bfb9c76536bbc00826fbb8dbe",
        "_cell_guid": "76ffa777-cce7-46c8-b0fc-3762f514793d",
        "id": "VegHN20IePQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_labels = {0: 'Statistics', 1:'Numerical Analysis', 2:'Online Learning', 3:'Deep Learning'}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8a88e101807551ee914967e17d542204378db86a",
        "_cell_guid": "b8b9599c-c6d8-4d7a-a85e-3ec0aae9e951",
        "id": "dJeR75YnePQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a97a8dce-88da-49f9-93b6-a723b3d0674e"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "def paper_to_wordlist( paper, remove_stopwords=True ):\n",
        "    '''\n",
        "        Function converts text to a sequence of words,\n",
        "        Returns a list of words.\n",
        "    '''\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    # 1. Remove non-letters\n",
        "    paper_text = re.sub(\"[^a-zA-Z]\",\" \", paper)\n",
        "    # 2. Convert words to lower case and split them\n",
        "    words = paper_text.lower().split()\n",
        "    # 3. Remove stop words\n",
        "    words = [w for w in words if not w in stops]\n",
        "    # 4. Remove short words\n",
        "    words = [t for t in words if len(t) > 2]\n",
        "    # 5. lemmatizing\n",
        "    words = [nltk.stem.WordNetLemmatizer().lemmatize(t) for t in words]\n",
        "\n",
        "    return(words)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2VgF7ShUXgr",
        "colab_type": "text"
      },
      "source": [
        "###Agora vamos mudar a representação TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "3830dfd544633111cfa445aaf44260b2f0a03b32",
        "_cell_guid": "96d23559-83cd-41cd-9c5c-33bd55afe656",
        "id": "0nq7LaoXePQf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e08d9922-bff8-42ba-b1b2-12ea62517d6c"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tvectorizer = TfidfVectorizer(input='content', analyzer = 'word', lowercase=True, stop_words='english',\\\n",
        "                                  tokenizer=paper_to_wordlist, ngram_range=(1, 3), min_df=40, max_df=0.20,\\\n",
        "                                  norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
        "\n",
        "dtm = tvectorizer.fit_transform(p_df['PaperText']).toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['le'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "917fb65ed246a61182d9606c6b8cd786abaef53b",
        "_cell_guid": "630c13fe-57c6-49df-a2f5-2958b70a8271",
        "id": "cVpHotrQePQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_dist =[]\n",
        "for d in corpus:\n",
        "    tmp = {i:0 for i in range(num_topics)}\n",
        "    tmp.update(dict(model[d]))\n",
        "    vals = list(OrderedDict(tmp).values())\n",
        "    top_dist += [array(vals)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7422b187c28d1f2b6da57536a866a25fe9255e24",
        "_cell_guid": "8d2615ec-62b5-4443-b57c-39482093f7f8",
        "id": "JVecddqoePQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_dist, lda_keys= get_doc_topic_dist(model, corpus, True)\n",
        "features = tvectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "389811cde90d4989b10b4fd18d641f9e1896b746",
        "_cell_guid": "154bfbfe-1c83-4a27-9602-90fbc8c09741",
        "id": "O5h12b13ePQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_ws = []\n",
        "for n in range(len(dtm)):\n",
        "    inds = int0(argsort(dtm[n])[::-1][:4])\n",
        "    tmp = [features[i] for i in inds]\n",
        "    \n",
        "    top_ws += [' '.join(tmp)]\n",
        "    \n",
        "p_df['Text_Rep'] = pd.DataFrame(top_ws)\n",
        "p_df['clusters'] = pd.DataFrame(lda_keys)\n",
        "p_df['clusters'].fillna(10, inplace=True)\n",
        "\n",
        "cluster_colors = {0: 'blue', 1: 'green', 2: 'yellow', 3: 'red', 4: 'skyblue', 5:'salmon', 6:'orange', 7:'maroon', 8:'crimson', 9:'black', 10:'gray'}\n",
        "\n",
        "p_df['colors'] = p_df['clusters'].apply(lambda l: cluster_colors[l])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d16af6cfc14d9b8d7d3ac9851e2d4d3ceefe0cc1",
        "_cell_guid": "a356fc0e-e589-4e5d-b5da-f03328c9dc27",
        "id": "ka5FBNz0ePQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(n_components=2)\n",
        "X_tsne = tsne.fit_transform(top_dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6e23799bea222f5acb56add0c481c1b0c82fed8b",
        "_cell_guid": "b62decb3-60e7-4e20-8319-a3fbda8ee1bc",
        "id": "6_lKtUD9ePQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p_df['X_tsne'] =X_tsne[:, 0]\n",
        "p_df['Y_tsne'] =X_tsne[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1f1d4ff6071ed132a4a6a68e86987e65f8bd5956",
        "_cell_guid": "cc8deea2-d651-4eb9-8928-28882e091c3c",
        "id": "Mg1RoPNqePQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bokeh.plotting import figure, show, output_notebook, save#, output_file\n",
        "from bokeh.models import HoverTool, value, LabelSet, Legend, ColumnDataSource\n",
        "output_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "27ddd00b2085860a52118d995cf7c461885cefb4",
        "_cell_guid": "153dde79-a07b-4041-81ce-e0d2cf4c2f24",
        "id": "wyWH8P3QePQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source = ColumnDataSource(dict(\n",
        "    x=p_df['X_tsne'],\n",
        "    y=p_df['Y_tsne'],\n",
        "    color=p_df['colors'],\n",
        "    label=p_df['clusters'].apply(lambda l: top_labels[l]),\n",
        "#     msize= p_df['marker_size'],\n",
        "    topic_key= p_df['clusters'],\n",
        "    title= p_df[u'Title'],\n",
        "    content = p_df['Text_Rep']\n",
        "))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ecb9b9f46894e857788141b271be186fb8ffcb2e",
        "_cell_guid": "2c2e7018-1fc5-4f85-a205-2ae00be40845",
        "id": "G_oGpSu7ePQu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "12b37967-7d2a-42a4-9b34-826d58571386"
      },
      "source": [
        "title = 'T-SNE visualization of topics'\n",
        "\n",
        "plot_lda = figure(plot_width=1000, plot_height=600,\n",
        "                     title=title, tools=\"pan,wheel_zoom,box_zoom,reset,hover\",\n",
        "                     x_axis_type=None, y_axis_type=None, min_border=1)\n",
        "\n",
        "plot_lda.scatter(x='x', y='y', legend='label', source=source,\n",
        "                 color='color', alpha=0.8, size=10)#'msize', )\n",
        "\n",
        "# hover tools\n",
        "hover = plot_lda.select(dict(type=HoverTool))\n",
        "hover.tooltips = {\"content\": \"Title: @title, KeyWords: @content - Topic: @topic_key \"}\n",
        "plot_lda.legend.location = \"top_left\"\n",
        "\n",
        "show(plot_lda)\n",
        "\n",
        "#save the plot\n",
        "# save(plot_lda, '{}.html'.format(title))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
              "\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      if (url in hashes) {\n",
              "        element.crossOrigin = \"anonymous\";\n",
              "        element.integrity = \"sha384-\" + hashes[url];\n",
              "      }\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"c7c96293-5396-4cbc-b75e-f4a795f0181e\" data-root-id=\"1155\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"34a0a1ac-90e1-4a7c-aa78-744b3bebbe67\":{\"roots\":{\"references\":[{\"attributes\":{\"center\":[{\"id\":\"1187\"}],\"min_border\":1,\"plot_width\":1000,\"renderers\":[{\"id\":\"1181\"}],\"title\":{\"id\":\"1156\"},\"toolbar\":{\"id\":\"1172\"},\"x_range\":{\"id\":\"1158\"},\"x_scale\":{\"id\":\"1162\"},\"y_range\":{\"id\":\"1160\"},\"y_scale\":{\"id\":\"1164\"}},\"id\":\"1155\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"label\":{\"field\":\"label\"},\"renderers\":[{\"id\":\"1181\"}]},\"id\":\"1188\",\"type\":\"LegendItem\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1171\",\"type\":\"BoxAnnotation\"},{\"attributes\":{},\"id\":\"1162\",\"type\":\"LinearScale\"},{\"attributes\":{\"text\":\"T-SNE visualization of topics\"},\"id\":\"1156\",\"type\":\"Title\"},{\"attributes\":{\"overlay\":{\"id\":\"1171\"}},\"id\":\"1168\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1160\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1185\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1180\",\"type\":\"Scatter\"},{\"attributes\":{\"source\":{\"id\":\"1154\"}},\"id\":\"1182\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1166\",\"type\":\"PanTool\"},{\"attributes\":{\"items\":[{\"id\":\"1188\"}],\"location\":\"top_left\"},\"id\":\"1187\",\"type\":\"Legend\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.8},\"fill_color\":{\"field\":\"color\"},\"line_alpha\":{\"value\":0.8},\"line_color\":{\"field\":\"color\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1179\",\"type\":\"Scatter\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"content\",\"Title: @title, KeyWords: @content - Topic: @topic_key \"]]},\"id\":\"1170\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1167\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1169\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1164\",\"type\":\"LinearScale\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1166\"},{\"id\":\"1167\"},{\"id\":\"1168\"},{\"id\":\"1169\"},{\"id\":\"1170\"}]},\"id\":\"1172\",\"type\":\"Toolbar\"},{\"attributes\":{\"data\":{\"color\":[\"yellow\",\"yellow\",\"blue\",\"blue\",\"blue\",\"blue\",\"yellow\",\"green\",\"red\",\"green\",\"red\",\"green\",\"green\",\"green\",\"red\",\"yellow\",\"blue\",\"blue\",\"red\",\"blue\",\"green\",\"red\",\"red\",\"yellow\",\"green\",\"blue\",\"red\",\"blue\",\"red\",\"red\",\"green\",\"blue\",\"red\",\"green\",\"yellow\",\"green\",\"green\",\"blue\",\"green\",\"yellow\",\"red\",\"blue\",\"green\",\"green\",\"blue\",\"green\",\"green\",\"red\",\"yellow\",\"red\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"green\",\"blue\",\"blue\",\"green\",\"green\",\"blue\",\"green\",\"green\",\"blue\",\"red\",\"green\",\"yellow\",\"yellow\",\"green\",\"yellow\",\"yellow\",\"red\",\"red\",\"red\",\"yellow\",\"green\",\"red\",\"green\",\"yellow\",\"yellow\",\"green\",\"green\",\"green\",\"blue\",\"green\",\"green\",\"green\",\"yellow\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"green\",\"green\",\"red\",\"green\",\"blue\",\"red\",\"yellow\",\"red\",\"blue\",\"red\",\"yellow\",\"red\",\"yellow\",\"blue\",\"yellow\",\"red\",\"blue\",\"green\",\"green\",\"yellow\",\"green\",\"green\",\"yellow\",\"blue\",\"blue\",\"green\",\"blue\",\"green\",\"yellow\",\"red\",\"red\",\"red\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"red\",\"green\",\"green\",\"blue\",\"blue\",\"green\",\"green\",\"red\",\"blue\",\"red\",\"green\",\"yellow\",\"green\",\"green\",\"yellow\",\"green\",\"yellow\",\"yellow\",\"red\",\"yellow\",\"yellow\",\"yellow\",\"green\",\"red\",\"blue\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"yellow\",\"blue\",\"blue\",\"green\",\"red\",\"red\",\"red\",\"blue\",\"blue\",\"green\",\"yellow\",\"green\",\"green\",\"green\",\"yellow\",\"green\",\"blue\",\"green\",\"yellow\",\"green\",\"green\",\"blue\",\"green\",\"blue\",\"green\",\"blue\",\"red\",\"green\",\"yellow\",\"yellow\",\"yellow\",\"blue\",\"blue\",\"green\",\"yellow\",\"green\",\"blue\",\"yellow\",\"yellow\",\"yellow\",\"green\",\"red\",\"red\",\"green\",\"red\",\"yellow\",\"green\",\"red\",\"blue\",\"yellow\",\"green\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"blue\",\"yellow\",\"blue\",\"red\",\"blue\",\"green\",\"red\",\"green\",\"yellow\",\"blue\",\"red\",\"green\",\"red\",\"blue\",\"green\",\"yellow\",\"green\",\"yellow\",\"blue\",\"yellow\",\"yellow\",\"yellow\",\"blue\",\"green\",\"green\",\"red\",\"yellow\",\"green\",\"green\",\"red\",\"green\",\"yellow\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"green\",\"green\",\"yellow\",\"blue\",\"green\",\"red\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\",\"red\",\"red\",\"yellow\",\"red\",\"blue\",\"blue\",\"blue\",\"yellow\",\"yellow\",\"green\",\"yellow\",\"red\",\"green\",\"yellow\",\"blue\",\"green\",\"red\",\"green\",\"blue\",\"green\",\"blue\",\"blue\",\"green\",\"yellow\",\"green\",\"green\",\"red\",\"red\",\"green\",\"blue\",\"green\",\"yellow\",\"green\",\"blue\",\"yellow\",\"blue\",\"red\",\"green\",\"red\",\"blue\",\"yellow\",\"yellow\",\"yellow\",\"green\",\"green\",\"blue\",\"red\",\"green\",\"green\",\"green\",\"blue\",\"green\",\"blue\",\"yellow\",\"yellow\",\"blue\",\"red\",\"yellow\",\"red\",\"red\",\"yellow\",\"red\",\"blue\",\"green\",\"green\",\"blue\",\"red\",\"green\",\"yellow\",\"green\",\"red\",\"red\",\"yellow\",\"green\",\"blue\",\"red\",\"blue\",\"green\",\"green\",\"yellow\",\"yellow\",\"green\",\"blue\",\"yellow\",\"green\",\"yellow\",\"yellow\",\"yellow\",\"yellow\",\"blue\",\"blue\",\"green\",\"green\",\"green\",\"red\",\"yellow\",\"green\",\"yellow\",\"blue\",\"yellow\",\"red\",\"blue\",\"blue\",\"yellow\",\"green\",\"blue\",\"blue\",\"green\",\"green\",\"green\",\"blue\",\"green\",\"blue\",\"yellow\",\"yellow\",\"red\",\"blue\",\"blue\",\"blue\",\"yellow\",\"blue\",\"blue\",\"red\",\"yellow\",\"blue\",\"red\",\"green\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\"],\"content\":[\"mechanism answer confidence multiplicative\",\"robustness learner svm equivalence\",\"stability vol training example parametric\",\"dirichlet mixture model concentration hyperparameters\",\"covariance matrix article maintaining letter\",\"covariance matrix rate convergence tail oracle\",\"leaf logarithmic pure left right\",\"segmentation closest plane vertex\",\"retrieval post recurrent query\",\"vertex round item permutation\",\"proposal box shared convolutional\",\"manifold embeddings embedding euclidean\",\"svd descent algorithm retrieval jain\",\"real valued utility cover feedback\",\"physical video physic mass\",\"item sample complexity pseudo price\",\"neuron trial population stationary\",\"manifold digit locally low dimensional\",\"color pixel fold end end\",\"ranking item stationary pairwise\",\"sgd step size gaussian process mnist\",\"recurrent list hidden unit hidden layer\",\"grid ground truth convolutional social\",\"regret learner expert reward\",\"law eigenvalue polynomial time orthogonal\",\"sampler boundary step size biased\",\"video resolution convolution recurrent\",\"moment concave hybrid mode\",\"embedding embeddings parametric auxiliary\",\"convolutional convolutional neural network convolutional neural spatial\",\"averaging auxiliary communication propagation\",\"identification dirichlet mixture model central\",\"svm white category ball\",\"soft subgradient accelerated relaxation\",\"regret retrieval confidence existence\",\"smoothing manifold principal green\",\"svm biased ranking conjugate\",\"trajectory policy reinforcement learning reinforcement\",\"orthogonal factorization svd pca\",\"regret greedy reward maximal\",\"segmentation extra semantic feature vector\",\"neuron posterior distribution stationary inherent\",\"accelerated gradient method critical convergence rate\",\"pca principal component sketch principal\",\"functional nonparametric expansion theoretic\",\"round singular value singular reconstruction\",\"non convex kdd supplement cpu\",\"proposal box overlap plane\",\"regret budget reward boundary\",\"fully connected hidden unit number parameter convolutional\",\"mcmc partitioning sampler smoothing\",\"shared segment brain functional\",\"cell biological root mark\",\"backward greedy reward trajectory\",\"moment mixture model gaussians kakade\",\"width away strongly convex oracle\",\"recurrent neural network recurrent neural interaction recurrent\",\"moment document dirichlet component analysis\",\"sensing retrieval low rank rank matrix\",\"marginals solver vertex iterates\",\"mixing stationary sup exp exp\",\"svd embedding embeddings pairwise\",\"alternating oracle completion rank matrix\",\"variational inference automatic mixture model dirichlet\",\"speech mechanism content recurrent\",\"regression model closed form thresholding exponential family\",\"learner pas online learning regret\",\"item ranking pairwise marginals\",\"diverse energy segmentation ordered\",\"vertex width cover polynomial time\",\"ordering undirected directed vol\",\"boltzmann hidden unit expansion epoch\",\"article convolutional corpus language processing\",\"discriminative brain proposed method labeled\",\"partitioning regret smoothness cell\",\"vertex community recovery regime\",\"momentum communication imagenet moving\",\"greedy item vertex disjoint\",\"oracle query weak false\",\"globally margin classification problem time complexity\",\"recovery thresholding solver dense\",\"embeddings embedding learner ensemble\",\"truncated retrieval kxk flow\",\"trajectory population gaussian process cause\",\"subspace inner product counterpart segmentation\",\"pca vol disjoint extracted\",\"leverage bach running time low rank\",\"regret policy round strongly convex\",\"neuron diag filter moment\",\"flow cell convolutional digit\",\"logistic regression solver regularization parameter radius\",\"boltzmann calculation probabilistic model normalization\",\"stat digit gaussian process modelling\",\"precision false segment figure left\",\"budget greedy cover allocation\",\"missing mcmc recurrent neural network recurrent neural\",\"mini accelerated strongly convex maxi\",\"mixing strongly convex markov chain mcmc\",\"hessian recurrent neural network recurrent neural recurrent\",\"predictor fold minimax proper\",\"resolution translation convolutional convolutional neural network\",\"manifold mixture model euclidean convexity\",\"embeddings embedding convolution error rate\",\"grid cpu depth recursive\",\"labeling recurrent convolutional pixel\",\"leaf assignment store conditioning\",\"mcmc markov chain flow exponential family\",\"resource regret allocation confidence\",\"shape learner unsupervised solver\",\"neuron recurrent balance feedback\",\"sketch gibbs moment latent variable model\",\"subspace gibbs utility sampler\",\"margin ranking document learner\",\"characterization embedding embeddings geometric\",\"sgd ranking computational cost estimation error\",\"vertex sample complexity reward round\",\"brain dot trial neuron\",\"bayes discriminative naive logistic regression\",\"round closest counterpart assigned\",\"walk list semantic item\",\"rate convergence precision frobenius estimation error\",\"fisher linear model query convergence rate\",\"pose recurrent face manifold\",\"softmax cpu hidden layer backpropagation\",\"neuron backpropagation vol ensemble\",\"zhu formed flow fold\",\"fully connected neuron bit imagenet\",\"compact characteristic vol rate convergence\",\"population dirichlet held variational inference\",\"integration integral posterior distribution model selection\",\"recurrent neural network recurrent neural recurrent model trained\",\"completion width estimation error sample complexity\",\"sun regularizer definite unconstrained\",\"proposal segmentation sampler dirichlet\",\"mcmc concave moment bayes\",\"hessian convergence rate second order step size\",\"nearest neighbor query sensitive\",\"video manifold temporal locally\",\"walk mixing ball box\",\"manifold pose query embedding\",\"hessian completion vol retrieval\",\"round regret feedback online learning\",\"leaf solver depth iii\",\"vertex perfect auxiliary vol\",\"item regret factorization cumulative\",\"journal optimization unconstrained stanford hessian\",\"permutation proc formula ordering\",\"greedy event strength confidence\",\"robustness transform transformed face\",\"regret reward treatment outcome\",\"ensemble game predictor leaf\",\"regret feedback minimax learner\",\"differential vertex nonparametric maximal\",\"proposal box greedy bounding\",\"hessian backpropagation variational inference auto\",\"singular singular value frobenius svd\",\"proposed method embeddings document embedding\",\"gaussian process error rate variational inference gaussians\",\"markov chain walk max max trajectory\",\"proposal wainwright pairwise confidence\",\"exponential family mcmc gibbs formula\",\"item regret reward combinatorial\",\"mixing markov chain confidence stationary\",\"policy formula trajectory sensitive\",\"concave stability strongly convex minimizer\",\"resolution model trained conditioning boltzmann\",\"segmentation semantic activation pixel\",\"hessian sgd non convex mnist\",\"environment shift strength covariance matrix\",\"perturbation policy budget robustness\",\"epoch linear regression fraction kxk\",\"environment hyper learner posterior distribution\",\"bit link compressed sensing\",\"invariant integration vol sample complexity\",\"estimation error mixed regularizer linear regression\",\"history stochastic optimization policy recursive\",\"locally convex function sgd lipschitz\",\"filtering coding population neuron\",\"pca relaxation moment principal component\",\"majority margin discriminative error rate\",\"stopping epoch inf iterates\",\"walk vertex geometric kxk\",\"gaussian process mcmc sampler gibbs\",\"leverage model selection statistical learning regularization parameter\",\"inference algorithm markov chain state space trajectory\",\"regularization parameter option grid support vector\",\"environment neuron spatial reward\",\"query document reader corpus\",\"projected relaxation population subgradient\",\"policy filter belief claim\",\"vertex directed mixed undirected\",\"leaf depth greedy augmented\",\"manifold video gaussian process missing\",\"reward expert trajectory segment\",\"round communication strongly convex convex function\",\"discriminative gibbs document dirichlet\",\"greedy decay bit zhou\",\"self normalization linear model characterization\",\"regret game learner round\",\"ranking proc social dot\",\"non linear proc closer link\",\"rank matrix pca low rank completion\",\"recurrent translation strength scalar\",\"margin discriminative missing subgradient\",\"positive definite transform compact definite\",\"projected coding reconstruction hidden unit\",\"identification ordering list independence\",\"completion rank matrix low rank lipschitz\",\"retrieval style embedding margin\",\"sampler gibbs mcmc mixture model\",\"item greedy partitioning vertex\",\"item rank matrix ranking low rank\",\"spatial frequency stationary width\",\"pixel neighborhood recurrent ensemble\",\"compressed low rank missing pca\",\"mixing gibbs sampler state space\",\"event link evolution social\",\"linear regression filtering moment history\",\"regret game history calculate\",\"characteristic analytic embeddings frequency\",\"proposal segmentation box pixel\",\"spectrum gaussian process frequency brain\",\"bit differential communication symposium\",\"spatial digit grid transformed\",\"critical radius inf tight\",\"svm margin vol structural\",\"neuron vol population trial\",\"digit semantic segmentation ground truth\",\"bit kxk sensing compressed\",\"fisher sgd conditioning normalization\",\"population ball mcmc manifold\",\"iterates scaled adapt hybrid\",\"document proportion variational inference dirichlet\",\"completion multiplication factorization rank matrix\",\"regret reward combinatorial feedback\",\"environment reward internal reinforcement learning\",\"smoothing walk compressed event\",\"regret min max oracle competitive\",\"policy budget leaf reward\",\"sampler hybrid mass biased\",\"query ensemble runtime coding\",\"smoothness svm locally ball\",\"pixel segmentation spatial theoretic\",\"regret perturbation penalty learner\",\"width sample complexity estimation error recovery\",\"embeddings vertex embedding mnist\",\"feature vector convolutional depth convolutional neural\",\"partitioning round segmentation greedy\",\"query answer supplement compact\",\"mixed support vector convergence rate grow\",\"formula vol dirichlet distinguish\",\"neuron principal thresholding eigenvalue\",\"step size mcmc invariant backward\",\"exponential family random field neighborhood undirected\",\"answer embedding translation content\",\"sgd epoch step size neighborhood\",\"integral policy trial trajectory\",\"approximating propagation gaussians moment\",\"concave relaxation cover tight\",\"pca subspace mini component analysis\",\"differential query data analysis overfitting\",\"price utility belief budget\",\"augmented iterates solver projected\",\"depth transform deep network mnist\",\"model selection gaussian process hyperparameters frequency\",\"sampler gibbs mixing state space\",\"manifold trajectory shift mcmc\",\"reward confidence trial dot\",\"sgd regularizer geometry invariant\",\"article sign predictor non zero\",\"softmax embedding answer recurrent\",\"frequency filter spatial conjugate\",\"regret learner base online learning\",\"hidden layer temporal recurrent belief\",\"cell electrical identification completion\",\"vol trial internal recovers\",\"spectrum physical resolution energy\",\"configuration software detect researcher\",\"cause independence identified directed\",\"latent variable model variable model rate convergence low dimensional\",\"price regret round game\",\"face neuron pose light\",\"low rank mode recovery rank matrix\",\"minimax regret round game\",\"differential running time sample size synthetic data\",\"sample complexity uci lipschitz nearest\",\"recurrent resolution proposal reinforcement learning\",\"error bound regularization parameter random field frobenius\",\"mixing markov chain sample size vol\",\"missing frobenius alternating ground truth\",\"proposal recurrent recurrent neural network recurrent neural\",\"variational inference gibbs mnist integration\",\"epoch iterate step size sgd\",\"query web embedding answer\",\"frequency recovery resolution minimal\",\"sgd precision non convex bit\",\"dot discriminative run time page ieee\",\"softmax mechanism input output combinatorial\",\"recovery store kxk subspace\",\"gibbs factorization corpus non negative\",\"vertex solver hessian minimizer\",\"game item precision ranking\",\"shared agarwal convergence rate mainly\",\"trajectory locally non linear reconstruction\",\"query epoch hyper parameter regret\",\"soft state space plan reinforcement learning\",\"corpus web ensemble google\",\"oracle recovery low rank covariance matrix\",\"convolutional filter hidden unit mnist\",\"dirichlet corpus document mcmc\",\"regret depth optimization method iii\",\"reward policy reinforcement learning reinforcement\",\"relaxation semantic relaxed translation\",\"vertex assignment singular running time\",\"accelerated trajectory interpretation differential\",\"gaussian process learner ranking covariance matrix\",\"game recurrent encoding video\",\"recovery gaussian noise recovering fourth\",\"round utility cover greedy\",\"community overlapping walk vertex\",\"state space reward base reinforcement learning\",\"width sign ball sup\",\"sampler mcmc stationary supplement\",\"regret self averaging perturbation\",\"vertex game flow labeled\",\"policy trajectory environment reward\",\"answer color vol embeddings\",\"auto ensemble hyperparameters configuration\",\"boltzmann euclidean sgd mnist\",\"modelling speech recurrent recurrent neural network\",\"regret game utility item\",\"segmentation pixel brain fully connected\",\"momentum boundary trajectory tuned\",\"neighbor link dense regime\",\"differential width vertex mechanism\",\"price outcome subspace belief\",\"hidden unit width hidden layer dirichlet\",\"hessian convergence rate eigenvalue sgd\",\"game regret price correlated\",\"universal hilbert space hilbert treatment\",\"recurrent document labeled error rate\",\"diag multiplication false sharing\",\"width gibbs mixing polynomial time\",\"subspace mode singular gaussian noise\",\"policy robustness environment trajectory\",\"regularizer backward propagation mnist\",\"trajectory policy feedback physical\",\"unconstrained diverse cardinality document\",\"universal vol accelerated gradient method\",\"ordering correctly examine greedy\",\"regret learner exploration game\",\"singular low rank pas singular value\",\"time step polynomial time sample complexity social\",\"directed undirected vol vertex\",\"oracle query concave convex function\",\"library gibbs document boundary\",\"gibbs embeddings dirichlet scalability\",\"overfitting feedback self policy\",\"formula equivalence assignment cell\",\"policy trajectory primary directed\",\"bayes strictly characterization link\",\"exp exp uai supplement log exp\",\"marginals twice feature vector stanford\",\"eigenvalue recovery grow community\",\"thought semantic translation corpus\",\"loop directed stopping compressed\",\"principal pca principal component color\",\"utility population averaging bayes\",\"regret gaussian process mcmc greedy\",\"mixing regret reward stationary\",\"brain logistic regression hidden layer reconstruction\",\"gaussian process random field spatial event\",\"tail detect post random field\",\"expert regret sup oracle\",\"strongly convex accelerated convergence rate rate convergence\",\"realization variational inference pseudo gaussian process\",\"conjugate variational inference diag geometry\",\"oracle smoothing enjoys sec\",\"regularizer precise non linear sign\",\"walk vertex neighborhood neighbor\",\"sgd mcmc hyper parameter precision\",\"completion sample complexity item recovery\",\"gibbs correlated auxiliary dirichlet\",\"query game utility stanford\",\"event confidence marginals margin\",\"segmentation pixel labeling neuron\",\"item event temporal history\",\"white gaussian process filter convolution\",\"price mechanism query exponential family\",\"formula proc canonical equality\",\"reinforcement learning reinforcement backpropagation surrogate\",\"surrogate policy reward considerably\",\"supervised learning mnist cost function unsupervised\",\"margin assignment embedding arg max\",\"variational inference factorization gaussians augmented\",\"recursive boundary segmentation dense\",\"augmented strongly convex solver regularizer\",\"sample complexity vol concave independence\",\"vol soft structural functional\",\"proposal belief exponential family propagation\",\"energy population modelling summary\",\"logistic regression radius ball confidence\",\"variational inference epoch activation trick\"],\"label\":[\"Online Learning\",\"Online Learning\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\",\"Online Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Numerical Analysis\",\"Deep Learning\",\"Online Learning\",\"Statistics\",\"Statistics\",\"Deep Learning\",\"Statistics\",\"Numerical Analysis\",\"Deep Learning\",\"Deep Learning\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Statistics\",\"Deep Learning\",\"Deep Learning\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Online Learning\",\"Deep Learning\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Deep Learning\",\"Online Learning\",\"Deep Learning\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Online Learning\",\"Numerical Analysis\",\"Online Learning\",\"Online Learning\",\"Deep Learning\",\"Deep Learning\",\"Deep Learning\",\"Online Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Numerical Analysis\",\"Online Learning\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Deep Learning\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Online Learning\",\"Deep Learning\",\"Statistics\",\"Deep Learning\",\"Online Learning\",\"Deep Learning\",\"Online Learning\",\"Statistics\",\"Online Learning\",\"Deep Learning\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Online Learning\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Online Learning\",\"Deep Learning\",\"Deep Learning\",\"Deep Learning\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Deep Learning\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Online Learning\",\"Online Learning\",\"Deep Learning\",\"Online Learning\",\"Online Learning\",\"Online Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Statistics\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\",\"Online Learning\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Deep Learning\",\"Deep Learning\",\"Deep Learning\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Online Learning\",\"Online Learning\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Online Learning\",\"Online Learning\",\"Online Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Deep Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Online Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Statistics\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Statistics\",\"Online Learning\",\"Statistics\",\"Deep Learning\",\"Statistics\",\"Numerical Analysis\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Statistics\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Online Learning\",\"Statistics\",\"Online Learning\",\"Online Learning\",\"Online Learning\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Deep Learning\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Online Learning\",\"Statistics\",\"Numerical Analysis\",\"Deep Learning\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Deep Learning\",\"Online Learning\",\"Deep Learning\",\"Statistics\",\"Statistics\",\"Statistics\",\"Online Learning\",\"Online Learning\",\"Numerical Analysis\",\"Online Learning\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Statistics\",\"Numerical Analysis\",\"Deep Learning\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Deep Learning\",\"Deep Learning\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Online Learning\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Statistics\",\"Online Learning\",\"Online Learning\",\"Online Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Statistics\",\"Online Learning\",\"Online Learning\",\"Statistics\",\"Deep Learning\",\"Online Learning\",\"Deep Learning\",\"Deep Learning\",\"Online Learning\",\"Deep Learning\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Online Learning\",\"Numerical Analysis\",\"Deep Learning\",\"Deep Learning\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Deep Learning\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Online Learning\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Online Learning\",\"Numerical Analysis\",\"Online Learning\",\"Online Learning\",\"Online Learning\",\"Online Learning\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Numerical Analysis\",\"Deep Learning\",\"Online Learning\",\"Numerical Analysis\",\"Online Learning\",\"Statistics\",\"Online Learning\",\"Deep Learning\",\"Statistics\",\"Statistics\",\"Online Learning\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Numerical Analysis\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Numerical Analysis\",\"Statistics\",\"Online Learning\",\"Online Learning\",\"Deep Learning\",\"Statistics\",\"Statistics\",\"Statistics\",\"Online Learning\",\"Statistics\",\"Statistics\",\"Deep Learning\",\"Online Learning\",\"Statistics\",\"Deep Learning\",\"Numerical Analysis\",\"Numerical Analysis\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\",\"Statistics\"],\"title\":[\"Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing\",\"Learning with Symmetric Label Noise: The Importance of Being Unhinged\",\"Algorithmic Stability and Uniform Generalization\",\"Adaptive Low-Complexity Sequential Inference for Dirichlet Process Mixture Models\",\"Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling\",\"Robust Portfolio Optimization\",\"Logarithmic Time Online Multiclass prediction\",\"Planar Ultrametrics for Image Segmentation\",\"Expressing an Image Stream with a Sequence of Natural Sentences\",\"Parallel Correlation Clustering on Big Graphs\",\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"Space-Time Local Embeddings\",\"A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements\",\"Smooth Interactive Submodular Set Cover\",\"Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning\",\"On the Pseudo-Dimension of Nearly Optimal Auctions\",\"Unlocking neural population non-stationarities using hierarchical dynamics models\",\"Bayesian Manifold Learning: The Locally Linear Latent Variable Model (LL-LVM)\",\"Color Constancy by Learning to Predict Chromaticity from Luminance\",\"Fast and Accurate Inference of Plackett\\u2013Luce Models\",\"Probabilistic Line Searches for Stochastic Optimization\",\"Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets\",\"Where are they looking?\",\"The Pareto Regret Frontier for Bandits\",\"On the Limitation of Spectral Methods: From the Gaussian Hidden Clique Problem to Rank-One Perturbations of Gaussian Tensors\",\"Measuring Sample Quality with Stein's Method\",\"Bidirectional Recurrent Convolutional Networks for Multi-Frame Super-Resolution\",\"Bounding errors of Expectation-Propagation\",\"A fast, universal algorithm to learn parametric nonlinear embeddings\",\"Texture Synthesis Using Convolutional Neural Networks\",\"Extending Gossip Algorithms to Distributed Estimation of U-statistics\",\"Streaming, Distributed Variational Inference for Bayesian Nonparametrics\",\"Learning visual biases from human imagination\",\"Smooth and Strong: MAP Inference with Linear Convergence\",\"Copeland Dueling Bandits\",\"Optimal Ridge Detection using Coverage Risk\",\"Top-k Multiclass SVM\",\"Policy Evaluation Using the \\u03a9-Return\",\"Orthogonal NMF through Subspace Exploration\",\"Stochastic Online Greedy Learning with Semi-bandit Feedbacks\",\"Deeply Learning the Messages in Message Passing Inference\",\"Synaptic Sampling: A Bayesian Approach to Neural Network Plasticity and Rewiring\",\"Accelerated Proximal Gradient Methods for Nonconvex Programming\",\"Approximating Sparse PCA from Incomplete Data\",\"Nonparametric von Mises Estimators for Entropies, Divergences and Mutual Informations\",\"Column Selection via Adaptive Sampling\",\"HONOR: Hybrid Optimization for NOn-convex Regularized problems\",\"3D Object Proposals for Accurate Object Class Detection\",\"Algorithms with Logarithmic or Sublinear Regret for  Constrained Contextual Bandits\",\"Tensorizing Neural Networks\",\"Parallelizing MCMC with Random Partition Trees\",\"A Reduced-Dimension fMRI Shared Response Model\",\"Spectral Learning of Large Structured HMMs for Comparative Epigenomics\",\"Individual Planning in Infinite-Horizon Multiagent Settings: Inference, Structure and Scalability\",\"Estimating Mixture Models via Mixtures of Polynomials\",\"On the Global Linear Convergence of Frank-Wolfe Optimization Variants\",\"Deep Knowledge Tracing\",\"Rethinking LDA: Moment Matching for Discrete ICA\",\"Efficient Compressive Phase Retrieval with Constrained Sensing Vectors\",\"Barrier Frank-Wolfe for Marginal Inference\",\"Learning Theory and Algorithms for Forecasting Non-stationary Time Series\",\"Compressive spectral embedding: sidestepping the SVD\",\"A Nonconvex Optimization Framework for Low Rank Matrix Estimation\",\"Automatic Variational Inference in Stan\",\"Attention-Based Models for Speech Recognition\",\"Closed-form Estimators for High-dimensional Generalized Linear Models\",\"Online F-Measure Optimization\",\"Online Rank Elicitation for Plackett-Luce: A Dueling Bandits Approach\",\"M-Best-Diverse Labelings for Submodular Energies and Beyond\",\"Tractable Bayesian Network Structure Learning with Bounded Vertex Cover Number\",\"Learning Large-Scale Poisson DAG Models based on OverDispersion Scoring\",\"Training Restricted Boltzmann Machine via the \\ufffcThouless-Anderson-Palmer free energy\",\"Character-level Convolutional Networks for Text Classification\",\"Robust Feature-Sample Linear Discriminant Analysis for Brain Disorders Diagnosis\",\"Black-box optimization of noisy functions with unknown smoothness\",\"Recovering Communities in the General Stochastic Block Model Without Knowing the Parameters\",\"Deep learning with Elastic Averaging SGD\",\"Monotone k-Submodular Function Maximization with Size Constraints\",\"Active Learning from Weak and Strong Labelers\",\"On the Optimality of Classifier Chain for Multi-label Classification\",\"Robust Regression via Hard Thresholding\",\"Sparse Local Embeddings for Extreme Multi-label Classification\",\"Solving Random Quadratic Systems of Equations Is Nearly as Easy as Solving Linear Systems\",\"A Framework for Individualizing Predictions of Disease Trajectories by Exploiting Multi-Resolution Structure\",\"Subspace Clustering with Irrelevant Features via Robust Dantzig Selector\",\"Sparse PCA via Bipartite Matchings\",\"Fast Randomized Kernel Ridge Regression with Statistical Guarantees\",\"Online Learning for Adversaries with Memory: Price of Past Mistakes\",\"Convolutional spike-triggered covariance analysis for neural subunit models\",\"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\",\"GAP Safe screening rules for sparse multi-task and multi-class models\",\"Empirical Localization of Homogeneous Divergences on Discrete Sample Spaces\",\"Statistical Model Criticism using Kernel Two Sample Tests\",\"Precision-Recall-Gain Curves: PR Analysis Done Right\",\"A Generalization of Submodular Cover via the Diminishing Return Property on the Integer Lattice\",\"Bidirectional Recurrent Neural Networks as Generative Models\",\"Quartz: Randomized Dual Coordinate Ascent with Arbitrary Sampling\",\"Maximum Likelihood Learning With Arbitrary Treewidth via Fast-Mixing Parameter Sets\",\"Hessian-free Optimization for Learning Deep Multidimensional Recurrent Neural Networks\",\"Large-scale probabilistic predictors with and without guarantees of validity\",\"Shepard Convolutional Neural Networks\",\"Matrix Manifold Optimization for Gaussian Mixtures\",\"Semi-supervised Convolutional Neural Networks for Text Categorization via Region Embedding\",\"Parallel Recursive Best-First AND/OR Search for Exact MAP Inference in Graphical Models\",\"Convolutional Neural Networks with Intra-Layer Recurrent Connections for Scene Labeling\",\"Bounding the Cost of Search-Based Lifted Inference\",\"Gradient-free Hamiltonian Monte Carlo with Efficient Kernel Exponential Families\",\"Linear Multi-Resource Allocation with Semi-Bandit Feedback\",\"Unsupervised Learning by Program Synthesis\",\"Enforcing balance allows local supervised learning in spiking recurrent networks\",\"Fast and Guaranteed Tensor Decomposition via Sketching\",\"Differentially private subspace clustering\",\"Predtron: A Family of Online Algorithms for General Prediction Problems\",\"Weighted Theta Functions and Embeddings with Applications to Max-Cut, Clustering and Summarization\",\"SGD Algorithms based on Incomplete U-statistics: Large-Scale Minimization of Empirical Risk\",\"On Top-k Selection in Multi-Armed Bandits and Hidden Bipartite Graphs\",\"The Brain Uses Reliability of Stimulus Information when Making Perceptual Decisions\",\"Fast Classification Rates for High-dimensional Gaussian Generative Models\",\"Fast Distributed k-Center Clustering with Outliers on Massive Data\",\"Human Memory Search as Initial-Visit Emitting Random Walk\",\"Non-convex Statistical Optimization for Sparse Tensor Graphical Model\",\"Convergence Rates of Active Learning for Maximum Likelihood Estimation\",\"Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis\",\"Efficient Exact Gradient Update for training Deep Networks with Very Large Sparse Targets\",\"Backpropagation for Energy-Efficient Neuromorphic Computing\",\"Alternating Minimization for Regression Problems with Vector-valued Outputs\",\"Learning both Weights and Connections for Efficient Neural Network\",\"Optimal Rates for Random Fourier Features\",\"The Population Posterior and Bayesian Modeling on Streams\",\"Frank-Wolfe Bayesian Quadrature: Probabilistic Integration with Theoretical Guarantees\",\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"Unified View of Matrix Completion under General Structural Constraints\",\"Efficient Output Kernel Learning for Multiple Tasks\",\"Scalable Adaptation of State Complexity for Nonparametric Hidden Markov Models\",\"Variational Consensus Monte Carlo\",\"Newton-Stein Method: A Second Order Method for GLMs via Stein's Lemma\",\"Practical and Optimal LSH for Angular Distance\",\"Learning to Linearize Under Uncertainty\",\"Finite-Time Analysis of Projected Langevin Monte Carlo\",\"Deep Visual Analogy-Making\",\"Matrix Completion from Fewer Entries: Spectral Detectability and Rank Estimation\",\"Online Learning with Adversarial Delays\",\"Multi-Layer Feature Reduction for Tree Structured Group Lasso via Hierarchical Projection\",\"Minimum Weight Perfect Matching via Blossom Belief Propagation\",\"Efficient Thompson Sampling for Online \\ufffcMatrix-Factorization Recommendation\",\"Improved Iteration Complexity Bounds of Cyclic Block Coordinate Descent for Convex Problems\",\"Lifted Symmetry Detection and Breaking for MAP Inference\",\"Evaluating the statistical significance of biclusters\",\"Discriminative Robust Transformation Learning\",\"Bandits with Unobserved Confounders: A Causal Approach\",\"Scalable Semi-Supervised Aggregation of Classifiers\",\"Online Learning with Gaussian Payoffs and Side Observations\",\"Private Graphon Estimation for Sparse Graphs\",\"SubmodBoxes: Near-Optimal Search for a Set of Diverse Object Proposals\",\"Fast Second Order Stochastic Backpropagation for Variational Inference\",\"Randomized Block Krylov Methods for Stronger and Faster Approximate Singular Value Decomposition\",\"Cross-Domain Matching for Bag-of-Words Data via Kernel Embeddings of Latent Distributions\",\"Scalable Inference for Gaussian Process Models with Black-Box Likelihoods\",\"Fast Bidirectional Probability Estimation in Markov Models\",\"Probabilistic Variational Bounds for Graphical Models\",\"Linear Response Methods for Accurate Covariance Estimates from Mean Field Variational Bayes\",\"Combinatorial Cascading Bandits\",\"Mixing Time Estimation in Reversible Markov Chains from a Single Sample Path\",\"Policy Gradient for Coherent Risk Measures\",\"Fast Rates for Exp-concave Empirical Risk Minimization\",\"Deep Generative Image Models using a \\ufffcLaplacian Pyramid of Adversarial Networks\",\"Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation\",\"Equilibrated adaptive learning rates for non-convex optimization\",\"BACKSHIFT: Learning causal cyclic graphs from unknown shift interventions\",\"Risk-Sensitive and Robust Decision-Making: a CVaR Optimization Approach\",\"Asynchronous stochastic convex optimization: the noise is in the noise and SGD don't care\",\"Lifelong Learning with Non-i.i.d. Tasks\",\"Optimal Linear Estimation under Unknown Nonlinear Transform\",\"Learning with Group Invariant Features: A Kernel Perspective.\",\"Regularized EM Algorithms: A Unified Framework and Statistical Guarantees\",\"Adaptive Stochastic Optimization: From Sets to Paths\",\"Beyond Convexity: Stochastic Quasi-Convex Optimization\",\"A Tractable Approximation to Optimal Point Process Filtering: Application to Neural Encoding\",\"Sum-of-Squares Lower Bounds for Sparse PCA\",\"Max-Margin Majority Voting for Learning from Crowds\",\"Learning with Incremental Iterative Regularization\",\"Halting in Random Walk Kernels\",\"MCMC for Variationally Sparse Gaussian Processes\",\"Less is More: Nystr\\u00f6m Computational Regularization\",\"Infinite Factorial Dynamical Model\",\"Regularization Path of Cross-Validation Error Lower Bounds\",\"Attractor Network Dynamics Enable Preplay and Rapid Path Planning in Maze\\u2013like Environments\",\"Teaching Machines to Read and Comprehend\",\"Principal Differences Analysis: Interpretable Characterization of Differences between Distributions\",\"When are Kalman-Filter Restless Bandits Indexable?\",\"Segregated Graphs and Marginals of Chain Graph Models\",\"Efficient Non-greedy Optimization of Decision Trees\",\"Probabilistic Curve Learning: Coulomb Repulsion and the Electrostatic Gaussian Process\",\"Inverse Reinforcement Learning with Locally Consistent Reward Functions\",\"Communication Complexity of Distributed Convex Learning and Optimization\",\"End-to-end Learning of LDA by Mirror-Descent Back Propagation over a Deep Architecture\",\"Subset Selection by Pareto Optimization\",\"On the Accuracy of Self-Normalized Log-Linear Models\",\"Regret Lower Bound and Optimal Algorithm in Finite Stochastic Partial Monitoring\",\"Is Approval Voting Optimal Given Approval Votes?\",\"Regressive Virtual Metric Learning\",\"Analysis of Robust PCA via Local Incoherence\",\"Learning to Transduce with Unbounded Memory\",\"Max-Margin Deep Generative Models\",\"Spherical Random Features for Polynomial Kernels\",\"Rectified Factor Networks\",\"Learning Bayesian Networks with Thousands of Variables\",\"Matrix Completion Under Monotonic Single Index Models\",\"Visalogy: Answering Visual Analogy Questions\",\"Tree-Guided MCMC Inference for Normalized Random Measure Mixture Models\",\"Streaming Min-max Hypergraph Partitioning\",\"Collaboratively Learning Preferences from Ordinal Data\",\"Biologically Inspired Dynamic Textures for Probing Motion Perception\",\"Generative Image Modeling Using Spatial LSTMs\",\"Robust PCA with compressed data\",\"Sampling from Probabilistic Submodular Models\",\"COEVOLVE: A Joint Point Process Model for Information Diffusion and Network Co-evolution\",\"Supervised Learning for Dynamical System Learning\",\"Regret-Based Pruning in Extensive-Form Games\",\"Fast Two-Sample Testing with Analytic Representations of Probability Measures\",\"Learning to Segment Object Candidates\",\"GP Kernels for Cross-Spectrum Analysis\",\"Secure Multi-party Differential Privacy\",\"Spatial Transformer Networks\",\"Anytime Influence Bounds and the Explosive Behavior of Continuous-Time Diffusion Networks\",\"Multi-class SVMs: From Tighter Data-Dependent Generalization Bounds to Novel Algorithms\",\"High-dimensional neural spike train analysis with generalized count linear dynamical systems\",\"Learning with a Wasserstein Loss\",\"b-bit Marginal Regression\",\"Natural Neural Networks\",\"Optimization Monte Carlo: Efficient and Embarrassingly Parallel Likelihood-Free Inference\",\"Adaptive Primal-Dual Splitting Methods for Statistical Learning and Image Processing\",\"On some provably correct cases of variational inference for topic models\",\"Collaborative Filtering with Graph Information: Consistency and Scalable Methods\",\"Combinatorial Bandits Revisited\",\"Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning\",\"A Structural Smoothing Framework For Robust Graph Comparison\",\"Competitive Distribution Estimation: Why is Good-Turing Good\",\"Efficient Learning by Directed Acyclic Graph For Resource Constrained Prediction\",\"A hybrid sampler for Poisson-Kingman mixture models\",\"An Active Learning Framework using Sparse-Graph Codes for Sparse Polynomials and Graph Sketching\",\"Local Smoothness in Variance Reduced Optimization\",\"Saliency, Scale and Information: Towards a Unifying Theory\",\"Fighting Bandits with a New Kind of Smoothness\",\"Beyond Sub-Gaussian Measurements: High-Dimensional Structured Estimation with Sub-Exponential Designs\",\"Spectral Norm Regularization of Orthonormal Representations for Graph Transduction\",\"Convolutional Networks on Graphs for Learning Molecular Fingerprints\",\"Mixed Robust/Average Submodular Partitioning: Fast Algorithms, Guarantees, and Applications\",\"Tractable Learning for Complex Probability Queries\",\"StopWasting My Gradients: Practical SVRG\",\"Mind the Gap: A Generative Approach to Interpretable Feature Selection and Extraction\",\"A Normative Theory of Adaptive Dimensionality Reduction in Neural Networks\",\"On the Convergence of Stochastic Gradient MCMC Algorithms with High-Order Integrators\",\"Learning structured densities via infinite dimensional exponential families\",\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"Variance Reduced Stochastic Gradient Descent with Neighbors\",\"Sample Efficient Path Integral Control under Uncertainty\",\"Stochastic Expectation Propagation\",\"Exactness of Approximate MAP Inference in Continuous MRFs\",\"Scale Up Nonlinear Component Analysis with Doubly Stochastic Gradients\",\"Generalization in Adaptive Data Analysis and Holdout Reuse\",\"Market Scoring Rules Act As Opinion Pools For Risk-Averse Agents\",\"Sparse Linear Programming via Primal and Dual Augmented Coordinate Descent\",\"Training Very Deep Networks\",\"Bayesian Active Model Selection with an Application to Automated Audiometry\",\"Particle Gibbs for Infinite Hidden Markov Models\",\"Learning spatiotemporal trajectories from manifold-valued longitudinal data\",\"A Bayesian Framework for Modeling Confidence in Perceptual Decision Making\",\"Path-SGD: Path-Normalized Optimization in Deep Neural Networks\",\"On the consistency theory of high dimensional variable screening\",\"End-To-End Memory Networks\",\"Spectral Representations for Convolutional Neural Networks\",\"Online Gradient Boosting\",\"Deep Temporal Sigmoid Belief Networks for Sequence Modeling\",\"Recognizing retinal ganglion cells in the dark\",\"A Theory of Decision Making Under Dynamic Context\",\"A Gaussian Process Model of Quasar Spectral Energy Distributions\",\"Hidden Technical Debt in Machine Learning Systems\",\"Local Causal Discovery of Direct Causes and Effects\",\"High Dimensional EM Algorithm: Statistical Optimization and Asymptotic Normality\",\"Revenue Optimization against Strategic Buyers\",\"Deep Convolutional Inverse Graphics Network\",\"Sparse and Low-Rank Tensor Decomposition\",\"Minimax Time Series Prediction\",\"Differentially Private Learning of Structured Discrete Distributions\",\"Sample Complexity of Learning Mahalanobis Distance Metrics\",\"Learning Wake-Sleep Recurrent Attention Models\",\"Robust Gaussian Graphical Modeling with the Trimmed Graphical Lasso\",\"Testing Closeness With Unequal Sized Samples\",\"Estimating Jaccard Index with Missing Observations: A Matrix Calibration Approach\",\"Neural Adaptive Sequential Monte Carlo\",\"Local Expectation Gradients for Black Box Variational Inference\",\"On Variance Reduction in Stochastic Gradient Descent and its Asynchronous Variants\",\"NEXT: A System for Real-World Development, Evaluation, and Application of Active Learning\",\"Super-Resolution Off the Grid\",\"Taming the Wild: A Unified Analysis of Hogwild-Style Algorithms\",\"The Return of the Gating Network: Combining Generative Models and Discriminative Training in Natural Image Priors\",\"Pointer Networks\",\"Associative Memory via a Sparse Recovery Model\",\"Robust Spectral Inference for Joint Stochastic Matrix Factorization\",\"Fast, Provable Algorithms for Isotonic Regression in all L_p-norms\",\"Adversarial Prediction Games for Multivariate Losses\",\"Asynchronous Parallel Stochastic Gradient for Nonconvex Optimization\",\"Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images\",\"Efficient and Parsimonious Agnostic Active Learning\",\"Softstar: Heuristic-Guided Probabilistic Inference\",\"Grammar as a Foreign Language\",\"Regularization-Free Estimation in Trace Regression with Symmetric Positive Semidefinite Matrices\",\"Winner-Take-All Autoencoders\",\"Deep Poisson Factor Modeling\",\"Bayesian Optimization with Exponential Convergence\",\"Sample Complexity of Episodic Fixed-Horizon Reinforcement Learning\",\"Learning with Relaxed Supervision\",\"Subsampled Power Iteration: a Unified Algorithm for Block Models and Planted CSP's\",\"Accelerated Mirror Descent in Continuous and Discrete Time\",\"The Human Kernel\",\"Action-Conditional Video Prediction using Deep Networks in Atari Games\",\"A Pseudo-Euclidean Iteration for Optimal Recovery in Noisy ICA\",\"Distributed Submodular Cover: Succinctly Summarizing Massive Data\",\"Community Detection via Measure Space Embedding\",\"Basis refinement strategies for linear value function approximation in MDPs\",\"Structured Estimation with Atomic Norms: General Bounds and Applications\",\"A Complete Recipe for Stochastic Gradient MCMC\",\"Bandit Smooth Convex Optimization: Improving the Bias-Variance Tradeoff\",\"Online Prediction at the Limit of Zero Temperature\",\"Learning Continuous Control Policies by Stochastic Value Gradients\",\"Exploring Models and Data for Image Question Answering\",\"Efficient and Robust Automated Machine Learning\",\"Preconditioned Spectral Descent for Deep Learning\",\"A Recurrent Latent Variable Model for Sequential Data\",\"Fast Convergence of Regularized Learning in Games\",\"Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation\",\"Reflection, Refraction, and Hamiltonian Monte Carlo\",\"The Consistency of Common Neighbors for Link Prediction in Stochastic Blockmodels\",\"Nearly Optimal Private LASSO\",\"Convergence Analysis of Prediction Markets via Randomized Subspace Descent\",\"The Poisson Gamma Belief Network\",\"Convergence rates of sub-sampled Newton methods\",\"No-Regret Learning in Bayesian Games\",\"Statistical Topological Data Analysis - A Kernel Perspective\",\"Semi-supervised Sequence Learning\",\"Structured Transforms for Small-Footprint Deep Learning\",\"Rapidly Mixing Gibbs Sampling for a Class of Factor Graphs Using Hierarchy Width\",\"Interpolating Convex and Non-Convex Tensor Decompositions via the Subspace Norm\",\"Sample Complexity Bounds for Iterative Stochastic Policy Optimization\",\"BinaryConnect: Training Deep Neural Networks with binary weights during propagations\",\"Interactive Control of Diverse Complex Characters with Neural Networks\",\"Submodular Hamming Metrics\",\"A Universal Primal-Dual Convex Optimization Framework\",\"Learning From Small Samples: An Analysis of Simple Decision Heuristics\",\"Explore no more: Improved high-probability regret bounds for non-stochastic bandits\",\"Fast and Memory Optimal Low-Rank Matrix Approximation\",\"Learnability of Influence in Networks\",\"Learning Causal Graphs with Small Interventions\",\"Information-theoretic lower bounds for convex optimization with erroneous oracles\",\"Fixed-Length Poisson MRF: Adding Dependencies to the Multinomial\",\"Large-Scale Bayesian Multi-Label Learning via Topic-Based Label Embeddings\",\"The Self-Normalized Estimator for Counterfactual Learning\",\"Fast Lifted MAP Inference via Partitioning\",\"Data Generation as Sequential Decision Making\",\"On Elicitation Complexity\",\"Decomposition Bounds for Marginal MAP\",\"Discrete R\\u00e9nyi Classifiers\",\"A class of network models recoverable by spectral clustering\",\"Skip-Thought Vectors\",\"Rate-Agnostic (Causal) Structure Learning\",\"Principal Geodesic Analysis for Probability Measures under the Optimal Transport Metric\",\"Consistent Multilabel Classification\",\"Parallel Predictive Entropy Search for Batch Global Optimization of Expensive Objective Functions\",\"Cornering Stationary and Restless Mixing Bandits with Remix-UCB\",\"Semi-Supervised Factored Logistic Regression for High-Dimensional Neuroimaging Data\",\"Gaussian Process Random Fields\",\"M-Statistic for Kernel Change-Point Detection\",\"Adaptive Online Learning\",\"A Universal Catalyst for First-Order Optimization\",\"Inference for determinantal point processes without spectral knowledge\",\"Kullback-Leibler Proximal Variational Inference\",\"Semi-Proximal Mirror-Prox for Nonsmooth Composite Minimization\",\"LASSO with Non-linear Measurements is Equivalent to One With Linear Measurements\",\"From random walks to distances on unweighted graphs\",\"Bayesian dark knowledge\",\"Matrix Completion with Noisy Side Information\",\"Dependent Multinomial Models Made Easy: Stick-Breaking with the Polya-gamma Augmentation\",\"On-the-Job Learning with Bayesian Decision Theory\",\"Calibrated Structured Prediction\",\"Learning Structured Output Representation using Deep Conditional Generative Models\",\"Time-Sensitive Recommendation From Recurrent User Activities\",\"Learning Stationary Time Series using Gaussian Processes with Nonparametric Kernels\",\"A Market Framework for Eliciting Private Data\",\"Lifted Inference Rules With Constraints\",\"Gradient Estimation Using Stochastic Computation Graphs\",\"Model-Based Relative Entropy Stochastic Search\",\"Semi-supervised Learning with Ladder Networks\",\"Embedding Inference for Structured Multilabel Prediction\",\"Copula variational inference\",\"Recursive Training of 2D-3D Convolutional Networks for Neuronal Boundary Prediction\",\"A Dual Augmented Block Minimization Framework for Learning with Limited Memory\",\"Optimal Testing for Properties of Distributions\",\"Efficient Learning of Continuous-Time Hidden Markov Models for Disease Progression\",\"Expectation Particle Belief Propagation\",\"Latent Bayesian melding for integrating individual and population models\",\"Distributionally Robust Logistic Regression\",\"Variational Dropout and the Local Reparameterization Trick\"],\"topic_key\":[2,2,0,0,0,0,2,1,3,1,3,1,1,1,3,2,0,0,3,0,1,3,3,2,1,0,3,0,3,3,1,0,3,1,2,1,1,0,1,2,3,0,1,1,0,1,1,3,2,3,0,0,0,0,0,1,0,0,1,1,0,1,1,0,3,1,2,2,1,2,2,3,3,3,2,1,3,1,2,2,1,1,1,0,1,1,1,2,0,3,1,0,0,1,1,3,1,0,3,2,3,0,3,2,3,2,0,2,3,0,1,1,2,1,1,2,0,0,1,0,1,2,3,3,3,0,3,1,0,0,3,1,1,0,0,1,1,3,0,3,1,2,1,1,2,1,2,2,3,2,2,2,1,3,0,1,0,0,0,0,0,2,0,0,1,3,3,3,0,0,1,2,1,1,1,2,1,0,1,2,1,1,0,1,0,1,0,3,1,2,2,2,0,0,1,2,1,0,2,2,2,1,3,3,1,3,2,1,3,0,2,1,0,3,1,0,0,0,2,0,3,0,1,3,1,2,0,3,1,3,0,1,2,1,2,0,2,2,2,0,1,1,3,2,1,1,3,1,2,1,0,0,0,0,3,1,0,0,1,1,2,0,1,3,0,0,0,0,3,1,3,3,2,3,0,0,0,2,2,1,2,3,1,2,0,1,3,1,0,1,0,0,1,2,1,1,3,3,1,0,1,2,1,0,2,0,3,1,3,0,2,2,2,1,1,0,3,1,1,1,0,1,0,2,2,0,3,2,3,3,2,3,0,1,1,0,3,1,2,1,3,3,2,1,0,3,0,1,1,2,2,1,0,2,1,2,2,2,2,0,0,1,1,1,3,2,1,2,0,2,3,0,0,2,1,0,0,1,1,1,0,1,0,2,2,3,0,0,0,2,0,0,3,2,0,3,1,1,0,0,0,0,0],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[403]},\"y\":{\"__ndarray__\":\"dNktQdSqIEGeCnu/zCQywPB288AVU/e/9WpWQf76A0DinZDByTXBvyW8k8G6/La/iCT6QKYyxb+lFE3B+0xoQTLFp8B4PaPATRZowTdFpb9ec4a/4p2QwXMSjsE1A1pBg+irQFuyucAaXJbBl5IIwQUbJsHFuI/BvgpgQNgjH7/HLYjB2RAdQb09iEGoqyY/XwC/wLWM9cBaSQVBRV2FQbpXmMFyOuXAroyKQOgmrkDCtju/nz62QKj8ZUClfYTBtMKMQXCwaMFs1m/Azz8PwQPfvL+2ZfK/R3yXv/OSFEF0RB/BE49IP0gsdUC8up8+VOFuP1uPDkHFihhBTN3pwI2sj8FvkIE/UuYfQVWuhkEFA+g/k6F1QcMQPkESRy/BXMSUwdxwB8Gwf3hBdNipQATLI8G4CFVAGxuDQejghkE49/NAfZcAwMMJ10BT4ePAOPtqQOr3kT5PXcBAurhEQXOwEsGDnY7BdDOeQGRQPMCl/LvAAOfHv2mwlECJ2UrBVBniQKral79QOo7Bt4FkQTFee8Gxr9492CqTwSslcUFRwZPBzf2HQSNyq8D5z2VBEaNdwSP4FcE5cEhAg0P/Pi1gJEHb5vg++rSEQLtYbEFsh9TACIjJvsV3Ar/+0HHAV/ycQB9gjkDXJJzBuaxnwZA+RsEr5Pc/R96Kwf9fikCSqSfAEAyyvoz0f8F4VgtB9agjQF6FncBtBN3AgyhcP/4gDEEgBIfBQQZnPbJgjMH3jqFAxwiDQfqfEkBGcX2/GfXgQKZBEECed31BdQMlQTWaKEHyWItBjhdLQYFybkFfDpo/Y3kMwd6xIMFCahtBA20Twcm89cC3JAvAlqUZP/w9B8HvDHxBt4KMwHl8+sBAbgS+zE+HwVITmMHIbhvBCdvHPnEx08CEukdAs+B7QEjHAUGai/XAU5ChQIDnikBqusXACrG3wH9sk0BEm0dB939aPnxqf0Co48fAqiRmQBL3wMAPVLo/ZRG9wIT4i8Hx9JE//D5wQB2JV0H8n1BBpFEJwTsIh8Bvwa5AHDcqQda7ykDoif7Ae4iAQRZackHbnA1BixTuQIr7kMGWkkLBlM7tP2UUMsGvpXxBcobwQFQlkcEN0O7AX3MeQSUndz7nyBvBulpYwVLakUD0X7S+/C9owGMKecDo2oJBmPLFv+zcmcFCiPDAhrUuP1hAk8FwuJg/4lYOQTb2xMCgSxbBY/3JQHylc8Hs38DA+6k/QCFd8kCmBg9BdN6DQTUIC8Heeg5BvHlXQbDJrUCqygLBoBrLv2TQSkAyvjzBOis/QWQCl0BJf7RAzWCGwdaeNkBgXlxBLpslQOS2MkC1cCu+OL1mwIYegr/TKZfBfqRsQDjj1sCaDt/ATDZwQOsTR0A3eYJAUVEJQAzQ/UD4c5jBs44GwGIQzMAcHgjB4ynAwGkId8EJ24c/nceLwawcmsGYsjZBfaAqwSCTEsH1+AfBfju7wNhcL0GfQnNBcdlrP4pfZkHASojBraixQPpCRkEanBO/BW4BwJKMPcEAk7k/zYTMwACTr0DQaArB4IC3wGY56kBFfU1BzmGPQD3j1T+YVUfBI4cywSFP20Ca8Y0/zR/NvgR1hEET5+bANIcUwQbXc0EcZwTAaB6LwQvPv0CndpnBscMNweZizkCc0I9AmVErQb3chb2sqPg/IGOQwPhinME1L6FAZWRAvhOCgkAbQKrAOkA8QJkB4cDv+BBBr/h+QQ8QvsCLW43BSqxEQaVxJ8EXHkzBz51+QdUZg8GkNAPBhKKcQB55iz8gjF5AsbogwasrckDwb4tBKHb4PhwSlsGSwDnBcyxeQQBgfUA1PATBjp2TwTSTG8EDMj9Azf/TQDF6p0BF7otBWKaWQCEJmj4/wF9BBWjTvyG0XEGIEdpAl4a5QCn8h0GlShbB0m71P34nhr/I8TA+HsxtQCFQm8G6sMRAjNBFvgcKgEFCW6o/4h+HQeeIQMFB1dLAF8RzwM1DfUEegxJBNBIGwbGlX8DEhAdB/5HXQD+Qtj99GxzB5XwaQTBHwsA4xkxBb9U9QciIlsEcHV2/6p6xwLISkT/9H4NBPnoNweWVg8AbdpLBqE42QX/P78CWrI/Bi6ICQa2KZD9dfP/AMbvNwKl8/sAs66q+xdglwQ==\",\"dtype\":\"float32\",\"order\":\"little\",\"shape\":[403]}},\"selected\":{\"id\":\"1185\"},\"selection_policy\":{\"id\":\"1184\"}},\"id\":\"1154\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1158\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1184\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data_source\":{\"id\":\"1154\"},\"glyph\":{\"id\":\"1179\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1180\"},\"selection_glyph\":null,\"view\":{\"id\":\"1182\"}},\"id\":\"1181\",\"type\":\"GlyphRenderer\"}],\"root_ids\":[\"1155\"]},\"title\":\"Bokeh Application\",\"version\":\"2.1.1\"}};\n",
              "  var render_items = [{\"docid\":\"34a0a1ac-90e1-4a7c-aa78-744b3bebbe67\",\"root_ids\":[\"1155\"],\"roots\":{\"1155\":\"c7c96293-5396-4cbc-b75e-f4a795f0181e\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else {\n",
              "        attempts++;\n",
              "        if (attempts > 100) {\n",
              "          clearInterval(timer);\n",
              "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        }\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1155"
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzW7DQsWUok8",
        "colab_type": "text"
      },
      "source": [
        "#Agora temos labels para nossos grupos "
      ]
    }
  ]
}